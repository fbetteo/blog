{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"AI Engineering &amp; Consulting","text":"<p>I'm an AI engineer, sr. data scientist, and consultant specializing in production-ready machine learning systems. With extensive experience designing and implementing AI solutions for CPG and retail businesses, I help organizations build scalable, efficient, and reliable AI systems that deliver measurable ROI.</p> <p>I write about life, AI - machine learning - statistics, building a business as indiehacker and of course, sports analytics. </p> <p>ex-Nielsen. ex-InsiteAI. ex-Despegar.</p>"},{"location":"#about-me","title":"About me","text":"<p>I've been there, I've worked with massive amounts of data, felt the pain of long pipelines that end up not working. I've seen that data not matching between reports, I've seen it duplicated in a side project, I've seen the wrong numbers in a coworker's customer facing powerpoint.</p> <p>I've built prediction models, I've deployed them, I've created AI agents and RAG applications and I know, because of experience, where the problems and uncertainties might appear, and I can help you be prepared for that.</p>"},{"location":"#my-approach-building-ai-systems-you-can-actually-control","title":"My approach: Building AI systems you can actually control","text":"<p>Measurable over mysterious - Turn your \"black box\" AI into systems you can debug, measure, and improve. No more guessing why things break or hoping they work.</p> <p>Hands-on, not hands-off - I build alongside your team with your data, your codebase, your specific problems. You get working solutions, not just recommendations.</p> <p>Team empowerment over dependency - The goal is making your team self-sufficient. You learn the systematic approaches that let you maintain and improve AI systems long after our engagement ends.</p> <p>When leadership asks \"What's our AI strategy?\" or \"Why did this fail?\" - you'll have clear answers backed by data, not excuses.</p>"},{"location":"#ai-consulting-services","title":"AI Consulting Services","text":"<ul> <li> <p> Advisory Services</p> <p>Strategic AI guidance without the full-time commitment</p> <p>Get expert AI roadmap development and strategic insights from dozens of successful implementations. Perfect for companies exploring AI adoption or validating their current approach.</p> <p>Low-touch, high-value consultation</p> <p>1 spot available</p> <p>Schedule Consultation</p> </li> <li> <p> Implementation Services</p> <p>From concept to working prototype in weeks</p> <p>Validate your AI concepts with working prototypes and get clear pathways to production. Hands-on development that proves feasibility and demonstrates real business value.</p> <p>Intensive, outcome-focused projects</p> <p>Schedule Consultation</p> </li> <li> <p> Fractional Head of AI</p> <p>Executive AI leadership when you need it most</p> <p>Scale your AI initiatives with experienced C-level leadership while maintaining flexibility. Get strategic direction, team building, and execution oversight without the full-time commitment.</p> <p>Strategic leadership + hands-on oversight</p> <p>1 spot available</p> <p>Schedule Consultation</p> </li> </ul> <p> View All Services &amp; Pricing</p> <p>Current and past clients include: Diggity, Oxford University, and several CPG startups.</p>"},{"location":"#client-testimonials","title":"Client Testimonials","text":"<ul> <li> <p>\"The educational materials Franco developed for our ML program were exceptional. A complex task successfully completed.\"</p> <p>Ajit Jaokar, Fellow, Department of Engineering Science, University of Oxford</p> </li> <li> <p>\"Franco developed the first MVP using Probabilistic Graphical Models to solve the main goal of Diggity: 'detect bottlenecks that might hinder the progress and success of the project without you having to ask for it'\"</p> <p>Stephan CEO, Diggity</p> </li> <li> <p>\"Working with Franco on our forecasting models gave us a competitive edge in our market.\"</p> <p>Juan Bujacich, Manager, Nielsen</p> </li> </ul>"},{"location":"#ready-to-transform-your-business-with-ai","title":"Ready to Transform Your Business with AI?","text":"<p>Don't just adopt AI - implement it strategically for real business impact.</p> <p>\u2713 Personalized solutions tailored to your specific challenges   \u2713 Implementation support from concept to production   \u2713 Clear communication without unnecessary technical jargon   \u2713 Focus on measurable business results, not just technical metrics  </p> <p>Schedule Your Free 30-Minute Consultation</p>"},{"location":"#youchatchannel-applied-ai-engineering-in-action","title":"YouChatChannel - Applied AI Engineering in Action","text":"<p>I'm the founder of YouChatChannel, an AI platform that allows you to have interactive conversations with YouTube channels through advanced AI assistants.</p> <p>YouChatChannel transforms passive content consumption into an engaging, interactive experience. The platform analyzes video content through transcripts and creates specialized AI assistants (LLMs) that can answer questions, explain concepts, and provide insights based on the channel's content.</p> <p></p> <p>This project exemplifies how I approach AI engineering challenges: building systems that deliver real value while maintaining technical excellence behind the scenes.</p>"},{"location":"#e-commerce-image-similarity-engine-from-concept-to-conversion","title":"E-commerce Image Similarity Engine: From Concept to Conversion","text":"<p>Business Problem: A major e-commerce retailer struggled with product discovery across their catalog of thousands of items, limiting cross-selling opportunities.</p> <p>My Engineering Solution: I engineered a complete visual similarity system using a proven 3-step methodology: 1. Efficient image acquisition pipeline handling thousands of product images 2. Optimized embedding generation with CLIP/ResNet models for maximum accuracy 3. High-performance similarity search using FAISS vector indexing.</p> <p>Business Impact: Inmediately customer support was able to offer similar products to customers reaching out, generating new sales or speeding up the customer support response time and reducing tedious work. Next application will be to compare current products with new catalogs from suppliers to identify valuable opportunities.</p> <p>Read this blogpost to see how  this inmediate high ROI problem was solved. Or check the portfolio example Could your business benefit from similar AI-powered product discovery? Schedule a consultation to discuss your specific needs.</p>"},{"location":"#sportsjobs-online","title":"Sportsjobs Online","text":"<p>I run a job board for sports analytics and data related positions. This includes working for teams, consultancy companies, whole leagues and some esports or betting organizations.  </p> <p>This is a project I handle myself, all self hosted and that I'm growing from a personal perspective. Finding sports analytics opportunities is not easy and I have a business running 24/7 which is something I encourage anyone to try.  </p> <p></p> <p>If you want to post a job, reach out to me at franco@sportsjobs.online or by any other channel and I'll happily charge 50% if you are coming from this site.</p>"},{"location":"#get-in-touch","title":"Get in touch","text":"<ul> <li> <p> Social Media</p> <p>You can reach out to me by email or social media.</p> <p>Email: francobetteo@gmail.com</p> <p>Stay connected and get the latest updates by following me on  Twitter,  Bluesky and  GitHub. These platforms are where I share my latest content, thoughts, and projects in the world of AI and machine learning.</p> </li> </ul>"},{"location":"github-site/","title":"GitHub Pages Site","text":""},{"location":"good_resources/","title":"Good resources","text":"<p>A list of books, channels, people that I find valuable and might be useful to you too. I find curated lists of good content most valuable than ever now that googling is complicated if you are not sure what you are looking for. For technical topics I tend to look here first and only after check random websites.</p>"},{"location":"good_resources/#machine-learning-statistics","title":"Machine learning -  Statistics","text":""},{"location":"good_resources/#books","title":"Books","text":"<ul> <li>Introduction to statistical learning (ISLR)</li> <li>Elements of statistical learning (ESL)</li> <li>Hands-On Machine learning with scikit-learn and tensorflow - Aurelie Geron</li> <li>Bayesian Data Analysis - Gelman</li> <li>Statistical Inference - Casella, Berger</li> <li>Linear Algebra Done Right - Axlr</li> <li>Statistical Rethinking - McElreath</li> <li>Artifical Intelligence A moddern approach - Russel, Norvig</li> <li>Mathematics for Machine Learning</li> </ul>"},{"location":"good_resources/#resources-links-and-videos","title":"Resources, links and videos","text":"<ul> <li>https://stanford.edu/~shervine/teaching/</li> <li>CS50 Stanford</li> <li>CS221 Stanford</li> <li>A short introduction to Entropy, Cross-Entropy and KL Divergence</li> <li>Data Science Decoded - Podcast reviewing seminal (old, foundational) papers</li> </ul>"},{"location":"services/","title":"AI Consulting Services","text":"<p>Transform your business with strategic AI implementation. Choose the engagement model that fits your needs and accelerate your AI journey with expert guidance.</p>"},{"location":"services/#advisory-services","title":"Advisory Services","text":""},{"location":"services/#strategic-ai-guidance-without-the-full-time-commitment","title":"Strategic AI Guidance Without the Full-Time Commitment","text":"<p>Perfect for: Companies exploring AI adoption, teams needing strategic direction, startups requiring expert guidance without full-time commitment.</p>"},{"location":"services/#what-you-get","title":"What you get:","text":"<ul> <li> <p>Strategic AI Roadmap Development   Clear, actionable plans aligned with your business objectives</p> </li> <li> <p>Technology Stack Recommendations   Optimal tools and platforms for your specific needs  </p> </li> <li> <p>Risk Assessment &amp; Mitigation   Avoid costly mistakes with insights from dozens of implementations</p> </li> <li> <p>Team Training &amp; Knowledge Transfer   Empower your team with AI expertise and best practices</p> </li> <li> <p>Architecture Reviews   Optimize existing systems for maximum efficiency and scalability</p> </li> </ul>"},{"location":"services/#how-we-work-together","title":"How we work together:","text":"<ul> <li>Direct access via Slack/Teams for quick questions and guidance</li> <li>Weekly or bi-weekly strategy calls to review progress and address challenges</li> <li>Monthly deep-dive sessions with comprehensive analysis and recommendations</li> <li>Detailed documentation and reports for your team and stakeholders</li> </ul> <p>Investment: $1,000-$3,000/month depending on scope and access level</p> <p>Book Advisory Consultation</p>"},{"location":"services/#implementation-services","title":"Implementation Services","text":""},{"location":"services/#from-concept-to-working-prototype-in-weeks","title":"From Concept to Working Prototype in Weeks","text":"<p>Perfect for: Companies with specific AI use cases to validate, teams wanting proof of feasibility before full commitment, businesses exploring AI potential with controlled risk.</p>"},{"location":"services/#what-you-get_1","title":"What you get:","text":"<ul> <li> <p>Working Prototypes   Functional AI solutions that demonstrate real business value</p> </li> <li> <p>Production Pathway Planning   Clear roadmap from prototype to full deployment</p> </li> <li> <p>Integration Assessment   Comprehensive analysis of how AI fits with your existing systems</p> </li> <li> <p>Performance Optimization   Fine-tuned solutions that meet your speed and accuracy requirements</p> </li> <li> <p>Team Collaboration   Work directly with your team for seamless knowledge transfer</p> </li> </ul>"},{"location":"services/#our-proven-process","title":"Our proven process:","text":"<ul> <li>POC development with regular demonstrations and feedback loops</li> <li>Collaborative development ensuring your team understands and can extend the solution</li> <li>Detailed production planning with step-by-step deployment guidance</li> <li>Post-POC consultation to support your production decisions</li> </ul> <p>Investment: $5,000-$100,000 depending on project complexity (individual budget assessment)</p> <p>Discuss Your Project</p>"},{"location":"services/#fractional-head-of-ai","title":"Fractional Head of AI","text":""},{"location":"services/#executive-ai-leadership-when-you-need-it-most","title":"Executive AI Leadership When You Need It Most","text":"<p>Perfect for: Growing companies ready to scale AI initiatives, organizations needing AI leadership without full-time hire commitment, businesses undergoing AI transformation.</p>"},{"location":"services/#what-you-get_2","title":"What you get:","text":"<ul> <li> <p>AI Strategy Development &amp; Execution   Comprehensive roadmaps with hands-on implementation oversight</p> </li> <li> <p>Team Building &amp; Leadership   Hiring guidance, team structure design, and direct management</p> </li> <li> <p>Technology &amp; Vendor Evaluation   Expert assessment and selection of AI tools and partnerships  </p> </li> <li> <p>Budget Planning &amp; Resource Allocation   Optimize investments for maximum ROI</p> </li> <li> <p>Cross-Functional Collaboration   Bridge AI initiatives with business units and stakeholders</p> </li> <li> <p>Board &amp; Executive Reporting   Regular updates on progress, metrics, and strategic decisions</p> </li> </ul>"},{"location":"services/#your-dedicated-ai-executive","title":"Your dedicated AI executive:","text":"<ul> <li>Remote AI direction. Full time async slack availability.</li> <li>Direct participation in executive team meetings and strategic decisions</li> <li>Ownership of AI initiatives from conception through deployment</li> <li>Performance tracking and optimization of AI team and projects</li> </ul> <p>Investment: $10,000-$20,000/month based on time commitment and scope</p> <p>Explore Leadership Role</p>"},{"location":"services/#service-comparison","title":"Service Comparison","text":"Service Duration Commitment Level Investment Range Best For Advisory 2 weeks - ongoing Low-touch $1,000-$3,000/month Strategic guidance &amp; planning Implementation 2-12 weeks High-touch $5,000-$100,000 project POC development &amp; validation Fractional Head of AI 3-12 months Medium-high touch $10,000-$20,000/month Leadership &amp; team scaling"},{"location":"services/#ready-to-transform-your-business-with-ai","title":"Ready to Transform Your Business with AI?","text":"<p>Don't just adopt AI - implement it strategically for real business impact. Every engagement starts with a comprehensive assessment to ensure we deliver maximum value for your specific situation.</p> <p>\u2713 Personalized solutions tailored to your specific challenges   \u2713 Implementation support from concept to production   \u2713 Clear communication without unnecessary technical jargon   \u2713 Measurable results focused on business outcomes, not just technical metrics  </p> <p>Schedule Your Free 30-Minute Consultation</p>"},{"location":"writing/","title":"My words, sometimes technical, sometimes not","text":"<p>I previously had a blog where I used to write about technical topics in english or spanish (lately only english). Here you can find all that old content and anything new that I publish, this is the actual source of truth.</p> <p>You can expect to find topics around statistics, AI, machine learning, learning to do business or software in general but also about myself.</p> <p> Follow me on X</p>"},{"location":"writing/2018/08/25/cadenas-de-markov/","title":"Cadenas de Markov","text":"<p>Las cadenas de Markov son herramientas muy \u00fatiles para modelar transiciones entre estados. Imaginemos un escenario sencillo con dos posibles estados: d\u00eda de lluvia o d\u00eda soleado. En el momento t el estado supongamos que es \"d\u00eda soleado\". \u00bfCu\u00e1l ser\u00e1 el estado en t+1 ? Dadas las probabilidades de transici\u00f3n de un estado a otro podemos simular escenarios tras el paso del tiempo. Mismo en algunos casos puede ser \u00fatil entender si en el largo plazo esta simulaci\u00f3n converge hacia alg\u00fan resultado estable en el tiempo.</p> <p>Mostraremos ejemplos sencillos, pero la metodolog\u00eda es escalable a procesos complejos como pueden usarse en meteorolog\u00eda, aplicaciones financieras, etc. El algoritmo de b\u00fasqueda de Google est\u00e1 basado en cadenas de Markov, para que vean la utilidad. <sup>1</sup></p> <p>Lo que necesitamos para este ejercicio son las probabilidades de transici\u00f3n de un estado a otro y los valores iniciales en cada estado.</p> <p>Supongamos una clase de estad\u00edstica con n estudiantes, en la que dos estados son posibles.  Estado A : El alumno est\u00e1 atento. Estado B : El alumno est\u00e1 aburrido.</p> <ul> <li>Las probablidades son las siguientes: <ul> <li>En t+1 el 80% de A sigue en A (y por lo tanto el 20% de A pasa a B)</li> <li>En t+1 el 25% de B pasa a A (y por lo tanto el 75% de B queda en B)</li> </ul> </li> </ul> <p>La matriz que representa esa probabilidades la vamos a llamar * Matriz de Transici\u00f3n *.</p> <pre><code>tmatrix &lt;-  as.matrix(c(0.8,0.25))  \n# 80% de A sigue en A, 25% de B pasa a A en t+1\n\ntmatrix &lt;- t(tmatrix) \n# trasponemos porque necesitamos esta informaci\u00f3n en la primera fila.\n\ntmatrix &lt;- rbind(tmatrix, 1 - tmatrix[1,]) \n# Agregamos la segunda fila, que es 1 menos la primera.\n\ntmatrix # Matriz de transci\u00f3n\n</code></pre> <pre><code>##      [,1] [,2]\n## [1,]  0.8 0.25\n## [2,]  0.2 0.75\n</code></pre> <p>La matriz de valores iniciales es la siguiente: En un primero momento (t), el 10% de los alumnos est\u00e1 atento y el 90% aburrido.</p> <pre><code>smatrix &lt;- as.matrix(c(0.1,0.9)) # Matriz inicial, 10% Atento, 90% aburridos\n</code></pre> <p>Ya tenemos toda la informaci\u00f3n necesaria para hacer nuestras primeras simulaciones. Supongamos que cada per\u00edodo de tiempo son 10 minutos, por lo tanto si t es el momento 0, t+1 es a los 10 de minutos de empezada la clase, t+2 a los 20 y as\u00ed sucesivamente.</p> <p>Para evaluar el porcentaje de alumnos concentrados en determinado momento de la clase lo que debemos hacer es multiplicar la matriz de estado inicial por la matriz de transici\u00f3n tantas veces como momentos a futuro querramos simular.</p> <p>Por ejemplo si queremos ver que pasar\u00e1 con nuestros alumnos luego de 20 minutos de clase debemos multiplicar smatrix * tmatrix 2 veces.</p> <pre><code>for (i in 1:2){            # Loopeamos 2 veces. %*% es la multiplicacion matricial.\n  smatrix = tmatrix %*% smatrix  \n# smatrix va tomando nuevos valores en cada iteracion, \n# reflejando el movimiento de un estado a otro\n}\n\nsmatrix  # Despues de 2 iteraciones -&gt; A 42% , B 58%\n</code></pre> <pre><code>##         [,1]\n## [1,] 0.41775\n## [2,] 0.58225\n</code></pre> <p>Vemos que luego de 2 transiciones el estado A est\u00e1 compuesto por casi 42% de alumnos (concentrados) y 58% no atentos. Son movimientos bastante r\u00e1pidos de un estado a otro.</p> <p>Veamos qu\u00e9 pasa luego de 10 iteraciones.</p> <pre><code>smatrix &lt;- as.matrix(c(0.1,0.9)) # Reseteamos smatrix a su estado inicial\n\nfor (i in 1:10){           \n# Loopeamos 10 veces. %*% es la multiplicacion matricial.\n  smatrix = tmatrix %*% smatrix   \n# smatrix va tomando nuevos valores en cada iteracion, \n# reflejando el movimiento de un estado a otro\n}\n\nsmatrix  # Despues de 10 iteraciones -&gt; A 55% , B 45%\n</code></pre> <pre><code>##           [,1]\n## [1,] 0.5544017\n## [2,] 0.4455983\n</code></pre> <p>Luego de 10 movimientos, A pasa a tener el 55% de los alumnos dejando a 45% en B (no atentos). En este ejemplo con el paso del tiempo los alumnos se concentran m\u00e1s y m\u00e1s en la clase. Pero es este un proceso continuo e infinito? Llega un momento en que dada la matriz de transci\u00f3n todos los alumnos pasan a estar en el estado A, es decir, atentos?</p> <p>Para analizar esto podemos ver qu\u00e9 sucede luego de 1000 iteraciones (ser\u00eda una clase muy muy larga...)</p> <pre><code>smatrix &lt;- as.matrix(c(0.1,0.9)) # Reseteamos smatrix a su estado inicial\n\nfor (i in 1:1000){  # Loopeamos 10 veces. %*% es la multiplicacion matricial.\n  smatrix = tmatrix %*% smatrix  \n# smatrix va tomando nuevos valores en cada iteracion,\n# reflejando el movimiento de un estado a otro\n}\n\nsmatrix  # Despues de 1000 iteraciones -&gt; A 55% , B 45%\n</code></pre> <pre><code>##           [,1]\n## [1,] 0.5555556\n## [2,] 0.4444444\n</code></pre> <p>El resultado es casi id\u00e9ntico luego de 1000 iteraciones al intento de tan solo 10 iteraciones. Por lo tanto podemos ver que esta cadena de Markov converge r\u00e1pidamente a 55% en A y 45% en B. Es un estado estacionario del cual no podemos movernos dada la matriz de transici\u00f3n que tenemos.</p> <p>Este ejemplo sencillo permite ver la intuici\u00f3n detr\u00e1s de esta potente herramienta en unos pocos pasos. Obviamente como comentamos antes se puede utilizar para procesos mucho m\u00e1s complejos y de muy diversas areas.  Quer\u00edamos mostrar los fundamentos con una aplicaci\u00f3n r\u00e1pida y que se comprenda que lo que se requiere es una matriz de transici\u00f3n y un estado inicial.</p> <ol> <li> <p>Para una explicaci\u00f3n gr\u00e1fica y muy did\u00e1ctica dejamos el siguiente link en ingl\u00e9s. \u21a9</p> </li> </ol>","tags":["r","matematica","cadenas de Markov"]},{"location":"writing/2018/08/25/simulacion-de-monty-hall/","title":"Simulaci\u00f3n de Monty Hall","text":"<p>Vamos a ver en un corto y sencillo ejemplo c\u00f3mo hacer una simulaci\u00f3n en R. El caso a utilizar es el \"famoso\" problema de Monty Hall, asociado a un programa televisivo de Estados Unidos. </p> <p>En breve, el problema consiste en que un concursante debe elegir una entre 3 puertas (A,B y C). Detr\u00e1s de una hay un premio (en general un autom\u00f3vil) y tras las otras dos no hay nada (o una cabra en algunos ejemplos, lo cual no me parece tan malo en realidad..). Una vez que el concursante eligi\u00f3 una puerta, el organizador del programa, que sabe qu\u00e9 puerta oculta el premio y cu\u00e1les no, abre una de las dos puertas restantes, tras la cual no hay premio (recuerden que sabe qu\u00e9 hay detr\u00e1s de cada puerta). Ante el nuevo escenario, el concursante debe elegir si mantiene su elecci\u00f3n original o decide cambiar por la puerta restante, es decir, la que no eligi\u00f3 ni la que abri\u00f3 el organizador.</p> <ul> <li>Qu\u00e9 conviene hacer ante tal incertidumbre? <ul> <li>Cambiar? </li> <li>Mantenerse fiel a la decisi\u00f3n original sin caer en los juegos psicol\u00f3gicos del programa? </li> <li>Es indistinto? 50/50 entre las dos puertas.</li> </ul> </li> </ul> <p>La simulaci\u00f3n deber\u00edaa darnos una respuesta acertada. Comencemos.</p> <p>Generamos las puertas y un vector donde vamos a guardar el resultado de la simulaci\u00f3n.</p> <pre><code>puertas &lt;- c(\"A\",\"B\",\"C\")\nxdata   &lt;- c()\n</code></pre> <p>Ahora lo que vamos a hacer es simular 10000 escenarios distintos emulando la l\u00f3gica del problema. En cada uno vamos a asignarle a una puerta al azar el premio (con el comando \"sample\"). Luego elegiremos, como si fueramos el concursante, una puerta al azar. Descartaremos una de las puertas sin premio y por \u00faltimo y m\u00e1s importante, vamos a analizar en cada escenario qu\u00e9 hubiera pasado si nos quedabamos con la puerta elegida originalmente y qu\u00e9 hubiera pasado si cambi\u00e1bamos.  Si no hay diferencia entre cambiar y no cambiar, luego de 10000 simulaciones deber\u00edamos haber ganado 5000 veces al cambiar y 5000 al no cambiar (con alg\u00fan margen de error). En caso contrario, alguna de las dos estrategias es superadora.</p> <pre><code>set.seed(10)\nfor (i in 1:10000) {  # 10000 iteraciones\n  premio &lt;- sample(puertas)[1] # Asignar al premio una puerta al azar\n  eleccion &lt;- sample(puertas)[1] # Concursante elige una puerta al azar\n  abrir &lt;- sample(puertas[which(puertas != eleccion \n  &amp; puertas != premio)])[1]\n  # \"Abren\" una que no es la que elegiste ni la que tiene premio\n  cambiarsi &lt;- puertas[which(puertas != eleccion \n  &amp; puertas != abrir)] # Situacion si cambiaras. \n  if(eleccion == premio) (xdata = c(xdata,\"nocambiargana\")) \n  # Caso en que eleccion original ganara y guardas resultado\n  if(cambiarsi == premio)(xdata = c(xdata, \"cambiargana\"))\n  # Caso en que cambiar ganara y guardas resultado\n}\n</code></pre> <p>LLegado este punto tenemos un vector xdata que tiene para cada una de las 10000 iteraciones, qu\u00e9 estategia hubiera ganado. Si cambiar de puerta o no cambiar. Ahora simplemente contamos cu\u00e1ntas hay de cada una y analizamos el resultado.</p> <pre><code>length(which(xdata == \"cambiargana\")) # Cantidad que hubieran ganado si cambiabas\n</code></pre> <pre><code>## [1] 6623\n</code></pre> <pre><code>length(which(xdata == \"nocambiargana\")) \n</code></pre> <pre><code>## [1] 3377\n</code></pre> <pre><code># Cantidad que hubieran ganado si no cambiabas\n\ntable(xdata)\n</code></pre> <pre><code>## xdata\n##   cambiargana nocambiargana \n##          6623          3377\n</code></pre> <p>Para sorpresa o no de ustedes, la elecci\u00f3n parece obvia. Cambiar de puerta nos hace elegir el premio un 66% de las veces y no cambiar tan solo un 33%.  </p> <p>Entender por qu\u00e9 es interesante.  </p> <p>Al elegir inicialmente una puerta entre las 3 opciones, la probabilidad de acertarle al premio es \u2153. De ah\u00ed que la estrategia de no cambiar de puerta es efectiva solo un 33% de las veces. Es simplemente quedarse con la elecci\u00f3n inicial que tenia \u2153 de chances de ser correcta, independientemente de la puerta que abra el organizador.</p> <p>Ahora, supongamos que en la elecci\u00f3n inicial elegimos una puerta que no contiene el premio ( 66% de probabilidades). La estrategia de no cambiar de puerta nos hace perder indiscutidamente.</p> <p>Si juntamos las dos proposiciones obtenemos que no cambiar de puerta nos hace ganar \u2153 de las veces, cuando elegimos bien por azar la puerta del premio inicialmente, y nos va a hacer perder el resto de las veces - \u2154 de las veces - que es cuando elegimos una puerta sin premio al principio.</p> <p>Otro razonamiento equivalente es que cambiar de puerta nos hacer perder siempre y cuando hayamos elegido la puerta del premio originalmente (\u2153) pero nos va a hacer ganar siempre que hayamos elegido una sin premio (\u2154) porque la nueva puerta si o s\u00ed tendr\u00e1 el premio, ya que la tercera es la que abre el organizador y no tiene premio.</p> <p>En caso de que la r\u00e1pida intuici\u00f3n nos hiciera creer que la elecci\u00f3n entre cambiar y no cambiar era indistinto y ambas ten\u00edan 50% de chances de garantizarnos el premio, el ejercicio de simulaci\u00f3n nos hubiera hecho elegir correctamente.</p> <p>En este caso razonar el problema es posible ya que involucra pocas opciones pero en situaciones m\u00e1s complejas la simulaci\u00f3n puede ayudar enormemente a la toma de decisiones.</p>","tags":["R","simulacion"]},{"location":"writing/2018/08/25/tipos-de-variables/","title":"Tipos de Variables","text":"<p>Las caracter\u00edsticas de las variables que podemos encontrar en un dataset son muy diversas, pero general se pueden clasificar bajo alguno de los siguientes formatos.</p> <p>Categ\u00f3ricas o Cualitativas</p> <p>Corresponden a variables con etiquetas o valores pero que no siguen un orden espec\u00edfico o no tienen jerarqu\u00eda. Por ejemplo: color de ojos, g\u00e9nero, sabor (dulce, salado, amargo), etc. Para estas variables, que una observaci\u00f3n corresponda a un valor u a otro no revela mayor importancia o mejor ponderaci\u00f3n  sobre otra observaci\u00f3n, son simplemente distintas.</p> <pre><code>df &lt;- as.data.frame(matrix(c(\"Persona1\",\"Persona2\",\"Persona3\",\"Verde\",\"Marron\",\n      \"Azul\",      1.8,1.87,1.65,\"Secundario Completo\", \"Universitario Completo\",\n      \"Sin estudios\",3,2,1),nrow = 3, ncol = 5))\nnames(df) &lt;- c(\"ID\",\"Ojos\",\"Altura\",\"Estudios\",\"Hijos\")\n\ndf$Ojos\n</code></pre> <pre><code>## [1] \"Verde\"  \"Marron\" \"Azul\"\n</code></pre> <p>Simulamos una tabla muy b\u00e1sica con 4 columnas por observaci\u00f3n. Como ejemplo de variable categ\u00f3rica tomamos el color de ojos de estas personas. Y vemos que puede tomar los valores azul, marr\u00f3n o verde. M\u00e1s all\u00e1 de los gustos personales, en principio estas etiquetas no revelan ning\u00fan orden, simplemente valores distintos seg\u00fan el individuo.</p> <p>Ordinales</p> <p>Corresponden a variables con etiquetas pero que en este caso s\u00ed tienen un orden establecido o jerarqu\u00eda. Es decir que una etiqueta es \"mejor\" o tiene un valor m\u00e1s elevado. Por otra parte, en esta jerarqu\u00eda o escala no podemos determinar cu\u00e1nto mejor es una etiqueta por sobre otra, solo sabemos c\u00f3mo se ordenan.</p> <p>Volvemos al ejemplo de nuestra tabla. Este caso tomamos la columna Nivel de estudios.</p> <pre><code>df$Estudios\n</code></pre> <pre><code>## [1] \"Secundario Completo\"    \"Universitario Completo\" \"Sin estudios\"\n</code></pre> <p>Vemos que en nuestra tabla se pueden encontrar los valores \"Sin estudios\", \"Secundario Completo\" y \"Universitario Completo\". Podemos decir que esta columna presenta un orden l\u00f3gico entre las distintas etiquetas y que Universitario completo es m\u00e1s deseable que Secundario Completo y este \u00faltimo a su vez m\u00e1s deseable que Sin Estudios.  Por otra parte, no podemos definir concretamente cu\u00e1nto m\u00e1s deseable una categor\u00eda sobre la otra. Es universitario Completo 2 veces mejor que Secundario completo? 1? 3?. Y esa \"distancia\", es la misma entre Secundario completo y Sin Estudios? No es clara amplitud.</p> <p>Cuantitativas Discretas</p> <p>Corresponden a variables num\u00e9ricas que son numerables, es decir que podemos contar cuantos valores intermedios hay entre 2 valores cualquiera. Entre cada valor no hay infinitos posibles. Siguiendo nuestra tabla, el ejemplo a tener en cuenta es el de n\u00famero de hijos.</p> <pre><code>df$Hijos\n</code></pre> <pre><code>## [1] \"3\" \"2\" \"1\"\n</code></pre> <p>Cada persona puede tener entre 0 y digamos... 10 hijos para no ser tan extremistas. A su vez, no se pueden tener fracciones de hijo. Por lo tanto, entre 6 y 8 hijos, solo se pueden tener 7. No 7.4, ni 6.2. En ese sentido decimos que entre dos valores cualquiera podemos numerar los intermedios.</p> <p>Cuantitativas Continuas</p> <p>Corresponden a variables num\u00e9ricas no numerables, es decir que entre 2 valores cualquiera, hay infinitos intermedios. En nuestro ejemplo, podemos tomar la columna Altura para ilustrarlo.</p> <pre><code>df$Altura\n</code></pre> <pre><code>## [1] \"1.8\"  \"1.87\" \"1.65\"\n</code></pre> <p>En nuestro caso tenemos valores redondeados pero si tuvi\u00e9ramos valores m\u00e1s precisos, hay inifinitas posibilidades entre 1.7 y 1.8. Este tipo de variables son muy comunes y se encuentran por todos lados. Temperatura, longitudes, etc.</p>","tags":["estadistica"]},{"location":"writing/2018/09/01/hola-map-chau-apply/","title":"Hola MAP. Chau Apply","text":"","tags":["tidyverse","R"]},{"location":"writing/2018/09/01/hola-map-chau-apply/#introduccion","title":"Introducci\u00f3n","text":"<p>La idea de este post es introducirlos a la familia de funciones MAP, propias de tidyverse. A grandes rasgos son un remplazo MUY \u00fatil a la familia de funciones APPLY, propias de R base. Estas \u00faltimas se suelen ense\u00f1ar en todos los cursos introductorios de R, como la manera correcta de aplicar funciones a listas o columnas de dataframes.  No es que no sirvan, pero dado el surgimiento de tantas librer\u00edas que facilitan el manejo de la data, no tiene sentido seguir insistiendo con ellas dado que hay nuevas con mayor flexibilidad, muy sencillas de utilizar y mucho m\u00e1s amenas.</p> <ul> <li>Lo mejor que tienen las funciones MAP es:<ul> <li>Consistencia en los inputs.</li> <li>Flexibilidad del output.</li> <li>Integraci\u00f3n con todo el universo tidyverse y prolijidad.</li> </ul> </li> </ul> <p>Empecemos.</p> <pre><code>library(purrr) # MAP est\u00e1 contenida ac\u00e1\nlibrary(dplyr)\n</code></pre> <pre><code>## Warning: package 'dplyr' was built under R version 4.0.5\n</code></pre> <p>Como regla general, MAP aplica funciones a elementos de una lista o de un vector. Su output es otra lista. Muy similar a lapply().</p> <pre><code>l1 &lt;- list( a= c(100,200), b = c(8,10))\nmap(l1, max)\n</code></pre> <p><pre><code>## $a\n## [1] 200\n## \n## $b\n## [1] 10\n</code></pre> A cada lista le calcula el m\u00e1ximo y devuelve una lista con cada elemento siendo el resultado de la funci\u00f3n.</p> <p>Tenemos la flexibilidad para pasarle funciones an\u00f3nimas..</p> <pre><code>map(l1, function(x) max(x))\n</code></pre> <pre><code>## $a\n## [1] 200\n## \n## $b\n## [1] 10\n</code></pre> <p>Aplicando funciones a elementos de un vector. Cada numero de 1 a 5 es usado como primer input de la funcion rnorm, sd y n son otros par\u00e1metros de rnorm. El resultado de nuevo es una lista.</p> <pre><code>set.seed(1)\n1:5 %&gt;% map(., rnorm,sd =2, n=5)\n</code></pre> <pre><code>## [[1]]\n## [1] -0.2529076  1.3672866 -0.6712572  4.1905616  1.6590155\n## \n## [[2]]\n## [1] 0.3590632 2.9748581 3.4766494 3.1515627 1.3892232\n## \n## [[3]]\n## [1]  6.023562  3.779686  1.757519 -1.429400  5.249862\n## \n## [[4]]\n## [1] 3.910133 3.967619 5.887672 5.642442 5.187803\n## \n## [[5]]\n## [1] 6.837955 6.564273 5.149130 1.021297 6.239651\n</code></pre>","tags":["tidyverse","R"]},{"location":"writing/2018/09/01/hola-map-chau-apply/#consistencia-entre-variantes","title":"Consistencia entre variantes","text":"<p>Por ahora solo vimos la versi\u00f3n de lapply en MAP, pero esta familia tiene varios integrantes.</p>","tags":["tidyverse","R"]},{"location":"writing/2018/09/01/hola-map-chau-apply/#map_if","title":"map_if","text":"<p>Ejecuta la funci\u00f3n solo si el elemento cumple determinada condici\u00f3n. Devuelve una lista.</p> <pre><code>l2 &lt;- list(a = 213, b = \"string\", c = c(1,2))\nmap_if(l2, is.numeric, function(x) x*2)\n</code></pre> <p><pre><code>## $a\n## [1] 426\n## \n## $b\n## [1] \"string\"\n## \n## $c\n## [1] 2 4\n</code></pre> El output es la lista original con los elementos correspondientes transformados. Vemos que no hubo ning\u00fan problema con \"string\" ya que fue omitido.</p>","tags":["tidyverse","R"]},{"location":"writing/2018/09/01/hola-map-chau-apply/#map_at","title":"map_at","text":"<p>Ejecuta la funci\u00f3n solo en los elementos que seleccionemos. No hace falta que cumplan alguna condici\u00f3n. Misma funci\u00f3n de antes pero solo aplicada al tercer elemento. Devuelve una lista.</p> <pre><code>map_at(l2, c(3), function(x) x*2)\n</code></pre> <pre><code>## $a\n## [1] 213\n## \n## $b\n## [1] \"string\"\n## \n## $c\n## [1] 2 4\n</code></pre> <p>Variantes s\u00faper \u00fatiles que permiten no utilizar loops y que dan mucho control de manera sencilla sobre las funciones a ejecutar. Por otra parte, en t\u00e9rminos de consistencia, la estructura es siempre la misma. El primer argumento es x= y luego viene la funci\u00f3n a aplicar. En el caso de map_if y map_at entre medio surge el condicionante. Si recuerdan, la familia apply cambia el orden de los inputs seg\u00fan si es apply, lapply, mapply, sapply...</p>","tags":["tidyverse","R"]},{"location":"writing/2018/09/01/hola-map-chau-apply/#flexibilidad-del-output","title":"Flexibilidad del output","text":"<p>Por el momento vimos que todos los outputs eran listas. Lo interesante es que podemos controlar eso y cambiar el formato del resultado, ahorr\u00e1ndonos conversiones molestas con unlist y etc.</p> <pre><code>l3 &lt;- list(c(1,2,4), c(100,200), c(5000,6000))\nmap_dbl(l3, max)\n</code></pre> <pre><code>## [1]    4  200 6000\n</code></pre> <p>Nos devuelve un vector con los resultados de aplicar la funci\u00f3n max a cada elemento!</p> <p>De este mismo tipo esta.</p> <ul> <li>map_chr # vector caracter</li> <li>map_int # vector de integers</li> <li>map_lgl # vector de booleanos</li> </ul>","tags":["tidyverse","R"]},{"location":"writing/2018/10/07/como-crear-un-blog-con-blogdown-y-netlify/","title":"Como crear un blog con Blogdown y Netlify","text":"<p>En este post vamos a ver el proceso reusmido para crear un blog donde podemos generar contenido directamente desde RStudio, utilizando el paquete blogdown, Github y Netlify. La idea es que al finalizar la configuraci\u00f3n, simplemente creemos el post en Rstudio (un markdown) usando blogdown y que al subirlo a github automaticamente se actualice el blog y se vea reflejado en nuestra p\u00e1gina. Es lo que estoy haciendo en este momento.</p> <p>Lo primero y m\u00e1s importante m\u00e1s all\u00e1 de este tema en particular es tener una cuenta en github. Si no la tienen se los recomiendo ampliamente para hacer version control - actualizar c\u00f3digo de forma segura y con backups constantes en un servidor + compartir proyectos. Es gratis, al menos la versi\u00f3n b\u00e1sica que alcanza y sobra para el uso cotidiano.  En nuestro repositorio crearemos un proyecto para el blog y ahi se subir\u00e1n nuestros posts en formato html. A su vez, estar\u00e1 el theme y otras configuraciones b\u00e1sicas del blog.  </p> <p>Lo segundo es instalar el paquete blogdown en nuestro R. Es una obra maestra de Yihui Xie, ingeniero de RStudio y creador de varios paquetes. En un nuevo proyecto de R, ejecutan el siguiente comando.</p> <pre><code>blogdown::new_site()\n</code></pre> <p>Con eso ya tienen generado la estructura b\u00e1sica de lo que ser\u00e1 su blog. Se crear\u00e1n carpetas y archivos en la ruta del proyecto con contenido de prueba para tener algo funcional. Blogdown es bastante complejo y hay un mill\u00f3n de configuraciones y detalles que uno puede personalizar. No entraremos en eso ac\u00e1 porque se har\u00eda super extenso. Para eso est\u00e1 la documentaci\u00f3n oficial en ingles.</p> <p>Eventualmente van a tener que cambiar el archivo config.toml con ciertos pasos de la gu\u00eda y luego podr\u00e1n explorar todas las posibilidades que presenta. Entre ellas pueden (y recomiendo) descargar otro theme para cambiar el formato. El que uso actualmente es tranquilpeak.</p> <p>Para crear un post nuevo simplemente escriben el comando.</p> <pre><code>blogdown::new_post()\n</code></pre> <p>Lo cual genera un script con un YAML, que es la configuraci\u00f3n con el t\u00edtulo, tags y otros metadatos del post. Simplemente escriben como cualquier markdown debajo. Cuando terminan el post (o mientras para ir visualizando como queda) corren </p> <p><pre><code>blogdown::serve_site()\n</code></pre> Lo cual generar\u00e1 el archivo html correspondiente que luego ser\u00e1 usado en su web y les permite ver el resultado temporal de su post.</p> <p>Luego lo que deben hacer es pushear  la carpeta que se les gener\u00f3 del blog a su repositorio en github. O al menos las carpetas y archivos que se ven en la siguiente imagen. Public no la pusheen.</p> <p></p> <p>Llegado a este punto tenemos el contenido inicial del blog, pero no hay sitio web. Ah\u00ed es donde entra en juego Netlify. No vamos a entrar en el paso a paso minucioso pero b\u00e1sicamente deben crearse una cuenta, generar una nueva web y linkearla a su repositorio Github. Es bastante lineal. Luego configuran el nombre de la web y otros detalles y en cuesti\u00f3n de minutos ya est\u00e1n publicados! (Y Gratis.) Para ver bien esta etapa les recomiendo la explicaci\u00f3n del link de blogdown.</p> <p>Una vez puesto en marcha solo es cuesti\u00f3n de abrir su proyecto en R (en su pc), crear un nuevo post con blogdown::new_post() y pushear a github! Prueben chusmeando todas las configuraciones para cambiar la est\u00e9tica del blog!</p>","tags":["blogdown","blog","netlify"]},{"location":"writing/2018/10/28/curvas-roc/","title":"Curvas ROC","text":"<p>La curva ROC y AUC (area bajo la curva) permiten evaluar la eficacia de un modelo clasificador y elegir el mejor umbral de corte donde determinar qu\u00e9 observaci\u00f3n es predicha positiva y cual negativa.</p> <p>Vamos a generar rapidamente un clasificador con regresi\u00f3n log\u00edsitca utilizando el dataset mtcars ya provisto por R. Solo a modo ilustrativo utilizaremos AM (caja manual o autom\u00e1tica) como la variable a predecir y mpg y drat como independientes. No separamos en train y test dadas las pocas observaciones.</p> <pre><code>library(tidyverse)\nlibrary(modelr)\nlibrary(pROC)\ndf &lt;- mtcars %&gt;% select(am, mpg, drat) %&gt;% mutate(am = as.factor(am))\nsummary(df)\n</code></pre> <pre><code>##  am          mpg             drat      \n##  0:19   Min.   :10.40   Min.   :2.760  \n##  1:13   1st Qu.:15.43   1st Qu.:3.080  \n##         Median :19.20   Median :3.695  \n##         Mean   :20.09   Mean   :3.597  \n##         3rd Qu.:22.80   3rd Qu.:3.920  \n##         Max.   :33.90   Max.   :4.930\n</code></pre> <pre><code># Clase dentro de todo balanceada\n\nmdl.log &lt;- glm(formula = am ~., data = df, family = binomial(link=\"logit\"))\nfit &lt;- predict(mdl.log, newdata = df, type = \"response\")\n\n\nroc(df[,1],  fit , percent=F,   boot.n=1000, ci.alpha=0.9, stratified=FALSE, plot=TRUE, grid=TRUE, show.thres=TRUE, legacy.axes = TRUE, reuse.auc = TRUE,\n    # print.thres = c(0.30,0.35, 0.40, 0.45,0.48, 0.50,0.55, 0.60),#\n    print.auc = TRUE, print.thres.col = \"blue\", ci=TRUE, ci.type=\"bars\", print.thres.cex = 0.7, main = paste(\"ROC curve using\",\"(N = \",nrow(df),\")\") )\n</code></pre> <p></p> <pre><code>## \n## Call:\n## roc.default(response = df[, 1], predictor = fit, percent = F,     ci = TRUE, plot = TRUE, boot.n = 1000, ci.alpha = 0.9, stratified = FALSE,     grid = TRUE, show.thres = TRUE, legacy.axes = TRUE, reuse.auc = TRUE,     print.auc = TRUE, print.thres.col = \"blue\", ci.type = \"bars\",     print.thres.cex = 0.7, main = paste(\"ROC curve using\", \"(N = \",         nrow(df), \")\"))\n## \n## Data: fit in 19 controls (df[, 1] 0) &lt; 13 cases (df[, 1] 1).\n## Area under the curve: 0.9433\n## 95% CI: 0.8695-1 (DeLong)\n</code></pre> <p>B\u00e1sicamente entrenamos un modelo log\u00edstico y graficamos la curva ROC prediciendo sobre el mismo dataset con el que fue entrenado. No es lo adecuado pero dadas las pocas observaciones y el prop\u00f3sito explicativo no lo tomamos como un problema. La curva ROC es la m\u00e1s oscura y como vemos empieza en (0,0) y termina en el (1,1). El eje X es 1 - Especificidad (Falsos Negativos) y el eje Y es Sensitividad (Verdaderos Positivos) por lo tanto lo deseable es estar lo m\u00e1s arriba a la izquierda posible. El punto (0,1) ser\u00eda \u00f3ptimo ya que habr\u00eda 0 falsos negativos y 100% de verdaderos positivos.</p> <p>Lo que representa la curva es la combinaci\u00f3n de Sensitividad y (1 - especificidad) para varios puntos de corte. Recordemos que la regresi\u00f3n log\u00edstica devuelve un valor entre 0 y 1 por lo tanto hay que determinar en qu\u00e9 valor empezamos a considerar una predicci\u00f3n como positiva o negativa. En este caso positivo ser\u00eda tener un valor de 1 en am, por lo tanto tener caja autom\u00e1tica. Cada punto de la curva corresponde a alg\u00fan punto de corte. Como dec\u00edamos antes, el mejor deber\u00eda ser el m\u00e1s \"arriba a la izquierda\" aunque depende el problema eso puede cambiar, dependiendo del costo de equivocarse en uno u otro sentido.</p> <p>El peor escenario es que la curva siga a la diagonal, lo que equivaldr\u00eda a ser iguales a un modelo eligiendo siempre la clase mayoritaria, totalmente in\u00fatil. Si estuviera por debajo de la diagonal, ser\u00eda peor a\u00fan, pero bastar\u00eda con invertir las predicciones para pasar a estar por encima. Un viejo truco no muy cient\u00edfico.</p> <p>El \u00e1rea bajo la curva (AUC) es una medida resumen de la curva ROC ya que justamente describe el \u00e1rea entre la curva ROC y la diagonal. Valores mayores se corresponden con curvas ROC m\u00e1s alejadas de la diagonal y por lo tanto que separan mejor a la clase dependiente. Es \u00fatil para comparar modelos.</p>","tags":["R","estadistica"]},{"location":"writing/2018/11/03/organizacion-de-proyectos/","title":"Organizaci\u00f3n de Proyectos","text":"<p>Este va a ser un breve post sobre c\u00f3mo organizar los proyectos que hagan en R. Es al d\u00eda de hoy la que utilizo y si googlean van a ver que existe y es usada en el \u00e1mbito. Puede ser esta tal cual o alguna alternativa similar.</p> <p>El enfoque es muy sencillo e intuitivo. La idea es tener por separado cada componente del proyecto y de manera clara y segmentada para poder acceder r\u00e1pidamente a lo necesario, ya sea c\u00f3digo, datos, outputs, etc.</p> <p>Primero y principal. CREEN UN PROYECTO en R. Esto va a facilitar todo el manejo de rutas, llamados a otros c\u00f3digos y mismo para compartir si es necesario con otra gente ya que las rutas que utilicemos ser\u00e1n relativas a la ubicaci\u00f3n en Disco del proyecto. Por lo tanto si el proyecto est\u00e1 creado en C:\\ProyectoR y en alg\u00fan codigo llamamos a <code>read.csv(\"/Datos/datos.csv\")</code> esto funcionar\u00e1 en cualquier computadora donde el proyecto tenga en su directorio una carpeta \"Datos\", independientemente de la ruta donde se encuentre. Yo puedo mover toda la carpeta del proyecto a C:\\OtraRuta y ejecutar ah\u00ed el read.csv sin tener que actualizar la ruta. Es uno de los problemas m\u00e1s b\u00e1sicos y molestos al trabajar con c\u00f3digos ajenos o mover nuestros proyectos de lugar.</p>","tags":["R"]},{"location":"writing/2018/11/03/organizacion-de-proyectos/#carpetas","title":"Carpetas","text":"<p>Una vez creado el proyecto, lo que sugerimos es crear una estructura de carpetas como la que se ve en la imagen siguiente.</p> <p></p> <p>DATA</p> <p>Contiene la data que ser\u00e1 el input de nuestros proyecto. A su vez podemos guardar archivos intermedios que hayamos ido procesando. Pueden adaptarlo como prefieran pero sugerimos guardar en \"raw\",la data que ser\u00e1 input del an\u00e1lisis, ya sean csvs, txts, htmls, etc. En \"working\"\" ir guardando objetos importantes o que lleven tiempo de procesar asi se pueden leer directamente en vez de tener que correr el c\u00f3digo nuevamente en una pr\u00f3xima sesi\u00f3n. Para ellos se usa el comando <code>saveRDS()</code>. En \"final\" guardar los objetos finales del an\u00e1lisis.</p> <p></p> <p>DOCS </p> <p>Ac\u00e1 guardamos archivos auxiliares \u00fatiles como diccionarios de variables, links a webs, consignas, documentaci\u00f3n, etc.</p> <p>OUTPUT</p> <p>Ac\u00e1 exportamos los resultados del an\u00e1lisis, desde gr\u00e1ficos que vayamos a usar en el reporte, el informe final que hagamos (PDF, HTML,etc), las conclusiones que saquemos, etc. Dependiendo de la complejidad del proyecto puede separar en carpetas al interior si hay outputs muy variados.</p> <p>SRC</p> <p>Carpeta para todo nuestro c\u00f3digo. Algunos eligen no usarla y dejar los c\u00f3digos en la ruta del proyecto pero me parece un poco desprolijo. Recomendamos tener muchos scripts con t\u00edtulos claros y segmentados por lo que hacen. Es decir, uno para levantar la data, otro para an\u00e1lisis exploratorio, otro para feature engineering y as\u00ed. A su vez, recomendamos tener un script propio para la funciones que definan ustedes y si les resulta c\u00f3modo otro para las librer\u00edas, de manera tal de tener todo claro, separado y no tener que andar buscando dentro de un gr\u00e1n c\u00f3digo lo que necesitan. Adem\u00e1s es m\u00e1s sencillo para modificar y arreglar bugs. Recuerden que para invocar c\u00f3digo de otro script simplemente lo corren usando <code>source(\"Script.R\")</code>. Dejamos un ejemplo ilustrativo.</p> <p></p>","tags":["R"]},{"location":"writing/2018/11/03/organizacion-de-proyectos/#github","title":"GITHUB","text":"<p>En alg\u00fan otro post lo dijimos pero recomendamos altamente UTILIZAR GITHUB para manejar sus proyectos, tener backups, compartirlos y actualizarlos desde cualquier computadora! Y hacer blogs como este siguiendo este POST</p> <p>Lo que tambi\u00e9n sugerimos es no subir la carpeta data a github por dos motivos. Primero por una cuesti\u00f3n de espacio, si tienen data muy pesada Github no les va a permitir incluirla en el repositorio. Por otra parte si la data es confidencial o tiene datos privados mejor que no est\u00e9 a disposici\u00f3n de cualquiera si tienen cuenta p\u00fablica. Obviamente queda a criterio y comodidad de cada uno si corresponde subir la data o no. Para evitar que una carpeta sea subida a github solo deben incluirla en el archivo .gitignore de su repositorio.</p>","tags":["R"]},{"location":"writing/2018/11/10/como-correr-un-proyecto-con-r-en-google-cloud/","title":"Como correr un proyecto con R en Google Cloud","text":"<p>Hay situaciones en que nuestras computadoras no alcanzan para correr ciertos algoritmos por la cantidad de memoria o n\u00facleos que tenemos (y comprar otra no es una opci\u00f3n..). Una soluci\u00f3n es correr nuestro proyecto en \"la nube\", es decir en servidores ajenos mantenidos por empresas. Los servicios de esta \u00edndole m\u00e1s conocidos son:</p> <ul> <li>Google Cloud</li> <li>Amazon AWS</li> <li>Microsoft Azure</li> </ul> <p>En este post usaremos el primero. Como es de esperar, estos servicios son pagos y si su negocio lo amerita son una gran opci\u00f3n. Igualmente Google Cloud ofrece U$S300 de regalo al crear una cuenta por lo que podr\u00edan hacer uso para alg\u00fan proyecto o pruebas. Les aseguro que no es particularmente bajo el monto. Solo tienen que registrarse y asociar una tarjeta de cr\u00e9dito y no abonar nada.</p> <p>Google Cloud ofrece un mont\u00f3n de servicios y opciones de las cuales presentaremos lo m\u00e1s b\u00e1sico pero igualmente suficiente para correr un xgboost en gigas y gigas de datos con cientos de variables je. </p> <ol> <li>Crear una m\u00e1quina virtual instalando R</li> <li>Crear un Bucket que sirve como Disco duro para guardar data, outputs, etc</li> <li>Correr un algoritmo</li> </ol>","tags":["R","Cloud"]},{"location":"writing/2018/11/10/como-correr-un-proyecto-con-r-en-google-cloud/#maquina-virtual","title":"M\u00e1quina Virtual","text":"<p>Una vez registrados, lo primero que vamos a hacer es crear la m\u00e1quina virtual e instalar R y ciertos paquetes. Lamentablemente el proceso es bastante engorroso para quienes no conocen bash ni est\u00e1n familiarizados con Cloud. Es todo por consola y para nada intuitivo sin leer la documentaci\u00f3n, que est\u00e1 en ingl\u00e9s. Es un proceso largo y la documentaci\u00f3n m\u00e1s clara que encontr\u00e9 se encuentra en este BLOG.  No tiene sentido intentar decir lo mismo que \u00e9l pero peor. Les recomiendo seguirlo y van a obtener una m\u00e1quina virtual con Rstudio instalado y ciertas dependencias \u00fatiles para la mayor\u00eda de las librer\u00edas que se usan.</p>","tags":["R","Cloud"]},{"location":"writing/2018/11/10/como-correr-un-proyecto-con-r-en-google-cloud/#crear-bucket","title":"Crear Bucket","text":"<p>Ir a   Clickear los 3 puntos a la derecha y entrar a \"Create key\"</p> <p>Se les descargar\u00e1 un archivo .json que deben renombrar a ** privatekey_inicial.json ** . Luego ir a: </p> <p>Crear un bucket cuyo nombre no tenga espacios ni caracteres raros. Va a pedirles que sea un nombre que no est\u00e9 siendo usado por nadie m\u00e1s.  Hecho esto el bucket est\u00e1 creado y se le pueden subir archivos. Luego desde los scripts tambi\u00e9n se le van a poder escribir directamente, es decir, guardar los outputs. Ahora vamos a cambiar los permisos del bucket. Copiarse el account id desde aqu\u00ed. </p> <p>Luego ir a storage y en los 3 puntitos de nuesto bucket clickear \"Edit Bucket permissions\" y pegar el ID. </p>","tags":["R","Cloud"]},{"location":"writing/2018/11/10/como-correr-un-proyecto-con-r-en-google-cloud/#crear-imagen","title":"Crear Imagen","text":"<p>Lo que haremos ahora es crear una imagen de la maquina virtual que generamos (donde instalamos R) para poder levantar futuras m\u00e1quinas y que directamente tengan instalado R y los paquetes si lo deseamos (invocando a esta imagen). Dejo im\u00e1genes de un tutorial que van a ser m\u00e1s claras que yo.</p> <p></p> <p></p> <p></p> <p>Luego ir a Compute Engine \u2192 Images</p> <p></p>","tags":["R","Cloud"]},{"location":"writing/2018/11/10/como-correr-un-proyecto-con-r-en-google-cloud/#status","title":"Status","text":"<p>Resumiendo brevemente:</p> <ul> <li>Tenemos una cuenta y U$S 300 disponibles.</li> <li>Creamos una VM con R y paquetes.</li> <li>Generamos una imagen de esa VM para poder retutilizarla.</li> <li>Creamos un bucket donde almacenar inputs y outputs, linkeado a la imagen.</li> </ul> <p>Estamos casi listos. Falta correr algun script!</p>","tags":["R","Cloud"]},{"location":"writing/2018/11/10/como-correr-un-proyecto-con-r-en-google-cloud/#como-correr-un-script-de-r","title":"C\u00f3mo correr un script de R.","text":"<p>Una vez seteado todo lo anterior (y asegur\u00e1ndonos de haber apagado la maquina virtual utilizada) lo que debemos hacer es crear otras VM (instance) con los n\u00facleos y Ram que cremos convenientes - esto depende totalmente de la complejidad del algoritmo que vayan a correr-, asignando una regi\u00f3n donde preferentemente sea de noche o fin de semana para que est\u00e9 menos saturada. Lo m\u00e1s importante es cambiar el boot disk y seleccionar dentro de \"custom\" la imagen que hayamos generado con R. De esta manera la VM que iniciemos ya tendr\u00e1 R, Rstudio y librer\u00edas instaladas.</p> <p></p> <p>Justo debajo de lo que se ve en la imagen hay opciones extras de \"Management, security, disks\", etc. Depende la importancia de lo que est\u00e9n haciendo puede ser bueno asegurarse que la opci\u00f3n Preemptibility est\u00e9 OFF. Si est\u00e1 ON, la VM se correr\u00e1 en un servidor que m\u00e1ximo puede durar 24hs (posterior a eso se apaga autom\u00e1ticamente la VM) y m\u00e1s importante a\u00fan, est\u00e1n sujetos a disponibilidad de Google, es decir que si hay mucha demanda de servidores pueden apagarles el suyo sin consultar. Lo positivo es que son mucho m\u00e1s baratas. Al tenerlo OFF, se aseguran que su VM estar\u00e1 encendida durante todo lo que tarde el script en correr y no va a depender de la demanda. Queda a criterio de cada uno.</p> <p>Ya estamos listos para correr. Hay dos maneras sencillas:</p> <ol> <li>Directo desde Rstudio en la VM.</li> </ol> <p>Haciendo click en el IP de su instancia. Se abrir\u00e1 Rstudio y deber\u00e1n poner Usuario y Contrase\u00f1a seteados durante la instalaci\u00f3n. Ahi pueden trabajar como si fuera directamente R. Recomiendo tener Script listo porque no es muy din\u00e1mico trabajar en vivo ah\u00ed.</p> <p></p> <ol> <li>Desde la terminal, llamando a script en el bucket.</li> </ol> <p>Otra opci\u00f3n es subir su script al bucket que generaron y en Rstudio (como en 1.) ir a la terminal y correr:</p> <pre><code>Rscipt --vanilla ~/cloud/cloud1/pathToScript/script.r\n</code></pre> <p>O desde la consola (que basicamente system() simular ser la temrinal) :</p> <pre><code>system(Rscipt --vanilla ~/cloud/cloud1/pathToScript/script.r)\n</code></pre> <ol> <li>Desde la terminal de la instancia.</li> </ol> <p></p> <p>Y ah\u00ed deber\u00edan poder correr sin problema.</p> <pre><code>Rscipt --vanilla ~/cloud/cloud1/pathToScript/script.r\n</code></pre> <p>En cualquiera de los 3 casos presten atenci\u00f3n a las rutas que usan en sus scripts para referenciar al bucket. Si linkearon el bucket a la imagen de la VM como vimos en el post deber\u00edan poder usar la siguiente ruta gen\u00e9rica.</p> <pre><code>\"~/cloud/cloud1/RestoDelPath/\"\n</code></pre> <p>Y eso es todo. Ya pueden levantar una VM en google cloud y correr algoritmos con gigas y gigas de data sin quemar su PC! </p>","tags":["R","Cloud"]},{"location":"writing/2019/03/30/introduccion-a-graficos-con-mapas/","title":"Introduccion a graficos con mapas","text":"","tags":["GIS","mapas","R","tidyverse"]},{"location":"writing/2019/03/30/introduccion-a-graficos-con-mapas/#data","title":"Data","text":"<p>Vamos a ver un ejemplo sencillo para representar informaci\u00f3n visualmente sobre mapas. En este caso un peque\u00f1o dataset de incendios forestales en Argentina de 2012 a 2015. La idea es usar ggplot y mantener el enfoque de gr\u00e1ficos por capas.</p> <p>Vamos a necesitar.</p> <p><pre><code>&gt; tidyverse\n&gt; rgdal\n&gt; rgeos\n</code></pre> Tendremos como input las provincias, departamento, cantidad de focos por incendio, area afectada y a\u00f1o de inicio y fin. Cada observaci\u00f3n es un incendio.</p> <p>Para este ejemplo nos vamos a centrar en las provincias, los focos y su efecto sin importar la fecha.</p> <p>Empezamos cargando la data.</p> <pre><code>library(tidyverse)\n# Load Raw data\nraw &lt;- read.csv(\"../../static/post/2019-03-30-introduccion-a-graficos-en-mapas/focosincendio.csv\", sep = \";\")\nraw &lt;- as.tibble(raw)\n</code></pre> <pre><code>## Warning: `as.tibble()` was deprecated in tibble 2.0.0.\n## i Please use `as_tibble()` instead.\n## i The signature and semantics have changed, see `?as_tibble`.\n</code></pre> <pre><code>glimpse(raw)\n</code></pre> <pre><code>## Rows: 120\n## Columns: 11\n## $ pais_id         &lt;int&gt; 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,~\n## $ pais            &lt;chr&gt; \"Argentina\", \"Argentina\", \"Argentina\", \"Argentina\", \"Argentina\", \"Argentina\", \"Argentina\", \"Argentina\", \"Argentina\", \"Argentina~\n## $ provincia_id    &lt;int&gt; 6, 14, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 30, 30, 30, 30, 30, 30, 30, 30, 30, ~\n## $ provincia       &lt;chr&gt; \"Buenos Aires\", \"C\u00f3rdoba\", \"Corrientes\", \"Corrientes\", \"Corrientes\", \"Corrientes\", \"Corrientes\", \"Corrientes\", \"Corrientes\", \"C~\n## $ departamento_id &lt;int&gt; 833, 14, 56, 28, 28, 28, 70, 84, 84, 84, 112, 112, 119, 119, 126, 147, 154, 154, 161, 168, 168, 168, 168, 8, 15, 15, 15, 15, 28~\n## $ departamento    &lt;chr&gt; \"Tres Arroyos\", \"Calamuchita\", \"General Alvear\", \"Concepci\u00f3n\", \"Concepci\u00f3n\", \"Concepci\u00f3n\", \"Goya\", \"Itizaing\u00f3\", \"Ituzaingo\", \"I~\n## $ sup_afectada    &lt;dbl&gt; 2400.00, 50.00, 257.00, 130.00, 5.00, 146.00, 30.00, 294.30, 378.00, 158.00, 300.00, 450.00, 450.00, 15.00, 20.00, 141.00, 295.~\n## $ uni_med_id      &lt;chr&gt; \"ha\", \"ha\", \"ha\", \"ha\", \"ha\", \"ha\", \"ha\", \"ha\", \"ha\", \"ha\", \"ha\", \"ha\", \"ha\", \"ha\", \"ha\", \"ha\", \"ha\", \"ha\", \"ha\", \"ha\", \"ha\", \"~\n## $ cant_focos      &lt;int&gt; 1, 1, 1, 2, 1, 1, 1, 3, 1, 3, 1, 1, 5, 2, 2, 1, 3, 1, 1, 18, 2, 3, 2, 1, 0, 0, 1, 7, 0, 2, 1, 0, 0, 0, 5, 10, 10, 3, 1, 1, 1, 1~\n## $ a\u00f1o_inicial     &lt;int&gt; 2014, 2015, 2012, 2012, 2013, 2015, 2012, 2012, 2013, 2014, 2012, 2013, 2012, 2013, 2015, 2012, 2012, 2014, 2012, 2012, 2013, 2~\n## $ a\u00f1o_final       &lt;int&gt; 2014, 2015, 2012, 2012, 2013, 2015, 2012, 2012, 2013, 2014, 2012, 2013, 2012, 2013, 2015, 2012, 2012, 2014, 2012, 2012, 2013, 2~\n</code></pre> <p>Exploramos un poco el dataset. Lo que nos vas a interesar represetnar es la segunda parte del c\u00f3digo. Variables agregadas a nivel provincia.</p> <pre><code># Generate Summary to Explore\nsum_year &lt;- raw %&gt;% group_by(a\u00f1o_inicial) %&gt;%\n  summarise(focos = sum(cant_focos), sup = sum(sup_afectada, na.rm = TRUE)) %&gt;%\n  mutate(sup_prom = sup/focos)\n\n# Actual data to be plotted\nsum_prov &lt;- raw %&gt;% group_by(provincia) %&gt;%\n  summarise(focos = sum(cant_focos), sup = sum(sup_afectada, na.rm = TRUE)) %&gt;%\n  mutate(sup_prom = sup/focos) %&gt;%\n  arrange(desc(sup_prom)) %&gt;%\n  mutate(provincia = as.character(provincia))\n\nhead(sum_prov)\n</code></pre> <pre><code>## # A tibble: 6 x 4\n##   provincia    focos   sup sup_prom\n##   &lt;chr&gt;        &lt;int&gt; &lt;dbl&gt;    &lt;dbl&gt;\n## 1 Buenos Aires     1 2400    2400  \n## 2 Corrientes      55 5440.     98.9\n## 3 Misiones        10  679      67.9\n## 4 C\u00f3rdoba          1   50      50  \n## 5 Entre R\u00edos      12  594      49.5\n## 6 Jujuy           62 2721.     43.9\n</code></pre> <p>Tenemos por provincia la cantidad de focos y la superficie  afectada. Vamos a usar la superficie promedio por foco para visualizar la magnitud de cada foco de incendio.</p> <p>Ahora llega lo importante. \u00bfC\u00f3mo representar esta data provincial en un mapa de Argentina?</p>","tags":["GIS","mapas","R","tidyverse"]},{"location":"writing/2019/03/30/introduccion-a-graficos-con-mapas/#mapa","title":"Mapa","text":"<p>Necesitamos un ShapeFile de Argentina, que basicamente es el tipo de archivo que se usa para representar mapas en gr\u00e1ficos. Contiene divisiones del pa\u00eds (provincias) con sus respectivas coordenadas y nombres.</p> <p>Utilizaremos data descargada del siguiente link. url &lt;- \"http://biogeo.ucdavis.edu/data/diva/adm/ARG_adm.zip\"</p> <p>Lo descargu\u00e9 y deszipee en la computadora. Lo leemos con una librer\u00eda particular RGDAL.</p> <p>dsn contiene la ruta a la carpeta con los archivos del shapefile. Layer apunta a al set de archivos que contiene la data que queremos. Generalmente hay otros sets con informaci\u00f3n no relevante al gr\u00e1fico.</p> <pre><code>argentina &lt;- rgdal::readOGR(dsn = \"../../static/post/2019-03-30-introduccion-a-graficos-en-mapas/ARG_adm\", layer = \"ARG_adm1\", use_iconv=TRUE, encoding='UTF-8')\n</code></pre> <pre><code>## OGR data source with driver: ESRI Shapefile \n## Source: \"D:\\DataScience\\StatsBlog\\blogStats\\static\\post\\2019-03-30-introduccion-a-graficos-en-mapas\\ARG_adm\", layer: \"ARG_adm1\"\n## with 24 features\n## It has 9 fields\n## Integer64 fields read as strings:  ID_0 ID_1\n</code></pre> <p>Es un archivo S4 por lo que se utiliza \"@\" para acceder a su contenido. Por ejemplo:</p> <pre><code>head(argentina@data)\n</code></pre> <pre><code>##   ID_0 ISO    NAME_0 ID_1                 NAME_1           TYPE_1        ENGTYPE_1 NL_NAME_1\n## 0   12 ARG Argentina    1           Buenos Aires        Provincia         Province      &lt;NA&gt;\n## 1   12 ARG Argentina    2                C\u00f3rdoba        Provincia         Province      &lt;NA&gt;\n## 2   12 ARG Argentina    3              Catamarca        Provincia         Province      &lt;NA&gt;\n## 3   12 ARG Argentina    4                  Chaco        Provincia         Province      &lt;NA&gt;\n## 4   12 ARG Argentina    5                 Chubut        Provincia         Province      &lt;NA&gt;\n## 5   12 ARG Argentina    6 Ciudad de Buenos Aires Distrito Federal Federal District      &lt;NA&gt;\n##                                                                               VARNAME_1\n## 0                                                                   Baires|Buenos Ayres\n## 1                                                                               Cordova\n## 2                                                                                  &lt;NA&gt;\n## 3                                                        El Chaco|Presidente Juan Peron\n## 4                                                                                  &lt;NA&gt;\n## 5 BUENOS AIRES D.F.|Capital Federal|Distretto Federale|Distrito Federal|Federal Capital\n</code></pre> <p>Este tipo de archivos tiene una estructura complicada y hay varias librer\u00edas \u00fatiles. Con el fin de mantenernos dentro del tidyverse usaremos el enfoque de ggplot por capaz para graficar. Primero necesitamos llevar la informaci\u00f3n del shapefile a un dataframe.</p> <pre><code># Transformo a dataframe.\nargentina_df &lt;- broom::tidy(argentina)\n</code></pre> <pre><code>## Regions defined for each Polygons\n</code></pre> <pre><code># id es la provincia\nhead(argentina_df)\n</code></pre> <pre><code>## # A tibble: 6 x 7\n##    long   lat order hole  piece group id   \n##   &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;lgl&gt; &lt;fct&gt; &lt;fct&gt; &lt;chr&gt;\n## 1 -60.2 -33.3     1 FALSE 1     0.1   0    \n## 2 -60.2 -33.3     2 FALSE 1     0.1   0    \n## 3 -60.2 -33.3     3 FALSE 1     0.1   0    \n## 4 -60.2 -33.3     4 FALSE 1     0.1   0    \n## 5 -60.2 -33.3     5 FALSE 1     0.1   0    \n## 6 -60.2 -33.3     6 FALSE 1     0.1   0\n</code></pre> <p>Ahora genero un diccionario de ids con su respectiva provincia para poder linkear mi mapa con la data de incendios.</p> <pre><code>ids &lt;- cbind.data.frame(provincia = as.character(argentina@data$NAME_1), id = as.character(rownames(argentina@data))) %&gt;%\n  mutate(provincia = as.character(provincia), id = as.character(id))\n</code></pre> <p>El dataframe generado a partir del shapefile tiene las coordenadas que forman cada provincia y el id. Ahora lo que haremos es pegarle la data de incendios para poder utilizarla sobre el mapa. Est\u00e1 generado el log de los focos porque en una prueba intent\u00e9 usar la data transformada para suavizar outliers pero no se ver\u00e1 en esta versi\u00f3n.</p> <pre><code># Agrego provincia por ID y data de incendios a la data del shapefile.\nargentina_df2 &lt;- argentina_df %&gt;% left_join(ids, by = \"id\") %&gt;%\n  left_join(sum_prov, by = \"provincia\") %&gt;%\n  mutate(focos = ifelse(is.na(focos),0.5,focos),\n         logfocos = log(focos), \n         logfocos2 = logfocos - min(logfocos))\n</code></pre> <p>Por ahora vamos a poder ser capaces de graficar un mapa de argentina con sus provincias delimitadas y pintarlas seg\u00fan la cantidad de focos de incendio por ejemplo. Pero adem\u00e1s vamos a querer agregar alguna forma sobre cada provincia. Por ejemplo un punto de distinto tama\u00f1o seg\u00fan el area afectada por cada foco en promedio. Para eso necesitamos localizar el centroide de cada poligono, es decir, el centro de cada provincia. Para ellos usamos la librer\u00eda RGEOS Luego a cada centro le agrego la data que voy a querer usar. En este caso la superficie promedio afectada por foco de cada provincia.</p> <pre><code># Calculo el centro de cada poligono (provincias)\n# para obtener el \"centro\" donde iran los puntos o nombres.\ncentros &lt;- rgeos::gCentroid(argentina, byid = TRUE) %&gt;%\n  as.data.frame() %&gt;%\n  mutate(id = rownames(.))\n\n# Agrego data relevante para el ploteo (superficie promedio)\ncentros2 &lt;- centros %&gt;% left_join(ids, by = \"id\") %&gt;%\n  left_join(sum_prov, by = \"provincia\") %&gt;%\n  mutate(focos = ifelse(is.na(focos),0.5,focos),\n         sup = ifelse(is.na(sup),0,sup),\n         log_sup_prom = log(sup_prom),\n         sup_prom_sin_outlier = ifelse(sup_prom &gt; 150, 150,sup_prom) ) # esto es para suavizar el outlier. Buscar otro enfoque.\n</code></pre>","tags":["GIS","mapas","R","tidyverse"]},{"location":"writing/2019/03/30/introduccion-a-graficos-con-mapas/#grafico","title":"Grafico!","text":"<p>Ya tenemos todo. Tenemos el mapa, tenemos la cantidad de focos de incendio por provincia y tenemos el centro de cada provincia donde vamos a incluir un punto que muestra la intensidad de los incendios. Simplemente graficamos sigueindo la l\u00f3gica por capas de ggplot. Las provincias sin puntos son aquellas que no tuvieron ning\u00fan incendio.</p> <pre><code>ggplot() +\n  geom_polygon(data = argentina_df2, aes(x=long, y = lat, group = group,  fill = focos), color = \"white\") + # mapa de argentina\n  # coloreado segun cantidad de focos\n  coord_fixed(0.8) + # tama\u00f1p del mapa\n  scale_fill_gradient2(\"Cantidad de Focos de incendio\", low = \"white\", mid = \"lightgreen\", high = \"darkred\") + # escala de colores para focos\n  geom_point(data = centros2, aes(x = x, y = y, size = sup_prom_sin_outlier)) + # puntos por provincia con superficie promedio\n  scale_size(name = \"Superficie Promedio Afectada (ha)\",range = c(1,5)) + # escala de los puntos\n  guides(fill = guide_legend(order = 1), # Orden de los leyendas a la derecha.\n         size = guide_legend(order = 2)) # Por algun motivo esto discretizo la leyenda de focos\n</code></pre> <p></p>","tags":["GIS","mapas","R","tidyverse"]},{"location":"writing/2019/04/03/funciones-de-probabilidad-y-distribucion/","title":"Funciones de Probabilidad y Distribucion","text":"","tags":["estadistica","R"]},{"location":"writing/2019/04/03/funciones-de-probabilidad-y-distribucion/#variables-aleatorias","title":"Variables Aleatorias","text":"<p>Consideremos un experimento cuyo espacio muestral denominaremos <code>S</code>.  Una funcion valuada en el dominio de los reales definida en <code>S</code> es una variable aleatoria. </p> <p>En otras palabras es una funci\u00f3n que asigna a cada resultado posible de un experimento un valor real.</p> <p>Por ejemplo:</p> <p>Si el experimento es lanzar una moneda 10 veces hay 2<sup>10</sup> combinaciones posibles de caras (o) y cruz (x).  Si definimos la variable aleatoria X como cantidad de caras entonces X(s) ser\u00e1 la cantidad de caras del experimento.  Si s resulta ser la secuencia <code>ooxxxoxxxo</code> entonces X(s) = 4.</p>","tags":["estadistica","R"]},{"location":"writing/2019/04/03/funciones-de-probabilidad-y-distribucion/#distribucion-de-una-variable-aleatoria","title":"Distribucion de una variable aleatoria","text":"<p>Si tenemos la distribuci\u00f3n de probabilidad del espacio muestral del experimento podemos determinar la distribuci\u00f3n de probabilidad de cualquier variable aleatoria v\u00e1lida.</p> <p>Volviendo al ejemplo de la moneda. Dijimos que hay 2<sup>10</sup> combinaciones de cara o cruz. La cantidad de combinaciones de X caras en 10 lanzamientos es \\(P(X = x) = \\binom{n}{x} \\frac{1}{2^{10}}\\)  para \\(x = 0,1,2,..,10\\)</p>","tags":["estadistica","R"]},{"location":"writing/2019/04/03/funciones-de-probabilidad-y-distribucion/#distribuciones-discretas","title":"Distribuciones Discretas","text":"<p>Una variable aleatoria tiene una distribuci\u00f3n discreta si solo puede tomar valores de una secuencia (generalmente finita pero puede no serlo). </p> <ul> <li>La funci\u00f3n de probabilidad le otorga una probabilidad puntual a cada valor de esa secuencia.</li> <li>Los valores por fuera de la secuencia tienen probabilidad  = 0</li> <li>La suma de todas las probabilidades tiene que ser 1</li> </ul>","tags":["estadistica","R"]},{"location":"writing/2019/04/03/funciones-de-probabilidad-y-distribucion/#distribucion-uniforme","title":"Distribuci\u00f3n Uniforme","text":"<p>En el caso de la dsitribuci\u00f3n uniforme, supongamos que la variable puede tomar valores de 1 a k. La funci\u00f3n de probabilidad ser\u00e1 \\(f(x) = \\frac{1}{k}\\) para x = 1,2,...,k.  Y 0 para todos los otros valores.</p> <p>si k = 10 Los valores de la variable ser\u00e1n cualquier entero entre 1 y 10 Cada valor tendr\u00e1 probabilidad \\(\\frac{1}{10}\\)</p>","tags":["estadistica","R"]},{"location":"writing/2019/04/03/funciones-de-probabilidad-y-distribucion/#distribucion-binomial","title":"Distribuci\u00f3n Binomial","text":"<p>En el caso de la dsitribuci\u00f3n binomial se asumen dos posibles resultados, uno con probabilidad p y su contraparte con probabilidad 1-p. Por ejemplo la probabilidad p de que una m\u00e1quina genere un producto defectuoso y 1-p de que sea no defectuoso. Si una m\u00e1quina produce n productos va a generar X productos defectuosos. La variable aleatoria X tendr\u00e1 una distribuci\u00f3n discreta y sus posibles valores ir\u00e1n de 0 a n. Para cualquier valor de x (entre 0 y n), la probabilidad de que la m\u00e1quina genere x productos defectuosos entre los n producidos (de una secuencia particular) es \\(p^{x}q^{(n-x)}\\) Como existen \\(\\binom{n}{x}\\) distintas secuencias posibles con x defectuosos entre los n productos tenemos que: \\(Pr(X = x) = \\binom{n}{x}p^{x}q^{(n-x)}\\) La funci\u00f3n de probabilidad ser\u00e1 \\(f(x) = \\binom{n}{x}p^{x}q^{(n-x)}\\) para x = 0,1,2,...,n.  Y 0 para todos los otros valores.</p> <p>Para usar esta distribuci\u00f3n en R tenemos los siguientes comandos:</p> <ul> <li>Para generar n escenarios al azar donde se producen size productos con probabilidad p de ser defectuosos. El resultado es la variable x por escenario. Es decir la cantidad de defectuosos. En el primer escenario x = 0, en el segundo x = 1 y as\u00ed.</li> </ul> <pre><code>set.seed(1)\nrbinom(n = 10, size = 5, p = 0.2 )\n</code></pre> <pre><code>##  [1] 0 1 1 2 0 2 3 1 1 0\n</code></pre> <pre><code># random binomial\n</code></pre> <ul> <li>Para saber la probabilidad de obtener x productos defectuosos si una m\u00e1quina produce size productos y la probabilidad de que produzca un defectuoso es prob. Hay probabilidad de 0.0264 de obtener 5 defectuosos si producimos 10 con probabilidad 0.2.</li> </ul> <pre><code>dbinom(x = 5, size = 10, prob = 0.2)\n</code></pre> <pre><code>## [1] 0.02642412\n</code></pre> <ul> <li>Para saber la probabilidad acumulada de obtener q o menos productos defectuosos si la m\u00e1quina fabrica size objetos, con probabilidad de defecto prob. Hay probabiliad de 0.879 de obtener 3 o menos defectuosos si la m\u00e1quina produce 10 objetos con probabilidad 0.2 de defecto. Es decir, es la suma de obtener exactamanete 0 defectuosos, m\u00e1s exactamente 1 defectuoso, m\u00e1s exactamnente 2 defectuosos, m\u00e1s exactamente 3 defectuosos.</li> </ul> <pre><code>pbinom(q = 3, size = 10, prob = 0.2)\n</code></pre> <pre><code>## [1] 0.8791261\n</code></pre>","tags":["estadistica","R"]},{"location":"writing/2019/04/03/funciones-de-probabilidad-y-distribucion/#distribuciones-continuas","title":"Distribuciones Continuas","text":"<p>Una variable aleatoria X tiene una distribuci\u00f3n continua si existe una funci\u00f3n <code>f</code> definida en los reales tal que para alg\u00fan intervalo A \\(Pr(X \\in A) = \\int_{A} f(x)\\) </p> <p>La funci\u00f3n <code>f</code> es la funci\u00f3n de densidad de probabilidad. PDF por sus siglas en ingl\u00e9s. La probabilidad de que X tome alg\u00fan valor en un intervalo se encuentra integrando <code>f</code> en ese rango.</p> <p>Por ejemplo para la distribuci\u00f3n uniforme en un intervalo (a,b) podemos ver que su pdf (o funci\u00f3n de densidad de probabilidad) es \\(f(x) = \\begin{cases}\\frac{1}{b-a} &amp; \\text{para } a \\leq x \\leq b \\\\ 0 &amp; \\text{resto}\\\\  \\end{cases}\\)</p>","tags":["estadistica","R"]},{"location":"writing/2019/04/03/funciones-de-probabilidad-y-distribucion/#distribucion-normal","title":"Distribuci\u00f3n Normal","text":"<p>Para la distribuci\u00f3n Normal tenemos los siguientes comandos:  </p> <ul> <li>Para obtener n variables aleatorias provenientes de una normal con media mean y desv\u00edo sd</li> </ul> <pre><code>set.seed(1)\nrnorm(n = 5, mean = 10, sd = 2)\n</code></pre> <pre><code>## [1]  8.747092 10.367287  8.328743 13.190562 10.659016\n</code></pre> <ul> <li>Para obtener el valor de la pdf de la normal para alg\u00fan valor de X en particular. Recuerden que no es una probabilidad, solo es el valor de la funci\u00f3n. Las probabilidad se encuentra integrando la funci\u00f3n en el intervalo deseado. Si grafic\u00e1ramos los valores de dnorm para el intervalo -3,3 obtendr\u00edamos la forma t\u00edpica de la normal.</li> </ul> <pre><code>dnorm(0.5, mean = 0, sd = 1)\n</code></pre> <pre><code>## [1] 0.3520653\n</code></pre> <ul> <li>Para obtener la probabilidad acumulada hasta determinado punto. Tambi\u00e9n conocido como Funci\u00f3n de Distribuci\u00f3n o Funci\u00f3n de Distribuci\u00f3n Acumulada C.D.F. por sus siglas en ingles Por ejemplo, cual es la probabilidad de obtener un valor igual o menos a 1.5 si tomamos una muestra de una normal est\u00e1ndar </li> </ul> <p>\\(N \\sim (0,1)\\)</p> <pre><code>pnorm(q = 1.5, mean = 0, sd = 1)\n</code></pre> <pre><code>## [1] 0.9331928\n</code></pre> <p>Hay 93.31% de chances de obtener un valor inferior a 1.5 si tomamos una muestra al azar de una normal con media 0 y desv\u00edo 1.</p> <ul> <li>La inversa tambi\u00e9n se puede calcular facilmente en R. Que valor debe tomar la variable aleatoria normal si deseo tenes un 93.31% de chances de obtener un valor menor o igual a ese?</li> </ul> <pre><code>qnorm(p = 0.9331, mean = 0, sd = 1)\n</code></pre> <p><pre><code>## [1] 1.499284\n</code></pre> La diferencia respecto al c\u00f3digo anterior es porque redondeamos la probabilidad.</p>","tags":["estadistica","R"]},{"location":"writing/2019/04/20/esencia-del-algebra-lineal/","title":"Esencia del Algebra Lineal","text":"<p>El \u00e1lgebra lineal est\u00e1 por todas partes en estad\u00edstica y data science. Matrices, vectores y transformaciones son t\u00e9rminos que se escuchan seguido y est\u00e1n detr\u00e1s de muchos de los m\u00e9todos y algoritmos que se usan hoy por hoy. Aunque no sea necesario saber del tema para correr un modelo empaquetado en una librer\u00eda de R, es muy \u00fatil entender lo que hacemos realmente ya que nos permite ver a los modelos como algo l\u00f3gico y no una caja negra m\u00e1gica.</p> <p>Hay una serie de videos excelente en ingl\u00e9s que mediante visualizaciones y animaciones permite entender la intuici\u00f3n de muchos de los conceptos b\u00e1sicos, que solo con un libro puede ser medio cr\u00edptico o poco imaginable. Para el que le interese: ESSENCE OF LINEAR ALGEBRA por 3Blue1Brown.</p> <p>Este post, aunque quiz\u00e1s medio desordenado y sin mucha prolijidad, es una recopilaci\u00f3n de algunas notas. Puede que queden t\u00e9rminos en ingl\u00e9s intercalados.</p>","tags":["estadistica","matematica","algebra"]},{"location":"writing/2019/04/20/esencia-del-algebra-lineal/#matrices-y-vectores","title":"Matrices y vectores","text":"<ul> <li>Vector vive en n dimensiones.</li> <li>Suma de vectores es combinaci\u00f3n lineal</li> <li>En \\(R^{2}\\) \\(\\hat \\imath = \\left&lt; 1, 0 \\right&gt; \\text{y} \\hat \\jmath = \\left&lt; 0, 1 \\right&gt;\\) forman una base. Cualquier punto es una combinaci\u00f3n lineal de ellos.     </li> <li>Span es el espacio que pueden generar x vectores. \\(R^{2}\\) es el span de  \\(\\left&lt; 1, 0 \\right&gt; \\left&lt; 0, 1 \\right&gt;\\)</li> <li>Vector puede ser pensado como una flecha desde el origen (0,0) a las coordenadas que lo identifican. O como un punto directo en las coordenadas..</li> <li>Matriz es una transformaci\u00f3n. Lleva un vector a otro punto. Si transformamos cada posible vector de un espacio por la matriz podemos ver como el espacio es transformado. Ej: rotar, invertir, estirar.</li> <li>Si transformamos una base, cada punto nuevo puede generarse transformando la nueva base.  Por ej: \\(z = \\left&lt; 3, 2 \\right&gt; \\text{es } 3\\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix} + 2\\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix} = 3\\hat \\imath + 2\\hat \\jmath\\) Aplicando la transformaci\u00f3n de la matriz A = \\(\\begin{pmatrix} A &amp; B \\\\ C &amp; D \\end{pmatrix} \\text{obtenemos los nuevos vectores base } \\hat \\imath^{*} \\text{y } \\hat \\jmath^{*}\\) \\(z^{*} = 3\\hat \\imath^{*} + 2\\hat \\jmath^{*}\\) </li> <li>Multiplicar 2 matrices es transformar un espacio con la primera matriz ( desde la derecha) y luego transformar el resultado por la segunda matriz. Ej: Rotar un espacio y luego invertirlo.</li> <li>AB != BA -&gt; El orden de las transformaciones importa y se lee de derecha a izquierda.</li> <li> <p>La matriz (transformaci\u00f3n) ya dice como van a ser las nuevas bases. Si la matriz es \\(\\begin{pmatrix} A &amp; B \\\\ C &amp; D \\end{pmatrix}\\), el nuevo \\(\\hat \\imath^{*}\\) es \\(\\begin{bmatrix} A \\\\ C \\end{bmatrix}\\) y \\(\\hat \\jmath^{*}\\) es \\(\\begin{bmatrix} B \\\\ D \\end{bmatrix}\\) Ej: \\(z = \\left&lt; 3, 2 \\right&gt;  z^{*} =  \\begin{bmatrix} A &amp; B \\\\ C &amp; D \\end{bmatrix}\\begin{bmatrix} 3 \\\\ 2 \\end{bmatrix} = \\begin{bmatrix} 3A + 2B \\\\ 3C + 2D \\end{bmatrix}\\) Se puede ver tambi\u00e9n como:  \\(\\(z = 3\\hat \\imath + 2\\hat \\jmath \\text{  }  z^{*} = 3\\hat \\imath^{*} + 2\\hat \\jmath^{*} = 3\\begin{bmatrix} A \\\\ C \\end{bmatrix} + 2\\begin{bmatrix} B \\\\ D \\end{bmatrix} = \\begin{bmatrix} 3A + 2B \\\\ 3C + 2D \\end{bmatrix}\\)\\) </p> </li> <li> <p>!!!. Las transformaciones afectan el area (en R2, el volumen en R3..) de las figuras en el espacio (todas por igual). El DETERMINANTE de una matriz mide ese cambio.</p> </li> <li>Si el determinante es 0 significa que se perdi\u00f3 una dimensi\u00f3n o que todo se comprimi\u00f3. Pasa de \\(R^{2}\\) a una recta (o a un punto!)</li> <li>Si el determinante ** es &lt; 0** significa que el espacio se invirti\u00f3 (en sentido.. como dar vuelta una hoja) pero |DET| siguen siendo el cambio en el area.</li> <li>A<sup>-1</sup>A = I -&gt; una transformaci\u00f3n que no hace nada.</li> <li> <p>Si DET(A) = 0 no existe la matriz inversa. Ej. \\(R^{2}\\) -&gt; si det(A) = 0 la transformaci\u00f3n lleva el espacio a una recta. No hay funci\u00f3n que lleve cada vector de la recta a un punto en \\(R{2}\\). No hay vuelta atr\u00e1s. \u00a0 \u00a0</p> </li> <li> <p>Si una transformaci\u00f3n lleva todos los puntos a una recta tiene rango 1, si lleva a un plano rango 2, y as\u00ed.. RANGO es el n\u00famero de dimensiones del output. Rango completo es cuando mantiene las dimensiones del input.</p> </li> <li>El conjunto de posibles outputs de \\(A\\vec v\\) es el Column Space = Span de las columnas</li> <li>Cuando perd\u00e9s dimensiones por la transformaci\u00f3n todo un conjunto de vectores pasa a ser (0,0). Eso se llama Null Space o Kernel</li> <li>Matrices no cuadradas cambian la dimensi\u00f3n del espacio. $$ \\begin{bmatrix} A &amp; D \\ B &amp; E \\ C &amp; F \\end{bmatrix} \\begin{bmatrix} 1 \\ 1 \\end{bmatrix} = \\begin{bmatrix} A + D \\ B + E \\ C + F \\end{bmatrix} $$  Quedan todos los puntos de \\(R^{2}\\) en un plano en el espacio \\(R^{3}\\). De ac\u00e1 viene la restricci\u00f3n para multiplicar matrices. La cantidad de columnas de la transformaci\u00f3n tiene que ser igual a la dimensi\u00f3n del input</li> </ul>","tags":["estadistica","matematica","algebra"]},{"location":"writing/2019/04/20/esencia-del-algebra-lineal/#dot-product-o-producto-interno","title":"DOT PRODUCT o PRODUCTO INTERNO","text":"<ul> <li>Dot product entre dos vectores equivale a proyectar uno en el otro y multiplicar sus largos. \\(\\vec A \\cdot \\vec B = |A^{*}| * |B|\\) \\(A^{*}\\) es el vector A proyectado en B.</li> <li>\\(\\vec B\\) es un vector 2D pero tambi\u00e9n se lo puede ver como una matriz 1x2 que lleva del 2D a la recta. \\(\\vec B \\cdot \\vec A = B \\vec A \\text{que ser\u00eda llevar A al espacio transformado por B.}\\) \\(B = \\begin{bmatrix} B_x &amp; B_y \\end{bmatrix}\\) tiene en sus columnas donde queda \\(\\hat \\imath \\text{y } \\hat \\jmath\\) (los vectores unitarios) al ser transformados o algun valor escalado de esto. \\(\\vec A \\cdot \\vec B\\) es el valor de A en la recta a la que te lleva la transformaci\u00f3n B.</li> <li>Es equivalente proyecto B en A.</li> <li>Si Dot Product &gt; 0, tienen direcci\u00f3n similar.</li> <li>Si Dot Product = 0, son ortogonales - proyecci\u00f3n que cae en el origen.</li> <li>Si Dot Product &lt; 0, tienen direcciones opuestas.</li> </ul>","tags":["estadistica","matematica","algebra"]},{"location":"writing/2019/04/20/esencia-del-algebra-lineal/#cross-product","title":"CROSS PRODUCT","text":"<ul> <li>Est\u00e1 definido para vectores en \\(R^{3}\\)</li> <li>El cross product \\(\\vec u \\times \\vec v\\) es el area del paralelograma que se puede imaginar con las paralelas de los vectores (imaginandolo en \\(R^{2}\\). El signo depende de la orientaci\u00f3n de los vectores. El vector de la \"derecha\" tiene que estar primero para que el cross product sea &gt; 0.</li> <li>En realidad el paralelograma formado por dos vectores en R<sup>3</sup> tiene area equivalente al Largo del vector output de su cross product. Ese vector es ortogonal al paralelograma.</li> </ul>","tags":["estadistica","matematica","algebra"]},{"location":"writing/2019/04/20/esencia-del-algebra-lineal/#cambio-de-base","title":"CAMBIO DE BASE","text":"<ul> <li>Distintos sistemas de coordenadas definen \\(\\hat \\imath = \\left&lt; 1, 0 \\right&gt;, \\hat \\jmath \\left&lt; 0, 1 \\right&gt;\\) como algo distinto. NO hay una sola \"grilla\" v\u00e1lida. El espacio no tiene grilla predeterminada.</li> <li>Un mismo vector tiene distintas coordenadas seg\u00fan el sistema de bases desde donde se lo mire.</li> <li>Para pasar de una base a otra se aplica una transformaci\u00f3n lineal. Si \\(\\vec v\\) es un vector que queremos pasar de una base a otra, lo transformamos por la nueva base. Y \\(\\hat \\imath^{*} =  \\left&lt; \\hat \\imath^{*}_1, \\hat \\imath^{*}_2 \\right&gt;, \\hat \\jmath^{*} =  \\left&lt; \\hat \\jmath^{*}_1, \\hat \\jmath^{*}_2 \\right&gt;\\) Entonces: \\(\\(\\begin{bmatrix} \\hat \\imath^{*}_1 &amp; \\hat \\jmath^{*}_1 \\\\ \\hat \\imath^{*}_2 &amp; \\hat \\jmath^{*}_2 \\end{bmatrix} \\begin{bmatrix} v_1 \\\\ v_2 \\end{bmatrix} = \\begin{bmatrix} v^{*}_1 \\\\ v^{*}_2 \\end{bmatrix}\\)\\) Donde \\(\\begin{bmatrix} v^{*}_1 \\\\ v^{*}_2 \\end{bmatrix}\\) es el vector en la nueva base, es decir, ser\u00edan las coordenadas del vector \\(\\vec v\\) en el nuevo sistema de coordenadas y representando ese punto bajo el sistema de coordenadas original. -&gt; Como se ver\u00eda \\(\\vec v\\) en la nueva base? desde un punto de vista de la base original. La matriz transforma un vector siguiendo en el lenguaje de la base original. Ej: Si \\(\\vec v\\) es (1,2) en el sistema cartesiano t\u00edpico y aplicamos la matriz de cambio de base, un vector (1,2) bajo otros ejes se ubicar\u00eda en otro punto del espacio. Qu\u00e9 punto es ese bajo el sistema cartesiano? Es (1,2) en el nuevo, pero queremos saber su equivalente en el sistema original.</li> <li>Por otra parte si queremos saber que coordenadas tomar\u00eda el vector \\(\\vec v\\) bajo otra base debemos multiplicar por la inversa de la transformaci\u00f3n. Transforma el vector al lenguaje de la nueva base. Responde a la pregunta. Qu\u00e9 coordenadas toma el punto V_1, V_2 del espacio en el sistema nuevo? \u00a0</li> <li>Para aplicar una transformaci\u00f3n a otra base conviene llevar el vector a transformar a la base original, transformar y reconvertir a la nueva base. $$ [A]^{-1}[T][A]\\vec v = \\vec v^{*}$$ A lo expresa en t\u00e9rminos de la base original, luego se le aplica la transformaci\u00f3n T y luego se lo devuelve al lenguaje de la nueva transformaci\u00f3n.</li> </ul>","tags":["estadistica","matematica","algebra"]},{"location":"writing/2019/04/20/esencia-del-algebra-lineal/#eigenvalues-y-eigenvectors-autovalores-y-autovectores","title":"Eigenvalues y Eigenvectors (autovalores y autovectores)","text":"<ul> <li>!!! Al aplicar una transformaci\u00f3n lineal a un espacio algunos vectores no cambian de direcci\u00f3n, solo se estiran o contraen pero sobre la misma recta. El resto s\u00ed se mueve. Los que se mantienen son los eigenvectors, y su factor de expansi\u00f3n o contracci\u00f3n es su eigenvalue. Si A es la matriz de transformaci\u00f3n, \\(\\vec v\\) es un eigenvector y \\(\\lambda\\) su eigenvalue. $$ A\\vec v = \\lambda \\vec v$$  </li> <li>Si una transformaci\u00f3n es una matriz diagonal, lo \u00fanico que hace es estirar \\(\\hat \\imath \\text{y } \\hat \\jmath\\) por lo tanto los vectores base son eigenvectors y la diagonal son los eigenvalues.</li> <li>Si cambiamos la base a una formada por los eigenvectors (que spanean el espacio) de la matriz podemos aplicar la transformaci\u00f3n (la matriz original de donde salieron los eigenvectors) a esta nueva base y solo la va a estirar, por lo tanto es una transformaci\u00f3n diagonal, que permite calculos mucho m\u00e1s f\u00e1cil. Despu\u00e9s habr\u00eda que volver a la base original. A -&gt; Matriz de transformaci\u00f3n E -&gt; Matriz de autovectores que forman la nueva base \\(\\begin{bmatrix} e_11 &amp; e_21 \\\\ e_12 &amp; e_22 \\end{bmatrix}\\) D -&gt; Matriz Diagonal cuyos valores son los eigenvalues $$ E^{-1}AE=D$$</li> </ul> <p>E cambia la base a eigenvectors (expresado en la base original), A aplica transformaci\u00f3n y E<sup>-1</sup> lo lleva al lenguaje de la nueva base (queda expresado en las nuevas coordenadas) \u00a0 \u00a0</p>","tags":["estadistica","matematica","algebra"]},{"location":"writing/2019/04/20/esencia-del-algebra-lineal/#espacios-vectoriales-abstractos","title":"Espacios Vectoriales Abstractos","text":"<ul> <li>!!! Ver funciones como un tipo especial de vectores.</li> <li>Las funciones se pueden sumar y escalar \\(f(x) + g(x) \\text{y } 2f(x)\\)</li> <li>Existen transformaciones lineales de funciones, convierten una funci\u00f3n en otra. Tambi\u00e9n conocidas como \"operadores\"</li> <li>Para que una transformaci\u00f3n sea lineal tiene que cumplir aditividad y mulitplicaci\u00f3n por escalar $$ L(\\vec v + \\vec  w) = L(\\vec v) + L(\\vec w)$$ $$ L(c\\vec v) = cL(\\vec v)$$</li> <li>En general cualquier espacio que cumpla los axiomas los espacios vectoriales puede ser considerado uno.</li> </ul>","tags":["estadistica","matematica","algebra"]},{"location":"writing/2019/05/06/aprendizaje-estadistico-islr-capitulo-2/","title":"Aprendizaje Estad\u00edstico - ISLR Capitulo 2","text":"<p>Suponemos que las variables que encontramos en un set de datos son generadas a trav\u00e9s de un proceso generador de datos (DGP por sus siglas en ingl\u00e9s) cuya expresi\u00f3n es:  $$ Y = f(X) + \\epsilon $$</p> <p>Donde Y es la variable, en este caso la dependiente o la que queremos explicar. f(X) es una funci\u00f3n respecto a otra/s variable/s X (independientes) y \\(\\epsilon\\) es el error irreducible, es decir un valor aleatorio con media 0 pero que no depende de otras variables, es al azar. Puede referir a errores de medici\u00f3n, cambios inmesurables en las situaciones del experimento o simplemente azar en la generaci\u00f3n real de los datos. Cabe destacar que f(X) es desconocida para nosotros y justamente lo que queremos explorar con el an\u00e1lisis estad\u00edstico. Puede tenerse suposiciones o conocimiento de la forma funcional (lineal, no lineal, etc) pero en principio no tenemos mayores certezas y esperamos aprender a partir de la muestra que analizamos.</p>","tags":["estadistica","ISLR","Introduction Statistical Learning"]},{"location":"writing/2019/05/06/aprendizaje-estadistico-islr-capitulo-2/#por-que-estimar-fx","title":"Por qu\u00e9 estimar f(X)?","text":"<p>Los dos principales motivos para interesarse en f(X) son predicci\u00f3n (de Y) e inferencia de los par\u00e1metros de f(X).</p>","tags":["estadistica","ISLR","Introduction Statistical Learning"]},{"location":"writing/2019/05/06/aprendizaje-estadistico-islr-capitulo-2/#prediccion","title":"Predicci\u00f3n","text":"<p>Queremos predecir valores de Y para nuevos datos X. Como \\(\\epsilon\\) en promedio es 0 podemos aproximar Y de la forma:  $$ \\hat Y = \\hat f(X)$$ La precisi\u00f3n de \\(\\hat Y\\) va a depender del error reducible y del error irreducible. El primero depende de qu\u00e9 tan bien nos aproximemos a la verdadera f(X) y puede ser potencialmente reducido si utilizamos las t\u00e9cnicas m\u00e1s adecuadas para el caso. El segundo error es justamente irreducible y es porque nuestra aproximaci\u00f3n no puede tener en cuenta a \\(\\epsilon\\). El t\u00e9rmino aleatorio introducido por esa variable no lo podemos estimar para cada observaci\u00f3n y por lo tanto debemos convivir con ese margen de error.</p> <p>Suponiendo que tenemos una estimaci\u00f3n \\(\\hat f\\) y un set de datos X puede probarse que: $$ E(Y - \\hat Y)^2 = E[f(X) + \\epsilon - \\hat f(X)]^2$$                    $$                              = \\underbrace{[f(X) - \\hat f(X)]^2}\\text{Reducible} + \\underbrace{Var(\\epsilon)}\\text{Irreducible}$$</p> <p>Donde \\(E(Y-\\hat Y)^2\\) es el promedio o valor esperado de la diferencia al cuadrado del valor real de Y y de la predicci\u00f3n correspondiente. \\(Var(\\epsilon)\\) es la varianza del t\u00e9rmino de error \\(\\epsilon\\).</p>","tags":["estadistica","ISLR","Introduction Statistical Learning"]},{"location":"writing/2019/05/06/aprendizaje-estadistico-islr-capitulo-2/#inferencia","title":"Inferencia","text":"<p>Este enfoque se basa en entender la relaci\u00f3n entre las variables de X y la dependiente. Es necesario entender bien la f(X) elegida para poder interpretar sus coeficientes y poder ver qu\u00e9 variables est\u00e1n asociadas con Y, c\u00f3mo es esa relaci\u00f3n, cu\u00e1l es la forma de la funci\u00f3n f(X), etc para poder actuar sobre las variables X o comprender su efecto aunque no siendo tan exigentes con el poder de predicci\u00f3n de nuestro modelo.</p>","tags":["estadistica","ISLR","Introduction Statistical Learning"]},{"location":"writing/2019/05/06/aprendizaje-estadistico-islr-capitulo-2/#como-estimar-fx","title":"Como Estimar f(X)?","text":"","tags":["estadistica","ISLR","Introduction Statistical Learning"]},{"location":"writing/2019/05/06/aprendizaje-estadistico-islr-capitulo-2/#metodos-parametricos","title":"M\u00e9todos Param\u00e9tricos","text":"<p>Los m\u00e9todos param\u00e9tricos se conforman por dos etapas. La primera es asumir o suponer la forma funcional de f(X). Podes definir por ejemplo que f(X) es una funci\u00f3n lineal de la forma $$ f(X) = \\beta_0 + \\beta_1X_1 + \\beta_2X_2 + ... + \\beta_pX_p$$  </p> <p>Una vez definida la forma del modelo la segunda etapa consiste en estimar los par\u00e1metros con alg\u00fan m\u00e9todo, a partir de los datos de entrenamiento. En este caso ser\u00eda estimar todos los \\(\\beta\\). Por ejemplo para las funciones lineales se suele utilizar el m\u00e9todo de m\u00ednimos cuadrados ordinario. La ventaja de definir una forma funcional es que luego es m\u00e1s sencillo estimar sus par\u00e1metro y el problema se reduce a eso finalmente. Por el otro lado, posiblemente la forma que elijamos no sea exactamente igual a la real (DGP) y tengamos que aceptar que va a haber errores debido a eso. Si estamos muy lejos de la forma real esos errores ser\u00e1n groseros. Existen modelos flexibles que permiten ajustar modelos con diferentes formas de f(X) pero en general requieren estimar m\u00e1s par\u00e1metros  y son m\u00e1s propensos a sufrir sobreajuste/overfitting que b\u00e1sicamente es ajustarse mucho al ruido o error (\\(\\epsilon\\)) en los datos de entrenamiento y luego ajustar mal en testeo.  </p>","tags":["estadistica","ISLR","Introduction Statistical Learning"]},{"location":"writing/2019/05/06/aprendizaje-estadistico-islr-capitulo-2/#metodos-no-parametricos","title":"M\u00e9todos No Param\u00e9tricos","text":"<p>Los m\u00e9todos no param\u00e9tricos no requieren definir expl\u00edcitamente una forma funcional de f. Buscan un f que sea lo m\u00e1s cercano posible a los datos sin ser demasiado estricto o flexible. Al no asumir una forma puede cubrir potencialmente un rango mucho mayor. El problema es que al no reducir el problema a estimar par\u00e1metros necesitan muchas m\u00e1s observaciones para estimar f de forma medianamente precisa. En general uno tiene que decidir el nivel de \"suavidad\" del modelo, lo cual afecta que tan variable termina siendo la estimaci\u00f3n. Sirve para encontrar el punto de fleixibilidad/rigidez del modelo que queremos para que no sobreajuste (ni falle demasiado).</p>","tags":["estadistica","ISLR","Introduction Statistical Learning"]},{"location":"writing/2019/05/06/aprendizaje-estadistico-islr-capitulo-2/#prediccion-vs-interpretabilidad","title":"Predicci\u00f3n vs Interpretabilidad","text":"<p>Uno puede elegir entre modelos flexibles o m\u00e1s r\u00edgidos. Con pocas observaciones a veces uno no puede alejarse mucho de los r\u00edgidos pero suponiendo que uno tiene muchos datos, a veces puede igualmente elegir r\u00edgidez frente a modelos flexibles que permiten ajustar varias formas de f.  El motivo es que generalmente los modelos restrictivos son m\u00e1s f\u00e1ciles de interpretar y se le puede dar un significado claro a sus coeficientes mientras que con formas muy flexibles no es sencillo entender el impacto de las variables de manera individual. La elecci\u00f3n va a depender del objetivo del an\u00e1lisis y de qu\u00e9 tan bien o mal nuestros modelos ajustan a los datos.</p>","tags":["estadistica","ISLR","Introduction Statistical Learning"]},{"location":"writing/2019/05/06/aprendizaje-estadistico-islr-capitulo-2/#modelos-supervisados-vs-no-supervisados","title":"Modelos Supervisados vs No Supervisados","text":"<p>Nuestros datos pueden tener una variable dependiente que queremos explicar o predecir en base a un set de variables independientes, con alg\u00fan modelo a definir. Los casos de este estilo son llamados supervisados porque sabemos la \"respuesta\" (nuestra variable Y) y podemos validar nuestros modelos contra la realidad. Si los datos no tienen una variable dependiente lo que se puede hacer es un an\u00e1lisis no supervisado donde por ejemplo lo que se puede hacer es agrupar las observaciones en clusters o grupos. Es decir segmentar en distintas clasificaciones y descubrir patrones. El desaf\u00edo es que no hay en los datos nada contra qu\u00e9 validarlo, aunque s\u00ed contra el conocimiento del dominio o de la tem\u00e1tica.</p>","tags":["estadistica","ISLR","Introduction Statistical Learning"]},{"location":"writing/2019/05/06/aprendizaje-estadistico-islr-capitulo-2/#regresion-vs-clasificacion","title":"Regresi\u00f3n vs Clasificaci\u00f3n","text":"<p>En los modelos supervisados, nuestra variable dependiente puede ser cuantitativa o cualitativa. En el primer caso la variable toma valores n\u00famericos, como por ejemplo la altura de una persona, el precio de una propiedad, etc. Son problemas de regresi\u00f3n.   En el segundo caso la variable dependiente puede tomar el valor de una clase o categor\u00eda. Por ejemplo, g\u00e9nero de una persona, si paga o no paga su deuda, etc. Son problemas de clasificaci\u00f3n.</p>","tags":["estadistica","ISLR","Introduction Statistical Learning"]},{"location":"writing/2019/05/06/aprendizaje-estadistico-islr-capitulo-2/#midiendo-el-ajuste-del-modelo","title":"Midiendo el ajuste del modelo","text":"","tags":["estadistica","ISLR","Introduction Statistical Learning"]},{"location":"writing/2019/05/06/aprendizaje-estadistico-islr-capitulo-2/#regresion","title":"Regresi\u00f3n","text":"<p>Para problemas de regresi\u00f3n una de las medidas m\u00e1s utilizadas es el Error Cuadr\u00e1tico Medio (MSE por sus siglas en ingl\u00e9s). $$ MSE = \\frac{1}{n} \\sum_{i=1}^n(y_i - \\hat f(x_i))^2 $$</p> <p>Es b\u00e1sicamente la diferencia promedio entre la realidad y lo que predice nuestro modelo elevado al cuadrado. Esto \u00faltimo es para que los errores sean siempre positivos aunque subestimemos o sobreestimemos (y por su comodidad para c\u00e1lculos matem\u00e1ticos).</p> <p>En primero lugar se calcula este valor con los datos de entrenamiento sin embargo lo que realmente importa es como performa el modelo en datos de testeo, es decir en datos que no fueron utilizados para estimar f(X). Podemos decir que cada modelo deber\u00eda tener un MSE de entrenamiento y un MSE de testeo. Debido a la posibilidad de sobreajuste y a las diferencias en muestras nada garantiza que el modelo que estimemos con menor MSE en entrenamiento tambi\u00e9n sea el de menor MSE en testeo. </p> <p>A medida que aumentamos la flexibilidad de un modelo (sus grados de libertad) el MSE en entrenamiento va a disminuir, ya que tiene m\u00e1s herramientas para ajustarse a los datos pero puede que sobreajuste y por lo tanto no se traduzca en un menor MSE en testeo.</p>","tags":["estadistica","ISLR","Introduction Statistical Learning"]},{"location":"writing/2019/05/06/aprendizaje-estadistico-islr-capitulo-2/#el-tradeoff-entre-sesgo-y-varianza","title":"El tradeoff entre Sesgo y Varianza","text":"<p>No est\u00e1 demostrado en el libro pero es posible descomponer el MSE esperado de una observaci\u00f3n de testeo en sesgo de \\(\\hat f(x_0)\\), varianza de \\(\\hat f(x_0)\\) y varianza del error irreducible \\(\\epsilon\\).</p> \\[ E(y_0 - \\hat f(x_0))^2 = Var(\\hat f(x_0)) + [Sesgo(\\hat f(x_0))]^2 + Var(\\epsilon)\\] <p>El lado izquierdo de la ecuaci\u00f3n es el MSE esperado y coresponde MSE de testeo promedio que obtendr\u00edamos si estimaramos f utilizando una gran cantidad de sets de entrenamiento y testearamos cada uno en \\(x_0\\).</p> <p>Algunas observaciones:</p> <ul> <li>El MSE nunca puede ser menor que la varianza de \\(\\epsilon\\). Es un t\u00e9rmino fijo y por eso se lo llama error irreducible.</li> <li>La varianza es cuanto cambiar \\(\\hat f\\) si utilizamos otro set de entrenamiento. Siempre va a cambiar con otro set pero idealmente ese cambio no deber\u00eda ser grande. Modelos muy flexibles tienden a cambiar m\u00e1s frente a distintos sets y son m\u00e1s inestables.</li> <li>Sesgo es el error provocado por la diferencia entre el modelo elegido y el verdadero proceso generador de los datos. En general modelos m\u00e1s flexibles tienen menor sesgo ya que pueden ajustar mayor variedad de formas funcionales.</li> <li>Al aumentar la flexibilidad de un modelo en general reducimos el sesgo pero aumentamos la varianza. En general en un primer momento el sesgo suele disminuir a mayor velocidad de lo que aumenta la varianza y por lo tanto el MSE esperado se reduce. Sin embargo llega un punto donde mayor flexibilidad reduce menos el sesgo que lo que aumenta la varianza y el MSE empieza a aumentar. Es el primer indicio de sobreajuste. Por eso se habla de tradeoff o \"balance\".</li> <li>En la realidad donde la verdadera f del DGP es inobservable no suele ser posible calcular expl\u00edcitamente el MSE de testeo, el sesgo o la varianza de un m\u00e9todo estad\u00edstico pero el proceso de fondo aplica y siempre debemos tener en mente el tradeoff.</li> </ul>","tags":["estadistica","ISLR","Introduction Statistical Learning"]},{"location":"writing/2019/05/06/aprendizaje-estadistico-islr-capitulo-2/#clasificacion","title":"Clasificaci\u00f3n","text":"<p>Para problemas de clasificaci\u00f3n uno de los enfoques m\u00e1s frecuentes para cuantificar la precisi\u00f3n de una funci\u00f3n estimada \\(\\hat f\\) se suele usar el porcentaje de error en los datos de entrenamiento.</p> <p>$$ \\frac{1}{n} \\sum_{i=1}^nI(y_i \\neq \\hat y_i) $$ B\u00e1sicamente es el porcentaje de observaciones clasificadas erroneamente. Al igual que con MSE es de gran importance el porcentaje de error en los datos de testeo.</p>","tags":["estadistica","ISLR","Introduction Statistical Learning"]},{"location":"writing/2019/05/06/aprendizaje-estadistico-islr-capitulo-2/#clasificador-de-bayes","title":"Clasificador de Bayes","text":"<p>No lo demuestra en el libro pero la mejor manera de reducir el porcentaje de error en test es asignar a cada observaci\u00f3n la clase con mayor probabilidad (seg\u00fan el DGP ). Es un concepto muy sencillo, dado X, asignar la clase cuya chance de acierto sea mayor.</p> <p>$$ Pr(Y = j | X = x_0) $$ El porcentaje de error de Bayes (es decir el error luego de clasificar siguiendo esa regla) es an\u00e1logo al Error Irreducible de regresi\u00f3n. Hay que tener en cuenta que la distribuci\u00f3n condicional de Y dado X no lo sabemos en los casos aplicados en la vida real, ser\u00eda como saber la funci\u00f3n f(X) o el DGP y por lo tanto no lo podemos calcular.</p>","tags":["estadistica","ISLR","Introduction Statistical Learning"]},{"location":"writing/2019/05/06/aprendizaje-estadistico-islr-capitulo-2/#k-vecinos-mas-cercanos-knn-en-ingles","title":"K vecinos m\u00e1s cercanos (KNN en ingl\u00e9s)","text":"<p>Idealmente uno querr\u00eda aplicar el clasificador de Bayes pero es imposible ya que no sabemos la distribuci\u00f3n real de los datos (es justamente lo que queremos estimar). KNN intenta aproximarse a la distribuci\u00f3n condicional para clasificar las observaciones. Lo que hace este m\u00e9todo es, dado un valor de K que elegimos nosotros, clasificar cada nueva observaci\u00f3n seg\u00fan la clase mayoritaria entre las K observaciones m\u00e1s cercanas a esta.</p> <p>$$ Pr(Y = j | X = x_0) = \\frac{1}{K} \\sum_{i \\in N_0} I(y_i = j) $$ El valor que seleccionemos de K afecta en gran medida las predicciones del modelo. Un K menor hace m\u00e1s variable el modelo ya que selecciona menos observaciones y por lo tanto pocos cambios en el set de entrenamiento cambian la clasificaci\u00f3n. Suele reducir el sesgo pero ser mas variable. Es an\u00e1logo a hacer m\u00e1s flexible un modelo en regresi\u00f3n. Valores de K m\u00e1s grandes seleccionan puntos en un entorno m\u00e1s abarcativo y por lo tanto suele ser m\u00e1s constante pero con sesgo superior. Al igual que en regresi\u00f3n hay que tener cuidado con el sobreajuste. Reducir K garantiza menos errores en los datos de entrenamiento pero pasado un umbral la varianza aumenta en mayor medida y el porcentaje de error en test se incrementa.</p> <p>Conclusi\u00f3n: Tanto en Clasificaci\u00f3n como en Regresi\u00f3n la elecci\u00f3n del nivel de flexibilidad  es central en el \u00e9xito de m\u00e9todo de aprendizaje estad\u00edstico.</p>","tags":["estadistica","ISLR","Introduction Statistical Learning"]},{"location":"writing/2019/05/25/regresion-lineal-islr/","title":"Regresion Lineal - ISLR Cap\u00edtulo 3","text":"<p>La regresi\u00f3n lineal simple es un m\u00e9todo muy directo para estimar una variable cuantitativa Y en base a un solo predictor X. Asume que hay una relaci\u00f3n lineal entre X e Y. $$ Y \\approx \\beta_0 + \\beta_1X$$ \\(\\beta_0\\) y \\(\\beta_1\\) son dos constantes desconocidas que representan al intercepto y a la pendiente del modelo lineal. Son los coeficientes o par\u00e1metros. Con nuestros datos podemos estimar coeficientes para predecir futuros valores de Y basados en X y nuestro modelo.</p>","tags":["estadistica","Introduction Statistical Learning","ISLR","R"]},{"location":"writing/2019/05/25/regresion-lineal-islr/#estimacion-de-coeficientes","title":"Estimaci\u00f3n de Coeficientes","text":"<p>Los coeficientes que buscamos son \\(\\hat \\beta_0\\) y \\(\\hat \\beta_1\\) (estimados, por eso el sombrero) son aquellos que generen una recta que pase lo m\u00e1s cerca posible de todos nuestros datos de entrenamiento. Hay varias manera de definir \"cerca\" pero la m\u00e1s usada es el enfoque de m\u00ednimos cuadrados.</p> <p>Supongamos un ejemplo donde tenemos datos de horas trabajadas por ciertos individuos y la paga que reciben. Supongamos a fines del ejemplo que la relaci\u00f3n entre salario y horas es lineal (sabemos que no es real...)</p> <p>Cuando estimemos \\(\\hat \\beta_0\\) y \\(\\hat \\beta_1\\) obtendremos despu\u00e9s un valor \\(\\hat y_i\\) para cada valor de \\(x_i\\) (cada observaci\u00f3n), que ser\u00e1 el resultado de la predicci\u00f3n de nuestro modelo para ese valor de horas trabajadas. $$ \\hat y_i = \\hat \\beta_0 + \\hat \\beta_1 x_i$$ Luego \\(e_i = y_i - \\hat y_i\\) representa el residuo, que es la diferencia entre el valor real del salario para esa observaci\u00f3n y el valor que predice nuestro modelo. Una m\u00e9trica importante a saber es la suma de resiudos al cuadrado (RSS por siglas en ingl\u00e9s) que es: $$ RSS = e_1^2 + e_2^2 + ... + e_n^2$$ o de manera equivalente: $$ RSS = (y_1 - \\hat \\beta_0 - \\hat \\beta_1x_1) ^2 +  (y_2 - \\hat \\beta_0 - \\hat \\beta_1x_2) ^2  + ... + (y_n - \\hat \\beta_0 - \\hat \\beta_1x_n) ^2 $$</p> <p>Que basicamente es la suma de todas las diferencias entre lo predicho por nuestro modelo y el dato real de nuestro set, elevadas al cuadrado. Esto \u00faltimo es principalmente para evitar que se compensen los errores. Sobreestimar por 10 y luego subestimar por 10 tiene como suma de errores 0. Si elevamos esas diferencias al cuadrado, todos los errores ser\u00e1n positivos y se acumular\u00e1n. En este caso seria \\(10^2\\) + \\((-10)^2\\), que es 200. El enfoque de m\u00ednimos cuadrados estima \\(\\hat \\beta_0\\) y \\(\\hat \\beta_1\\) de tal manera que el RSS sea el m\u00ednimo posible dados los datos.  </p> <p>Usando un poco de c\u00e1lculo se puede demostrar que los par\u00e1metros que minimizan RSS son: $$ \\hat \\beta_1 = \\frac{\\sum_{i = 1}^n (x_i - \\bar{x}) (y_i - \\bar{y})}{\\sum_{i=1}^n (x_i - \\bar{x})^2}$$ $$ \\hat \\beta_0 = \\bar{y} - \\hat \\beta_1\\bar{x}$$ donde \\(\\bar{y}\\) y \\(\\bar{x}\\) son las respectivas medias muestrales.</p> <p></p> <p>En nuesto caso usando este set de datos generado ficticiamente obtenemos \\(\\hat \\beta_0\\) = 2.000713 \u00d7 10<sup>4</sup> y \\(\\hat \\beta_1\\) = 299.82</p> <p>Recordemos que esta es una estimaci\u00f3n en base a los datos y no sabemos los verdaderos par\u00e1metros de la DGP real(proceso generador de datos). En este caso yo si lo s\u00e9 porque gener\u00e9 los datos pero en la vida real es inaccesible. Lo que hicimos fue estimar, a partir de un set de datos, ciertos coeficientes o caracter\u00edstica de una poblaci\u00f3n mucho m\u00e1s amplia. (Todos los trabajadores del pa\u00eds..)</p>","tags":["estadistica","Introduction Statistical Learning","ISLR","R"]},{"location":"writing/2019/05/25/regresion-lineal-islr/#precision-de-nuestros-estimadores","title":"Precisi\u00f3n de nuestros estimadores","text":"<p>En este caso ten\u00edamos una sola muestra pero podr\u00edamos haber tenido muchas muestras (K) de la misma poblaci\u00f3n (muchos sets de datos con horas trabajadas y salarios). Si estim\u00e1ramos los coeficientes para cada uno de esos sets obtendr\u00edamos K pares de coeficientes, cada uno calculado con las particularidades de esos sets. Se puede demostrar que el promedio de una cantidad grande de estimadores provenientes de muchas muestras se centra en el verdadero valor poblacional (si el modelo es correcto). Es decir que el promedio de los K \\(\\hat \\beta_1\\) va a centrarse en el verdadero valor poblacional de \\(\\beta_1\\) ( y lo mismo para \\(\\beta_0\\)). Pero estos K par\u00e1metros centrados en el verdadero valor van a tener cierta dispoersi\u00f3n, es decir, pueden estar todos muy cerca del verdadero o estar muy dispersos pero que en promedio si quede centrado. Esto determina que tan preciso es el coeficiente que estimemos de una muestra.  Este desv\u00edo est\u00e1ndar de los par\u00e1metros (SE) puede estimarse y depende de la varianza del error del modelo.</p> <p>Puede ser \u00fatil para calcular los intervalos de confianza de los par\u00e1metros. Estos son intervalos que con X% de probabilidad contienen al verdadero valor del par\u00e1metro poblacional. Lo m\u00e1s habitual es calcular el intervalo de confianza al 95%. Para \\(\\hat \\beta_1\\) esto es aproximadamente: $$ \\hat \\beta_1 \\pm 2 \\cdot SE(\\hat \\beta_1)$$ La interpretaci\u00f3n ser\u00eda que de 100 intervalos que construya de esta manera (de 100 muestras distintas), 95 van a tener al verdadero valor de \\(\\beta_1\\).  </p> <p>Por otra parte podemos realizar un test de hipot\u00e9sis de los coeficientes. El m\u00e1s com\u00fan es testear la siguiente hip\u00f3tesis nula: H_0 : No hay relaci\u00f3n entre X e Y contra la hip\u00f3tesis alternativa H_1 : Hay alguna relaci\u00f3n entre X e Y Lo cual se traduce en: $$ H_0 : \\beta_1 = 0 $$ $$ H_1 : \\beta_1 \\neq 0$$</p> <p>Lo que se hace es determinar si \\(\\hat \\beta_1\\) est\u00e1 lo suficientemente lejos de 0 como para rechazar la hip\u00f3tesis nula. Qu\u00e9 tan lejos es suficiente depende en gran parte del desv\u00edo est\u00e1ndar (SE) del coeficiente. Si el SE es grande , necesitaremos valores elevado de \\(\\hat \\beta_1\\) para estar tranquilos con que el valor real no puede ser 0. Para esto lo que se hace es calcular el estad\u00edstico t: $$ t = \\frac{\\hat \\beta_1 - 0}{SE(\\hat \\beta_1)}$$ Que mide cuantos desv\u00edos est\u00e1ndar \\(\\hat \\beta_1\\) est\u00e1 alejado de 0. Si no hay relaci\u00f3n entre X e Y se espera que el estad\u00edstico tenga una distribuci\u00f3n t con n - 2 grados de libertad. Dado ese supuesto, lo que se hace es calcular la probabilidad de obtener un valor de t como el de nuestro estad\u00edstico, si este proviene de una distribuci\u00f3n t con n-2 grados de libertad. Esta probabilidad se la conoce como  p valor. Ser\u00eda qu\u00e9 tan probable es encontrar un valor al menos tan grande como el de t si este proviniera de la distribuci\u00f3n t con n-2 grados de libertad. Si esta probabilidad es muy chica (el umbral habitual es 0.05 pero depende del trabajo) uno rechaza la hip\u00f3tesis nula en favor de la alternativa, suponiendo que s\u00ed hay una relaci\u00f3n entre X e Y.</p>","tags":["estadistica","Introduction Statistical Learning","ISLR","R"]},{"location":"writing/2019/05/25/regresion-lineal-islr/#precision-del-modelo","title":"Precisi\u00f3n del modelo.","text":"<p>Naturalmente a uno le interesa saber qu\u00e9 tan bien ajusta nuestro modelo a los datos.</p> <p>El m\u00e9todo m\u00e1s habitual para regresi\u00f3n lineal es el R^2. Toma valores entre 0 y 1 porque es la proporci\u00f3n de la varianza de Y explicada por nuestro modelo.</p> \\[ R^2 = \\frac{TSS - RSS}{TSS} = 1 - \\frac{RSS}{TSS}\\] <p>donde $TSS = \\sum (y_i -\\bar{y})^2 $ es la suma de cuadrados totales y RSS es la suma de errores cuadrados que ya definimos antes. TSS mide la varianza total de Y y representa la variabilidad total inherent de la variable dependiente antes de correr la regresi\u00f3n. Por el contrario RSS mide la variabilidad que queda sin explicar por nuestro modelo (recuerden que proviene de los residuos).  Por lo tanto el numerador TSS - RSS mide la parte de la variabilidad de Y que s\u00ed pudo ser explicada por el modelo, y lo divide por la variabilidad total. \\(R^2\\) mide entonces la proporci\u00f3n de la variablidad que pudo ser explicada usando X. Cuanto m\u00e1s cerca de 1, mejor.</p>","tags":["estadistica","Introduction Statistical Learning","ISLR","R"]},{"location":"writing/2019/05/25/regresion-lineal-islr/#regresion-con-multiples-predictores","title":"Regresi\u00f3n con M\u00faltiples Predictores","text":"<p>Suena mucho m\u00e1s l\u00f3gico tratar de explicar una variable dependiente no solo por una independiente si no por varias. La regresi\u00f3n lineal simple puede ampliarse a regresi\u00f3n lineal m\u00faltiple donde nuestro modelo pasa a ser: $$ \\hat y_i = \\hat \\beta_0 + \\hat \\beta_1 x_i + ... + \\hat \\beta_p x_p$$ Y mantenemos un t\u00e9rmino de error con distribuci\u00f3n normal y media 0.</p> <p>En esencia la idea es la misma, explicar la variabilidad de Y basado en la variabilidad de nuestros predictores. La metodolog\u00eda para estimar los coeficientes suele ser M\u00ednimos Cuadrados como vimos antes, sin embargo la soluci\u00f3n no suele ser tan f\u00e1cil de expresar y es m\u00e1s sencillo verlo en t\u00e9rminos matriciales o simplemente ver los resultados desde el programa estad\u00edstico que estemos usando. No olvidar que varias regresiones simples no pueden sumarse en una resgresi\u00f3n m\u00faltiple, es decir, los coeficientes de las regresiones simples no tienen por que ser los mismos ni por qu\u00e9 mantener el signo cuando se juntan todas las variables en un solo modelo. Esto sucede porque la regresi\u00f3n m\u00faltiple estima coeficientes controlando por todas las otras variables, es decir, quitando el efecto de las otras. Por eso es que por separado quiz\u00e1s dos variables son significativas pero en una regresi\u00f3n m\u00faltiple solo una de ellas lo es. En general esto viene dado porque est\u00e1n correlacionadas y se comportan de manera similar. Al final del d\u00eda no es f\u00e1cilmente distinguible cu\u00e1l es realmente la que lidera el efecto.</p>","tags":["estadistica","Introduction Statistical Learning","ISLR","R"]},{"location":"writing/2019/05/25/regresion-lineal-islr/#hay-relacion-entre-la-dependiente-y-los-predictores-test-f","title":"Hay relaci\u00f3n entre la dependiente y los predictores? (test F)","text":"<p>En regresi\u00f3n simple vimos el test de hip\u00f3tesis para ver si el coeficiente de \\(\\hat \\beta_1\\) era significativamente distinto de 0. En regresi\u00f3n m\u00faltiple lo que debemos hacer es chequear si todos nuestros coeficientes son distintos de 0. (Y no uno por uno)</p> <p>Lo cual se traduce en: $$ H_0 : \\beta_1 = \\beta_2 = ... = \\beta_p = 0 $$ $$ H_1 : \\text{Al menos alg\u00fan } \\beta_j \\neq 0$$ El test de hip\u00f3tesis se hace calculando el estad\u00edstico F. $$ F = \\frac{(TSS - RSS) / p}{RSS / (n - p -1)}$$</p> <p>Si los supuestos del modelo lineal se cumplen puede probarse que \\(E[RSS/(n - p-1)] = \\sigma^2\\) y si \\(H_0\\) es verdadera \\(E[(TSS-RSS)/p] = \\sigma^2\\). Por lo tanto si no hay relaci\u00f3n el estad\u00edstico F ser\u00e1 cercano a 1 y si en realidad la hip\u00f3tesis alternativa es verdadera el numerador ser\u00e1 mayor que \\(\\sigma^2\\) y por lo tanto F ser\u00e1 mayor que 1. Dependiendo de n, p y del nivel de significatividad que busquemos F deber\u00e1 superar un umbral distinto para poder rechazar la hip\u00f3tesis nula. Es inevitable mirar los p-valores individuales sin embargo debemos tener cuidado particularmente cuando tenemos muchas variables. Por definici\u00f3n, algunos coeficientes saldr\u00e1n significativos por azar aunque no tengan relaci\u00f3n con la variable dependiente. En el caso t\u00edpico de significativdad del 95%, esto sucede en promedio el 5% de las veces. Con muchas variables nuestras posibilidades de encontrarnos con al menos alg\u00fan falso significativo aumentan notoriamente por lo que hay que mirar con cuidado. Por su parte, el estad\u00edstico F corrige en su c\u00e1lculo por la cantidad de coeficientes y por lo tanto no se ve afectado por este problema.</p>","tags":["estadistica","Introduction Statistical Learning","ISLR","R"]},{"location":"writing/2019/05/25/regresion-lineal-islr/#seleccion-de-variables","title":"Selecci\u00f3n de variables","text":"<p>Cuando tenemos un set de datos grande es habitual tener que seleccionar cu\u00e1les son las variables importantes para el modelo. M\u00e1s all\u00e1 del conocimiento del problema (fundamental), idealmente lo mejor es probar una gran cantidad de modelos y con alguna m\u00e9trica de comparaci\u00f3n seleccionar los mejores. El problema es que la cantidad de modelos posible crece exponencialmente con la cantidad de variables y esto no es posible. En el libro los autores mencionan como alternativas Forward Selection, Backward Selection y Selecci\u00f3n mixta. B\u00e1sicamente son enfoques que prueban una muestra de todos los modelos posibles seg\u00fan la significatividad de las variables. Son m\u00e9todos iterativos. Habiendo avanzado la disciplina, llegado el caso buscar\u00eda otros m\u00e9todos vigentes para atacar este problema.</p>","tags":["estadistica","Introduction Statistical Learning","ISLR","R"]},{"location":"writing/2019/05/25/regresion-lineal-islr/#ajsute-del-modelo","title":"Ajsute del modelo","text":"<p>Para verificar el ajuste del modelo se sigue usando el \\(R^2\\) como m\u00e9trica principal. En este caso es equivalente a la correlaci\u00f3n al cuadrado de Y e \\(\\hat Y\\). Un punto a tener en cuenta es que el R^2 nunca puede disminuir al agregar variables ya que el peor escenario posible es que la nueva variable tenga coeficiente de 0 y el ajuste quede igual que antes. Lo que se hace para controlar por esto y poder comparar modelos es ajustar el \\(R^2\\) por la cantidad de variables utilizadas o usar el RSE. De cualquier manera lo importante es recordar que el R2 sigue siendo \u00fatil en la regresi\u00f3n lineal m\u00faltiple.</p>","tags":["estadistica","Introduction Statistical Learning","ISLR","R"]},{"location":"writing/2019/05/25/regresion-lineal-islr/#otras-consideraciones","title":"Otras consideraciones","text":"<ul> <li> <p>Las variables independientes admiten variables categ\u00f3ricas! (Binarias o multiclase). Ej: Educaci\u00f3n m\u00e1xima alcanzada. Hay que mirar con atenci\u00f3n la interpretaci\u00f3n. Alteran el intercepto seg\u00fan la categor\u00eda de la observaci\u00f3n y puede alterar pendientes si se las incluye en interacci\u00f3n con alguna variable continua.</p> </li> <li> <p>El modelo que venimos viendo el aditivo y lineal, pero podemos remover esos supuestos. Por ejemplo podemos agregar interacci\u00f3n entre variable y por lo tanto relajar la aditividad. Esto significa que las variables se modelan multiplicadas entre s\u00ed por ejemplo.</p> </li> </ul> \\[ Y = \\beta_0 + \\beta_1X_1 + \\beta_2X_2 +  \\beta_3X_1X_2 + \\epsilon \\] <ul> <li>Podemos aproximar relaciones no lineales extendiendo el modelo a regresi\u00f3n polin\u00f3mica. Suponiendo que los datos provienen de un modelo polin\u00f3mico, podemos ver en el siguiente gr\u00e1fico c\u00f3mo cambia al agregar el t\u00e9rmino de no linealidad. La l\u00ednea naranja es la regresi\u00f3n lineal simple y la celeste (que ajusta casi perfecto) es la regresi\u00f3n polin\u00f3mica que respeta el proceso generador de los datos (la ecuaci\u00f3n que se ve en el gr\u00e1fico). Vemos que la variable Y depende de X linealmente pero tambi\u00e9n de X al cuadrado, lo que le da la curvatura.</li> </ul> <p></p>","tags":["estadistica","Introduction Statistical Learning","ISLR","R"]},{"location":"writing/2019/05/25/regresion-lineal-islr/#potenciales-problemas","title":"Potenciales problemas","text":"","tags":["estadistica","Introduction Statistical Learning","ISLR","R"]},{"location":"writing/2019/05/25/regresion-lineal-islr/#no-linealidad-de-los-datos","title":"No linealidad de los datos","text":"<p>Si la relaci\u00f3n entre nuestras variables independientes y la dependiente no es lineal nuestro modelo va a tener sesgo alto. Para el modelo simple es f\u00e1cil de ver al graficar X vs Y en un gr\u00e1fico de puntos pero con muchas variables eso ya no es tan sencillo. Un buen enfoque es realizar una regresi\u00f3n lineal y graficar los residuos contra los valores predichos.</p> <p>Es un caso un poco extremo pero supongamos que la relaci\u00f3n es no lineal, polin\u00f3mica  de orden 2 (como el ejemplo de arriba). Si nosotros corremos una regresi\u00f3n lineal, nuestros residuos van a seguir un patr\u00f3n muy obvio. </p> <p>Claramente en ese gr\u00e1fico el residuo no est\u00e1 centrado en 0... En cambio, si nosotros corremos una regresi\u00f3n lineal para un modelo realmente lineal, o para este caso, corremos un modelo no lineal, deber\u00edamos ver una nube de puntos dispersa para los resiudos, centrada en 0 y con alg\u00fan desv\u00edo est\u00e1ndar. Idealmente ver\u00edamos algo asi.</p> <p></p>","tags":["estadistica","Introduction Statistical Learning","ISLR","R"]},{"location":"writing/2019/05/25/regresion-lineal-islr/#correlacion-de-los-terminos-de-error","title":"Correlaci\u00f3n de los t\u00e9rminos de error","text":"<p>Uno de los supuestos de la regresi\u00f3n lineal es que los errores no est\u00e1n correlacionados, es decir que el error \\(\\epsilon_i\\) de una observaci\u00f3n no nos aporta informaci\u00f3n acerca del error \\(\\epsilon_j\\) de otra observaci\u00f3n. Son independientes. Si esto no se cumple lo que sucede es que el SE de los coeficientes estimados es menor al real y puede llevarnos a confiar m\u00e1s en nuestro modelo de lo que deber\u00edamos. Los errores correlacionados suelen suceder m\u00e1s frecuentemente en series de tiempo pero tambi\u00e9n pueden darse  en estudios experimentales mal dise\u00f1ados.</p>","tags":["estadistica","Introduction Statistical Learning","ISLR","R"]},{"location":"writing/2019/05/25/regresion-lineal-islr/#varianza-de-los-terminos-de-error-no-constante-heterocedasticidad","title":"Varianza de los t\u00e9rminos de error no constante. (Heterocedasticidad)","text":"<p>Otro supuesto de la regresi\u00f3n lineal es que la varianza de los errores es constante \\(Var(\\epsilon_i) = \\sigma^2\\). Esto no siempre es el caso. En este ejemplo vemos como los resiudos siguen centrados en 0 pero con una dispersi\u00f3n mucho mayor a medida que avanzamos en el eje X.  Entre las soluciones para este problema se encuentra transformar la variable dependiente - \\(ln(y)\\) por ejemplo, o utilizar M\u00ednimos cuadrados ponderados, que pondera por la inversa de la varianza. El libro no se explaya mucho m\u00e1s al respecto en este cap\u00edtulo.</p>","tags":["estadistica","Introduction Statistical Learning","ISLR","R"]},{"location":"writing/2019/05/25/regresion-lineal-islr/#outliers","title":"Outliers","text":"<p>Los outliers son observaciones cuya variable dependiente tienen valores que se alejan mucho del patr\u00f3n regular de los datos, por ejemplo debido a un error de medici\u00f3n o problema al registrar la informaci\u00f3n. Los outliers pueden tener diversas consecuencias en los modelos lineales. Puede afectar la estimaci\u00f3n de los par\u00e1metros, puede afectar el ajuste del modelo (ca\u00edda del \\(R^2\\)) o puede por ejemplo aumentar los intervalos de confianza ya que el outlier afecta el RSE que es com\u00fan a todos los intervalos. Todo esto puede ser generado por una sola observaci\u00f3n. Generalmente si no se distinguen en el an\u00e1lisis exploratorio pueden saltar a la vista analizando los resiudos del modelo (o los residuos estandarizados).</p>","tags":["estadistica","Introduction Statistical Learning","ISLR","R"]},{"location":"writing/2019/05/25/regresion-lineal-islr/#puntos-con-alto-leverage","title":"Puntos con alto \"leverage\"","text":"<ul> <li>Si alguno tiene una traducci\u00f3n satisfactoria bienvenido sea.. Los puntos con alto leverage son aquellos cuyo valor de la variable independiente se aleja del rango est\u00e1ndar. Las observaciones con esta caracter\u00edstica tienden a afectar en buena medida a la curva ajustada y por ende a los par\u00e1metros de nuestro modelo. Nuestra estimaci\u00f3n por m\u00ednimos cuadrados puede verse muy influenciada por estos puntos e invalidar el ajuste por eso es muy necesario identificar estas observaciones. En regresi\u00f3n simple es sencillo de ver porque resaltan si graficamos una nube de puntos pero en regresi\u00f3n m\u00faltiple es m\u00e1s dif\u00edcil de ver ya que debemos encontrar anomal\u00edas en el conjunto de todas las variables. Es decir que una observaci\u00f3n puede estar en el rango individual de cada variable pero si miramos a nivel conjunto, esa combinacion dentro de los rangos individuales es s\u00faper an\u00f3mala. Con m\u00e1s de dos variables independientes se dificulta identificar visualmente. Para ayudar en estos casos se puede calcular el est\u00e1distico de leverage en alg\u00fan programa estad\u00edstico.</li> </ul>","tags":["estadistica","Introduction Statistical Learning","ISLR","R"]},{"location":"writing/2019/05/25/regresion-lineal-islr/#colinealidad","title":"Colinealidad","text":"<p>Este problema refiere a la alta correlaci\u00f3n entre variables independientes del modelo, es decir que tienden a aumentar o decrecer de manera conjunta. Esto genera que sea dif\u00edcil (o imposible en el extremo) diferenciar el impacto de cada una de ellas en la variable dependiente. En una regresi\u00f3n lineal esto se traduce en aumento de la varianza de los estimadores y por ende incertidumbre sobre los par\u00e1metros estimados. A modo intuitivo, con variables con alta correlaci\u00f3n puede haber una gran cantidad de combinaciones de coeficientes para estas variables que resulten en un mismo ajuste (\\(R^2\\)) y por ende m\u00ednimos cuadrados es indistinto frente a ellos. Cambiando alguna observaci\u00f3n puede que el modelo pase de una combinaci\u00f3n a otra muy disinta en ese arco de posibilidades. Otra consecuencia es que el aumento de la varianza de los coeficientes reduce el estad\u00edstico t que miramos para la significatividad y puede que lleve a no rechazar una hip\u00f3tesis nula que deb\u00eda ser rechazada. La potencia del test de hip\u00f3tesis se ve disminuida por la colinealidad. No solo la correlaci\u00f3n sirve para detectar colinealidad. Puede existir multicolinealidad en donde varias variables son colineales a\u00fan sin tener alta correlaci\u00f3n de a pares. Posiblemente se deba a combinaci\u00f3n lineal generada por algunas de las variables. Para estos casos lo que se puede mirar es el VIF ( Variance Inflation Factor) en ingl\u00e9s. Este estad\u00edstico se calcula para cara variable y compara la varianza del estimador al tener la variable en el modelo versus ajustando un modelo solo con esa variable. Cuanto mayor es el VIF, mayores problemas de colinealidad resalta. Se puede calcular con la siguiente formula donde \\(R^2_{X_j|X_{-j}}\\) es el \\(R^2\\) de la regresi\u00f3n de \\(X_j\\) contra todas las otras variables independientes del modelo. $$ VIF(\\hat \\beta_j) = \\frac{1}{1 - R^2_{X_j|X_{-j}}}$$ La soluci\u00f3n a este problema suele ser descartar alguna de las variables o agruparlas de alguna manera para quedarnos con una \u00fanica variable que represente a ambas.</p>","tags":["estadistica","Introduction Statistical Learning","ISLR","R"]},{"location":"writing/2019/07/01/metodos-de-resampleo/","title":"Metodos de Resampleo - ISLR Capitulo 5","text":"<p>Los m\u00e9todos de resampleo son indispensables en la estad\u00edstica moderna ya que permiten ajustar modelos a diferentes muestras de un mismo set de entrenamiento con el fin de obtener mayor informaci\u00f3n del modelo. Por ejemplo puede ser de utilidad para ver la variabilidad del modelo en distintas muestras. Los dos m\u00e9todos que se presentan en el cap\u00edtulo son cross-validation y bootstrap. A grandes rasgos CV puede servir para estimar el test error de un modelo o para ajustar hiperpar\u00e1metros del modelo como el nivel de flexbilidad. Por su parte bootstrap puede usarse para medir la precisi\u00f3n de un par\u00e1metro estimado mediante un modelo estad\u00edstico.</p>","tags":["estadistica","ISLR","Introduction Statistical Learning","R"]},{"location":"writing/2019/07/01/metodos-de-resampleo/#cross-validation","title":"Cross-Validation","text":"<p>De los modelos que uno entrena es de sumo inter\u00e9s obtener el \"test error\" que ser\u00eda el error promedio al predecir una nueva observaci\u00f3n aplicando el modelo estad\u00edstico entrenado. Esto puede calcularse si tenemos un set de testeo puntualmente para ello pero no suele ser el caso lamentablemente. En general no se tienen tantos datos como para separar en sets como uno desear\u00eda y surgen distintas t\u00e9cnicas para estimar el test error basado solamente en los datos de entrenamiento. Algunas de estas t\u00e9cnicas estiman el test error ajustando el training error por alg\u00fan factor mientras que otras separan el training set en subsets donde uno hace las veces de test set.</p>","tags":["estadistica","ISLR","Introduction Statistical Learning","R"]},{"location":"writing/2019/07/01/metodos-de-resampleo/#validation-set","title":"Validation Set","text":"<p>Un m\u00e9todo muy utilizado es el del set de validaci\u00f3n. B\u00e1sicamente consiste en separar nuestro training set en dos sets, un \"nuevo\" training set y uno set de validaci\u00f3n. Una pr\u00e1ctica habitual es separar 70-30, pero va a depender de la cantidad de observaciones que tengan y no hay una regla estricta. B\u00e1sicamente de los datos que tienen para entrenar el modelo separan una parte que va a ser el set de validaci\u00f3n y entrenan el modelo con los datos restantes (70% por ejemplo). Luego se mide la precisi\u00f3n del modelo en el 30% restante (set de validaci\u00f3n) que  son datos que no fueron utilizados a la hora de ajustar el modelo. Si utilizamos el MSE (mean squared error) c\u00f3mo medida del error, este va a ser nuestro test error estimado. Recordemos que es el MSE calculado con las predicciones en el set de validaci\u00f3n. Por otra parte el set de validaci\u00f3n tambi\u00e9n puede servir para ajustar alg\u00fan hiperpar\u00e1metro. Se pueden correr muchos modelos con distintos hiperpar\u00e1metros y ver cu\u00e1l tiene menor MSE en el set de validaci\u00f3n.  </p> <p>Es un m\u00e9todo muy sencillo y suele ser eficaz pero tiene dos potenciales problemas: * El MSE puede variar mucho seg\u00fan c\u00f3mo dividieron las observaciones en training y validaci\u00f3n. Otra segmentaci\u00f3n puede dar resultados muy distintos. * No utiliz\u00e1s todos tus datos para ajustar el modelo y puede que eso lleve a sobreestimar el test error, que quiz\u00e1s ser\u00eda menor si usaras todas las observaciones para entrenar el modelo.</p>","tags":["estadistica","ISLR","Introduction Statistical Learning","R"]},{"location":"writing/2019/07/01/metodos-de-resampleo/#leave-one-out-cross-validation","title":"Leave-One-Out Cross-Validation","text":"<p>LOOCV es un intento de solucionar los problemas del enfoque del set de validaci\u00f3n [SPOILER: No es recomendado pero vale la pena conocerlo]. Este enfoque es llevar el set de validaci\u00f3n al extremo. Lo que se hace es de nuevo separar nuestro training set en dos pero esta vez guardando una sola observaci\u00f3n como validaci\u00f3n y usando las n-1 restantes para entrenar el modelo. La idea es hacer esto n veces, dejando cada vez una observaci\u00f3n distinta como validaci\u00f3n. El test error estimado es el promedio de los MSE de cada predicci\u00f3n que se hizo de la observaci\u00f3n de validaci\u00f3n.  Pensando en los problemas del set de validaci\u00f3n, con LOOCV logramos usar casi todos los datos disponibles para entrenar el modelo (n-1 observaciones) por lo tanto deber\u00edamos tener modelos con menos sesgo y no sobreestimar tanto el test error como con el enfoque de set de validaci\u00f3n. Por otra parte con el set de validaci\u00f3n podemos obtener resultados muy distintos seg\u00fan el azar de c\u00f3mo dividamos nuestros datos. En LOOCV esto no pasa ya que todos nuestros modelos de entrenamiento van a ser practicamente iguales salvo por una observaci\u00f3n cada vez. No hay azar en la divisi\u00f3n de training y validaci\u00f3n.  Enseguida vemos el mayor problema de este enfoque, que es computacional. Debemos ajustar n modelos y no solo uno. Dependiendo de nuestros datos y la complejidad de nuestro modelo esto puede demandar much\u00edsimo tiempo/recursos.</p>","tags":["estadistica","ISLR","Introduction Statistical Learning","R"]},{"location":"writing/2019/07/01/metodos-de-resampleo/#k-fold-cross-validation","title":"K-Fold Cross-Validation","text":"<p>K-Fold CV es un punto intermedio entre ambos enfoques y es de lo m\u00e1s utilizado al d\u00eda de hoy. Consiste en separar nuestros datos en K subsets de mismo tama\u00f1o. Se selecciona uno de esos K subsets y se lo deja como validaci\u00f3n. Se entrena el modelo con los K-1 subsets y se predice en el de validaci\u00f3n que separamos. As\u00ed K veces, dejando como validaci\u00f3n cada vez uno subset distinto. El Test error estimado es el promedio de los MSE en cada caso. Se puede ver f\u00e1cilmente que si K = n, entonces estar\u00edamos en LOOCV. Los valores t\u00edpicos de K suelen ser 5 o 10, y por ende es much\u00edsimo menos costoso que LOOCV. Al separar en \"solo\" 10 subsets cada set de validaci\u00f3n puede tener cierta variabilidad en el MSE respecto a otros pero esta va a ser menor que en el enfoque de set de validaci\u00f3n. En el libro se muestran unos gr\u00e1ficos para data simulada donde se ve que LOOCV y K-Fold tienen comportamiento muy similar y seg\u00fan el caso pueden sobreestimar o subestimar el verdadero test error (depende el problema y la flexibilidad elegida). Como mencionamos para el set de validaci\u00f3n, K-fold tambi\u00e9n puede ser utilizado para ajustar alg\u00fan hiperpar\u00e1metro del modelo como el nivel de fleixibilidad. En este caso lo que nos interesa es encontrar el valor m\u00ednimo del MSE entre los distintos posibles valores del hiperpar\u00e1metro para decidir cual es el mejor posible pero el valor puntual del MSE o su precisi\u00f3n no nos interesa tanto.</p>","tags":["estadistica","ISLR","Introduction Statistical Learning","R"]},{"location":"writing/2019/07/01/metodos-de-resampleo/#trade-off-entre-sesgo-y-varianza-en-k-fold-cross-validation","title":"Trade-Off entre sesgo y varianza en K-Fold Cross-Validation","text":"<p>Otro punto muy importante de K-Fold, adem\u00e1s de que requiere menos intensidad computacional que LOOCV, es que suele dar estimaciones m\u00e1s precisas del test error que LOOCV, y esto tiene que ver por el tradeoff entre sesgo y varianza.</p> <p>Vimos antes que LOOCV deber\u00eda ser el estimar m\u00e1s insesgado del test error ya que utiliza casi todas las observaciones de entrenamiento cada vez sin embargo hay que ver que sucede con la varianza ya que es otro componente del MSE. (M\u00e1s detalles en ISLR Cap 2). Resulta que LOOCV tiene mayor varianza que K-Fold CV siempre que K sea menor que n. Esto sucede porque en LOOCV lo que hacemos es promediar el resultado de n modelos cuyos datos de entrenamiento son casi id\u00e9nticos (salvo por una observaci\u00f3n) y por ende los resultados est\u00e1n en gran medida correlacionados positivamente. Por otro lado al hacer K-Fold CV se promedian solo K resultados que est\u00e1n menos correlacionados entre s\u00ed ya que los datos de entrenamiento se solapan menos entre ellos.  La clave ac\u00e1 es que el promedio de muchos valores altamente correlacionados tiene mayor varianza que el promedio de muchos valores que no est\u00e1n tan correlacionados. Dado este escenario se hicieron pruebas que llegaron a la conclusi\u00f3n emp\u00edrica de que K=5 y k = 10 son valores que no suelen tener excesivo sesgo ni varianza. Al parecer en los \u00faltimos a\u00f1os se empez\u00f3 a dudar de la universalidad de este enunciado y se han hecho pruebas donde LOOCV no tiene mayor varianza. Sin embargo sigue siendo computacionalmente m\u00e1s demandante y el beneficio del menor sesgo no era suficiente para darle demasiada importancia.</p>","tags":["estadistica","ISLR","Introduction Statistical Learning","R"]},{"location":"writing/2019/07/01/metodos-de-resampleo/#cross-validation-en-problemas-de-clasificacion","title":"Cross-Validation en problemas de clasificaci\u00f3n.","text":"<p>Los procedimientos vistos hasta ahora son \u00fatiles tanto para variables continuas como para problemas de clasificaci\u00f3n. Vinimos usando ejemplos donde la medida del error era el MSE (variable dependiente continua) pero podemos aplicar todo de la misma manera utilizando alguna medida de clasificaci\u00f3n como la cantidad de observaciones mal clasificadas. Todo el resto se mantiene y es v\u00e1lido, tanto sete de validaci\u00f3n, como LOOCV o K-Fold.</p>","tags":["estadistica","ISLR","Introduction Statistical Learning","R"]},{"location":"writing/2019/07/01/metodos-de-resampleo/#bootstrap","title":"Bootstrap","text":"<p>El bootstrap es una herramienta estad\u00edstica muy extendida que se utiliza para cuantificar la incertidumbre asociada a alg\u00fan estimador o m\u00e9todo de aprendizaje estad\u00edstico. Un ejemplo sencilla ser\u00eda que se puede usar para estimar los errores est\u00e1ndar de los coeficientes de una regresi\u00f3n lineal. Sin embargo lo poderoso de esta herramienta es que es utilizable en much\u00edsimos m\u00e9todos de aprendizaje, incluso en algunos donde es dif\u00edcil estimar la varianza o esta no es calculado por los paquetes estad\u00edsticos. Idealmente para estimar la variabilidad de un estimador lo que uno har\u00eda es ajustar un modelo n veces y ver c\u00f3mo var\u00eda el estimador a lo largo de esos n modelos utilizando n muestras. Sin embargo no es habitual tener tantos datos ni muestras disponibles. Mismo uno querr\u00eda utilizar todos los datos en simult\u00e1neo posiblemente para reducir el sesgo. Ac\u00e1 es donde bootstrap se luce ya que permite emular el proceso de obtener nuevas muestras de datos a partir de nuestros datos de entrenamiento. En vez de muestrear de manera independiente sobre la poblaci\u00f3n lo que se hace es muestrear n veces con reposici\u00f3n de nuestro set de entrenamiento, generado n muestras a partir de nuestros datos originales. Ya con nuestras nuevas muestras (provenientes todas del dataset original) podemos calcular n modelos y por ende n veces el mismo estimador, pudiendo estimar el desv\u00edo est\u00e1ndar de este. En el fondo lo que se hace es suponer que nuestra muestra es representativa de la poblaci\u00f3n y es nuestra mejor aproximaci\u00f3n. Luego obtenemos muestras de estos datos que son nuestra versi\u00f3n reducida de la poblaci\u00f3n. Posiblemente haya alg\u00fan sesgo pero es una herramienta bastante \u00fatil para estimar la variabilidad de nuestros estimadores.</p> <p>Generamos un ejemplo para ver c\u00f3mo funciona.</p> <p>Empezamos generado una poblaci\u00f3n de y que depende x con intercepto 5 y b1 = 5.</p> <pre><code>library(ggplot2)\nset.seed(1)\nx &lt;-rnorm(10000, mean = 2, sd = 3)\ny &lt;- 4 + 5*x + rnorm(10000,0,4)\ndf &lt;- cbind.data.frame(y,x)\n\nggplot(data = df, aes( x =x, y =y )) + \n  geom_point()\n</code></pre> <p></p> <p>Primero vemos el caso ideal que ser\u00eda poder obtener muchas muestras de la poblaci\u00f3n y ajustar modelos a estas. Luego veremos como var\u00edan nuestros coeficientes.</p> <pre><code># Muestras de la poblaci\u00f3n\nresults_pop &lt;- data.frame(b0 = double(), b1 = double())\nset.seed(123)\nfor (i in 1:1000){\n  df_train &lt;- df[sample(nrow(df),size = 500,replace = FALSE),]\n  ml_train &lt;- lm(formula = y ~ x, data = df_train)\n  results_pop[i,1] = ml_train$coefficients[[1]]\n  results_pop[i,2] = ml_train$coefficients[[2]]\n\n}\n\nsummary(results_pop)\n</code></pre> <pre><code>##        b0              b1       \n##  Min.   :3.198   Min.   :4.804  \n##  1st Qu.:3.834   1st Qu.:4.969  \n##  Median :3.974   Median :5.005  \n##  Mean   :3.975   Mean   :5.004  \n##  3rd Qu.:4.115   3rd Qu.:5.043  \n##  Max.   :4.615   Max.   :5.169\n</code></pre> <pre><code>print(paste0(\"El desv\u00edo est\u00e1ndar de b0 a partir de 1000 modelos es \", sd(x = results_pop$b0)))\n</code></pre> <pre><code>## [1] \"El desv\u00edo est\u00e1ndar de b0 a partir de 1000 modelos es 0.207882713489026\"\n</code></pre> <pre><code>ggplot(data = results_pop) + \n  geom_histogram( aes( x = b0), fill = \"white\", colour = \"black\")  + \n  geom_vline( aes(xintercept = mean(b0)), colour = \"red\", size = 1)\n</code></pre> <p></p> <p>Vemos que estimando 1000 modelos a partir de 500 observaciones independientes de la poblaci\u00f3n original obtenemos para b0 estimaciones centradas aproximadamente en el valor real (3.975) pero con un m\u00ednimo encontrado en 3.198 y un m\u00e1ximo en 4.615. El desv\u00edo est\u00e1ndar de la estimaci\u00f3n es de 0.2078. A su vez mostramos un histograma de c\u00f3mo se distribuye la estimaci\u00f3n de b0.</p> <p>Ahora simulemos un caso real donde solo tenemos una muestra de 500 observaciones y es todo con lo que podemos trabajar. Como primera medida estimamos una regresi\u00f3n lineal y vemos qu\u00e9 par\u00e1metros ajustan mejor nuestros datos.</p> <pre><code># Muestras de la poblaci\u00f3n\nresults_sample &lt;- data.frame(b0 = double(), b1 = double())\nset.seed(456)\ndf_train_sample &lt;- df[sample(nrow(df),size = 500,replace = FALSE),]\nml_train_sample &lt;- lm(formula = y ~ x, data = df_train_sample)\n\nresults_sample[1,1] &lt;- ml_train_sample$coefficients[[1]]\nresults_sample[1,2] &lt;- ml_train_sample$coefficients[[2]]\n\nknitr::kable(results_sample, caption = \"Coefficients\")\n</code></pre> <p>Table: Coefficients</p> b0 b1 3.89621 5.025914 <p>Vemos que a partir de entrenar el modelo con las 500 observaciones obtenemos un intercepto de 3.896 y un b1 estimado de 5.026. Nosotros, como conocemos la poblaci\u00f3n, sabemos que el intercepto no es del todo preciso ya que el real es 4 sin embargo en un caso real eso no lo sabr\u00edamos. Nos interesar\u00eda saber qu\u00e9 variabilidad tiene ese coeficiente para tener una medida de qu\u00e9 tan variable es nuestro resultado. Para una regresi\u00f3n lineal eso se puede saber ya que no es dif\u00edcil calcular la varianza de los estimadores, pero con modelos m\u00e1s complicados no siempre se puede y ah\u00ed es donde bootstrap ayuda realmente. Ac\u00e1 lo hacemos con la regresi\u00f3n lineal porque es lo m\u00e1s sencillo de mostrar. Suponiendo que queremos obtener una estimaaci\u00f3n de la variabilidad del coeficiente estimado b0 procedemos con bootstrap.</p> <p>Fijense que lo que hacemos es distinto al primer caso. Ac\u00e1 tomamos 10000 muestras no de la poblaci\u00f3n sino de nuestro set de 500 observaciones. Estas muestras son tambi\u00e9n de 500 observaciones, la diferencia es que es con reposici\u00f3n por lo tanto una misma observaci\u00f3n puede figurar m\u00e1s de una vez.</p> <pre><code># Muestras de la poblaci\u00f3n\nresults_bootstrap &lt;- data.frame(b0 = double(), b1 = double())\nset.seed(789)\nfor (i in 1:10000){\n  df_train_bs &lt;- df[sample(nrow(df_train_sample),size = 500,replace = TRUE),]\n  ml_train_bs &lt;- lm(formula = y ~ x, data = df_train_bs)\n  results_bootstrap[i,1] = ml_train_bs$coefficients[[1]]\n  results_bootstrap[i,2] = ml_train_bs$coefficients[[2]]\n\n}\n\nsummary(results_bootstrap)\n</code></pre> <pre><code>##        b0              b1       \n##  Min.   :3.245   Min.   :4.791  \n##  1st Qu.:3.822   1st Qu.:4.982  \n##  Median :3.962   Median :5.020  \n##  Mean   :3.962   Mean   :5.019  \n##  3rd Qu.:4.100   3rd Qu.:5.057  \n##  Max.   :4.709   Max.   :5.205\n</code></pre> <pre><code>print(paste0(\"El desv\u00edo est\u00e1ndar de b0 a partir de 10000 modelos es \", sd(x = results_bootstrap$b0)))\n</code></pre> <pre><code>## [1] \"El desv\u00edo est\u00e1ndar de b0 a partir de 10000 modelos es 0.207126704818891\"\n</code></pre> <pre><code>ggplot(data = results_bootstrap) + \n  geom_histogram( aes( x = b0),fill = \"white\", colour = \"black\") + \n  geom_vline( aes(xintercept = mean(b0)), colour = \"blue\", size = 1)\n</code></pre> <p></p> <p>Voil\u00e0. Corrimos 10000 iteraciones de nuestro modelo a partir de 10000 muestras de nuestra data original. El desv\u00edo est\u00e1ndar de b0 para bootstrap qued\u00f3 de 0.2071. Que si comparamos con el de 1000 muestras independientes que era 0.2078 es pr\u00e1cticamente igual. A su vez, podemos calcular el desv\u00edo te\u00f3rico de b0 a partir del modelo (la soluci\u00f3n f\u00e1cil).</p> <pre><code>summary(ml_train_sample)\n</code></pre> <pre><code>## \n## Call:\n## lm(formula = y ~ x, data = df_train_sample)\n## \n## Residuals:\n##      Min       1Q   Median       3Q      Max \n## -13.2193  -2.8265   0.0281   2.7421  10.7577 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(&gt;|t|)    \n## (Intercept)  3.89621    0.21607   18.03   &lt;2e-16 ***\n## x            5.02591    0.05902   85.16   &lt;2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 3.98 on 498 degrees of freedom\n## Multiple R-squared:  0.9357, Adjusted R-squared:  0.9356 \n## F-statistic:  7252 on 1 and 498 DF,  p-value: &lt; 2.2e-16\n</code></pre> <p>Vemos que desde R el modelo nos devuelve que b0 tiene un desv\u00edo de 0.21607. Pr\u00e1cticamente igual al desv\u00edo de las muestras independientes como al de bootstrap. Por otra parte vemos que el promedio de b0 estimado en bootstrap es mucho m\u00e1s cercano a 4 que el estimado con una sola iteraci\u00f3n y qued\u00f3 mucho m\u00e1s cerca que el promedio de los estimados mediante muestras independientes. Nada mal no?</p>","tags":["estadistica","ISLR","Introduction Statistical Learning","R"]},{"location":"writing/2019/10/13/teorema-central-del-limite/","title":"Teorema Central del Limite","text":"<p>El teorema central del l\u00edmite (TCL)  es fundamental en el desarrollo de la estad\u00edstica y ha obtenido distintas variantes a lo largo de la historia. Veremos dos de las versiones m\u00e1s conocidas.</p>","tags":["estadistica","r","simulacion"]},{"location":"writing/2019/10/13/teorema-central-del-limite/#teorema-central-del-limite-para-media-muestral-lindeberg-levy","title":"Teorema Central del L\u00edmite para Media Muestral (Lindeberg - L\u00e9vy)","text":"<p>Si las varaibles \\(X_1 ... X_n\\) forman una muestra aleatoria de tama\u00f1o n proveniente de una  distribuci\u00f3n con media \\(\\mu\\) y varianza \\(\\sigma^2\\) (0 &lt; \\(\\sigma^2\\) &lt; \\(\\infty\\)), entonces  para  cualquier n\u00famero fijo x. $$  \\lim_{n\\to \\infty} Pr\\Big[\\frac{n^{\u00bd}(\\bar X_n - \\mu)}{\\sigma} &lt;= x\\Big] = \\Phi (x)$$</p> <p>Donde \\(\\Phi (x)\\) es la funci\u00f3n de distribuci\u00f3n de una Normal Est\u00e1ndar.</p> <p>El por qu\u00e9 de la convergencia del teorema no ser\u00e1 probado ac\u00e1 pero no es d\u00edficil de encontrar. Por ejemplo AC\u00c1</p> <p>B\u00e1sicamente lo que dice el teorema, es que tomando una muestra grande de una poblaci\u00f3n con media \\(\\mu\\) y  varianza \\(\\sigma^2\\) definidas, entonces \\(\\frac{n^{1/2}(\\bar X_n - \\mu)}{\\sigma}\\) va a tender a una normal est\u00e1ndar. Como consecuencia de eso podemos decir que \\(\\bar X_n\\) va a distribuirse  aproximandamete como \\(N(\\mu, \\sigma^2/n)\\).</p> <p>El TCL nos dice c\u00f3mo se distribuye la media muestral si tenemos una muestra grande.</p> <p>An\u00e1logamente, tambi\u00e9n podemos decir que \\(\\sum_{i=1}^n X_i\\) va a ser aproximadamente una normal \\(N(n\\mu, n\\sigma^2)\\)</p>","tags":["estadistica","r","simulacion"]},{"location":"writing/2019/10/13/teorema-central-del-limite/#ejemplo-lanzar-una-moneda","title":"Ejemplo. Lanzar una moneda","text":"<p>Si lanzamos una moneda 900 veces. Cu\u00e1l es la probabilidad  de obtener m\u00e1s de 495 caras?</p> <p>\\(X_i\\) = 1 si sale cara en el lanzamiento i, y 0 si sale cruz. E(\\(X_i\\)) = \u00bd y Var(\\(X_i\\)) = \u00bc. Esto se deduce de ser un experimento con distribuci\u00f3n Bernouilli.</p> <p>Para llevarlo a los t\u00e9rminos del TCL, tenemos una muestra de tama\u00f1o n = 900, con \\(\\mu\\) = \u00bd y \\(\\sigma^2\\) = \u00bc.</p> <p>Por TCL tenemos que la distribuci\u00f3n de la suma del n\u00famero total de caras \\(\\sum_{i=1}^{900} X_i\\) se distribuye aproxim\u00e1damente como una normal con media = 900 * (\u00bd) = 450, varianza = 900 * (\u00bc) = 225 y desv\u00edo est\u00e1ndar 225^(\u00bd) = 15.</p> <p>Por lo tanto la variable \\(Z = \\frac{H - 450}{15}\\) se dsitribuye aproximadamente como una normal  est\u00e1ndar. \\(\\(Pr( H &gt; 495) = Pr(\\frac{H - 450}{15} &gt; \\frac{495 - 450}{15}) = Pr(Z&gt;3) = 1 - \\Phi(3) = 0.0013\\)\\)</p> <p>Podemos comparar contra el resultado que obtenemos al hacer el mismo ejercicio pero mirando  directamente la distribuci\u00f3n binomial (que es la que realmente genera el proceso de datos)</p> <pre><code>pbinom(495,900, 0.5, lower.tail = FALSE)\n</code></pre> <pre><code>## [1] 0.001200108\n</code></pre> <p>Vemos que los resultados son muy similares.</p>","tags":["estadistica","r","simulacion"]},{"location":"writing/2019/10/13/teorema-central-del-limite/#teorema-central-del-limite-para-suma-de-variables-aleatorias-independientes-liapunov","title":"Teorema Central del L\u00edmite para Suma de Variables Aleatorias Independientes (Liapunov)","text":"<p>Este TCL aplica a una secuencia de variables aleatorias independientes pero que no necesariamente tienen que provenir de una misma distribuci\u00f3n. Todas deben tener una media y varianza definidas.</p> <p>La variable \\(\\(Y_n = \\frac{\\sum_{i=1}^n X_i - \\sum_{i=1}^2 \\mu_i}{(\\sum_{i=1}^n\\sigma_i^2)^{1/2}}\\)\\)</p> <p>Entonces \\(E(Y_n) = 0\\) y \\(Var(Y_n)\\) = 1</p> <p>Siendo un poco m\u00e1s precisos veamos el teorema:</p> <p>Suponiendo que las variables aleatorias \\(X_1. X_2, ...\\)  son independientes y que \\(E(|X_i - \\mu_i|^3) &lt; \\infty\\) para 1,2,... Y suponidendo que \\(\\(\\lim_{n\\to \\infty} \\frac{\\sum_{i=1}^n E(|X_i - \\mu_i|^3)}{(\\sum_{i=1}^n \\sigma^2_i)^{3/2}} = 0\\)\\) Entonces, utilizando la variable Y definida previamente tenemos que \\(\\(\\lim_{n \\to \\infty} Pr(Y_n &lt;= x) = \\Phi(x)\\)\\)</p> <p>La interpretacai\u00f3n del teorema es que si se cumple la condici\u00f3n de los 3eros momentos, entonces para valores grandes de n la distribuci\u00f3n de \\(\\sum_{i=1}^n X_i\\) ser\u00e1 aproximadamente normal con media \\(\\sum_{i=1}^n \\mu_i\\) y varianza \\(\\sum_{i=1}^n \\sigma^2_i\\).</p>","tags":["estadistica","r","simulacion"]},{"location":"writing/2019/10/13/teorema-central-del-limite/#diferencias-entre-lindeberg-levy-y-liapunov","title":"Diferencias entre Lindeberg-L\u00e9vy y Liapunov","text":"<p>El teorema de Lindeberg-L\u00e9vy aplica para secuencias de variables aleatorias iid y solo requiere que la varianza de estas variables sea finita. En cambio el teorema de Liapunov aplica a secuencias de variables aleatorias independientes pero que no necesariamente provienen de una misma distribuci\u00f3n. Requiere que el tercer momento de cada variable existe y cumple con la ecuaci\u00f3n del teorema.</p>","tags":["estadistica","r","simulacion"]},{"location":"writing/2019/10/13/teorema-central-del-limite/#efecto-de-tcl","title":"Efecto de TCL","text":"<p>M\u00e1s all\u00e1 de la utilidad para aproximar distribuciones y medias mediante una normal, el TCL aporta una posible explicaci\u00f3n a por qu\u00e9 tantas variables se distribuyen aproximadamante como normales. Si muchas de las variables a medir pueden pensarse como sumas de otras variables es l\u00f3gico que tiendan a verse como normales aunque las variables que se suman para darle origen provengan de distintas distribuciones.</p>","tags":["estadistica","r","simulacion"]},{"location":"writing/2019/10/31/maxima-verosimilitud-y-estimacion-bayesiana/","title":"Maxima Verosimilitud y estimacion bayesiana","text":"","tags":["estadistica","R"]},{"location":"writing/2019/10/31/maxima-verosimilitud-y-estimacion-bayesiana/#distribucion-prior","title":"Distribucion prior","text":"<p>A falta de una buena traducci\u00f3n usamos este t\u00e9rmino.</p> <p>Supongamos que se toman muestras aleatorias de una distribucion con pdf (funcion de densidad de probabilidad) \\(f(x|\\theta)\\). Por ejemplo podr\u00edan provenir de una normal con media = \\(\\mu\\) y varianza = 4. Nosotros no sabemos el valor de \\(\\mu\\) pero podemos tener una idea de qu\u00e9 valores puede tomar y tener en mente una distribuci\u00f3n prior de este par\u00e1metro \\(\\epsilon(\\theta)\\). Para el ejemplo ser\u00eda \\(\\epsilon(\\mu)\\). Podemos suponer que \\(\\mu\\) se distribuye como una uniforme (0,1) por decir algo. El concepto radica en tener una distribuci\u00f3n prior para los par\u00e1metros de la distribuci\u00f3n de la cual tomamos muestras aleatorias.</p>","tags":["estadistica","R"]},{"location":"writing/2019/10/31/maxima-verosimilitud-y-estimacion-bayesiana/#distribucion-posterior","title":"Distribuci\u00f3n Posterior","text":"<p>Volviendo a nuestra muestra \\(X_1...X_n\\) proveniente de \\(f(x|\\theta)\\), podemos decir, debido a que son observaciones aleatorias e independientes que su distribuci\u00f3n conjunta es \\(f_n(x_1...X_n|\\theta) = f(x_1|\\theta)...f(x_n|\\theta)\\), que lo podemos escribir como \\(f_n(x|\\theta)\\). Dado que suponemos que \\(\\theta\\) proviene de una distribuci\u00f3n \\(\\epsilon(\\theta)\\), la pdf conjunta \\(f_n(x|\\theta)\\) tiene que ser vista como la pdf conjunta condicional de\\(X_1...X_n\\) para un valor particular de \\(\\theta\\). Multiplicando la pdf conjunta condicional por la pdf \\(\\epsilon(\\theta)\\) obtenemos la (n+1) distribuci\u00f3n conjunta de \\(X_1...X_n\\) y \\(\\theta\\) bajo la forma \\(f_n(x|\\theta)\\epsilon(\\theta)\\). Ser\u00eda la pdf de encontrar en simult\u00e1neo determinados valores para x y \\(\\theta\\). La probabilidad conjunta marginal de \\(X_1...X_n\\) se encuentra integrando la pdf conjunta con \\(\\theta\\) para todos los valores de \\(\\theta\\). Ser\u00eda la probabilidad marginal de encontrar determinados valores de x (sabiendo la distribuci\u00f3n de \\(\\theta\\) pero sin saber el valor puntual que toma).</p> <p>\\(g_n(x) = \\int_\\Omega f_n(x|\\theta)\\epsilon(\\theta) d\\theta\\)</p> <p>Por teorema de Bayes tenemos que la distribuci\u00f3n posterior de \\(\\theta\\), es decir, dados los x es: \\(\\(\\epsilon(\\theta|x) = \\frac{f_n(x|\\theta)\\epsilon(\\theta)}{g_n(x)} \\text{ para } \\theta \\in \\Omega\\)\\)   Se dice que la distribuci\u00f3n prior \\(\\epsilon(\\theta)\\) representa la verosimilitud, antes de ver los valores de \\(X_1...X_n\\), de que el verdadero valor de \\(\\theta\\) se encuentre en cada una de las regiones de \\(\\Omega\\) y que la pdf de la distribuci\u00f3n posterior \\(\\epsilon(\\theta|x)\\) representa la verosimilitud despu\u00e9s que los valores \\(X_1 = x_1,...,X_n = x_n\\) hayan sido observados.</p> <p>## La funcion de Versoimilitud</p> <p>El denominador de la distribuci\u00f3n posterior es b\u00e1sicamente la integral del numerador para todos los posibles valores de \\(\\theta\\). Depende de los valores observados \\(X_1...X_n\\) pero no de \\(\\theta\\), por lo que puede considerarse constante en este contexto.  Dado que es una constante podemos quitarla de la distribuci\u00f3n posterior que vimos y decir que   \\(\\(\\epsilon(\\theta|x) \\propto f_n(x|\\theta)\\epsilon(\\theta)\\)\\)</p> <p>Cuando se ve \\(f_n(x|\\theta)\\) para una muestra aleatoria como funci\u00f3n de \\(\\theta\\), se la suele llamar funci\u00f3n de verosimilitud. En ingl\u00e9s: Likelihood function.</p> <p>Juntando estos t\u00e9rminos podemos decir que la pdf posterior de \\(\\theta\\) es proporcional al producto de la funci\u00f3n de verosimilitud y la pdf prior de \\(\\theta\\).  </p> <p>La idea de ver esta relaci\u00f3n de proporcionalidad es para poder calcular la pdf posterior evitando calcular la integral del denomiador \\(g_n(x)\\). Si el numerador tiene la forma de alguna de las distribuciones conocidad (normal, beta, gamma, uniforme, etc) es posible calcular f\u00e1cilmente el factor constante por el cual multiplicar esa pdf para llegar a la posterior.</p>","tags":["estadistica","R"]},{"location":"writing/2019/10/31/maxima-verosimilitud-y-estimacion-bayesiana/#distribuciones-prior-conjugadas","title":"Distribuciones prior Conjugadas","text":"<p>Este concepto refiere a que ciertas distribuciones son particularmente \u00fatiles para los c\u00e1lculos cuando las variables aleatorias observadas provienen de alguna distribuci\u00f3n espec\u00edfica. Es decir que seg\u00fan la distribuci\u00f3n de la que provienen las X puede que haya alguna distribuci\u00f3n conjugada tal que al asumirla para la pdf prior \\(\\epsilon(\\theta)\\) ya sabemos que la distribuci\u00f3n posterior tambi\u00e9n ser\u00e1 de esa familia.</p> <p>Un ejemplo ilustrador:   Supongamos que tomamos observaciones \\(X_1...X_n\\) de una distribuci\u00f3n Bernoulli de la cual no sabemos el par\u00e1metro \\(\\theta\\) (que debe estar entre 0 y 1). Supongamos adem\u00e1s que la pdf prior de \\(\\theta\\) es una distribuci\u00f3n beta con alg\u00fanos par\u00e1metros dados \\(\\alpha \\text{ y } \\beta\\). En este caso sabemos que por ser un caso de distribuci\u00f3n conjugada, la pdf posterior de \\(\\theta\\) dado \\(X = x_i (i = 1,...,n)\\) es a su vez una distribuci\u00f3n beta con par\u00e1metros \\(\\alpha + \\sum_{i=1}^n x_i \\text{ y } \\beta + n - \\sum_{i=1}^n x_i\\).</p> <p>Seg\u00fan la distribuci\u00f3n de la que provengan las observaciones hay distintas distribuciones conjugadas que son las m\u00e1s convenientes para ese caso.</p>","tags":["estadistica","R"]},{"location":"writing/2019/10/31/maxima-verosimilitud-y-estimacion-bayesiana/#estimacion-de-parametros","title":"Estimaci\u00f3n de par\u00e1metros","text":"<p>La idea es estimar alg\u00fan par\u00e1metro de la distribuci\u00f3n de la cual se obtienen los datos observados. El valor estimado del par\u00e1metro va a depender de dos cosas:  </p> <ul> <li>Del estimador que hayamos elegido (es decir, la funci\u00f3n de los datos elegida)</li> <li>De la muestra. El valor estimado va a depender de los datos aleatorios que tengamos de la distribuci\u00f3n.</li> </ul> <p>Como el estimador depende de la muestra podemos verlo a su vez como una variable aleatoria.</p>","tags":["estadistica","R"]},{"location":"writing/2019/10/31/maxima-verosimilitud-y-estimacion-bayesiana/#funcion-de-perdida","title":"Funci\u00f3n de p\u00e9rdida","text":"<p>Lo que queremos de un estimador es que devuelva un valor estimado \"a\" para el par\u00e1metro lo m\u00e1s cercano posible al verdadero valor de \\(\\theta\\). La funci\u00f3n de p\u00e9rdida es una funci\u00f3n que cuantifica esto. $$ L(\\theta,a)$$ Hay algunas funciones habituales pero pueden adecuarse seg\u00fan el problema. Podemos decir que en general lo que se busca es encontrar una estimaci\u00f3n para la cual la esperanza de la p\u00e9rdida sea un m\u00ednimo.</p>","tags":["estadistica","R"]},{"location":"writing/2019/10/31/maxima-verosimilitud-y-estimacion-bayesiana/#estimador-bayesiano","title":"Estimador bayesiano","text":"<p>Si tenemos una muestra aleatoria y una pdf posterior para \\(\\theta\\) entonces el valor esperado de la p\u00e9rdida para cualquier valor estimado \"a\" es: \\(\\(E[L(\\theta,a)|x] = \\int_\\Omega L(\\theta,a)\\epsilon(\\theta,x)d\\theta\\)\\)</p> <p>Lo que buscamos es encontrar un valor de a cuya p\u00e9rdida esperada sea m\u00ednima. La funci\u00f3n que genera un valor de a m\u00ednimo para cada posible valor de X ser\u00e1 un estimador de \\(\\theta\\) y en particular se llamar\u00e1 Estimador Bayesiano. El estimador bayesiano, que minimiza la p\u00e9rdida esperada para cualquier set de datos X, va a depender de la funci\u00f3n de p\u00e9rdida que elijamos y de la pdf prior que se elija para \\(\\theta\\).</p> <p>Por ejemplo,para la funci\u00f3n de p\u00e9rdida m\u00e1s utilizada, que es la de error cuadr\u00e1tico \\(\\(L(\\theta,a) = (\\theta -a)^2\\)\\) est\u00e1 demostrado que la p\u00e9rdida es m\u00ednima cuando \\(a\\) es la media de la distribuci\u00f3n posterior \\(E(\\theta|x)\\).</p> <p>Dijimos que el valor del estimador bayesiano va a depender de la distribuci\u00f3n prior elegida. Esto es cierto, pero hay que tener en cuenta que para muestras grandes las diferencias empiezan a achicarse y los estimadores bayesianos provenientes de distintos priors empiezan a converger en la mayor\u00eda de los casos.</p>","tags":["estadistica","R"]},{"location":"writing/2019/10/31/maxima-verosimilitud-y-estimacion-bayesiana/#estimadores-de-maxima-verosimilitud","title":"Estimadores de M\u00e1xima Verosimilitud","text":"<p>Los estimadores de m\u00e1xima verosimilitud (MLE) son muy comunmente usados para estimar par\u00e1metros desconocidos ya que m\u00e1s all\u00e1 de la discusi\u00f3n casi filos\u00f3fica de \"bayesianos vs frecuentistas\", sirven para estimar sin tener que definir una funci\u00f3n de p\u00e9rdida ni una distribuci\u00f3n prior para los par\u00e1metros. Esto \u00faltimo es importante ya que para casos donde se necesita estimar un vector de par\u00e1metros, la distribuci\u00f3n prior debe ser una multivariada que englobe a todos y eleva la complejidad del proceso bayesiano ampliamente. Para muestras chicas MLE suele hacer un trabajo decente y para muestras grandes suele ser excelente por lo que se llega a resultados muy similares a trav\u00e9s de un proceso m\u00e1s directo y m\u00e1s sencillo.  </p> <p>Para estimar mediante MLE lo \u00fanico que necesitamos es la funci\u00f3n de verosimilitud ya definida. \\(\\(f_n(x_1...X_n|\\theta)\\)\\) Luego lo \u00fanico que se hace es buscar el par\u00e1metro \\(\\hat \\theta\\) (estimado) que maximice esa funci\u00f3n. B\u00e1sicamente es buscar qu\u00e9 par\u00e1metro hace que la probabilidad conjunta de obtener esos valores de X sea m\u00e1xima? Ese es nuestro MLE.</p> <p>Para la gran mayor\u00eda de los casos esta metodolog\u00eda funciona pero hay que tener en cuenta que es posible que para algunos problemas no haya un m\u00e1ximo para la funci\u00f3n de verosimilitud o que haya m\u00e1s de un punto, en cuyo caso hay que elegir alguno de ellos.</p>","tags":["estadistica","R"]},{"location":"writing/2019/10/31/maxima-verosimilitud-y-estimacion-bayesiana/#mle-en-bernoulli","title":"MLE en Bernoulli","text":"<p>Supongamos que tomamos observaciones \\(X_1...X_n\\) de una distribuci\u00f3n Bernoulli de la cual no sabemos el par\u00e1metro \\(\\theta\\) (que debe estar entre 0 y 1).</p> <p>Para cualquier vector de observaciones \\(X_1...X_n\\) la funci\u00f3n de verosimilitud es: $$ f_n(x|\\theta) = \\prod_{i = 1}^n \\theta<sup>{x_i}(1-\\theta)</sup>$$ El valor de \\(\\theta\\) que maximice la funci\u00f3n de verosimilitud es el mismo valor que maximiza \\(log f_n(x|\\theta)\\), por lo que es conveniente encontrar tal valor buscando que maximice: \\(\\(L(\\theta) = log f_n(x|\\theta) = \\sum_{i=1}^n[x_i log \\theta + (1 - x_i) log(1-\\theta)] = (\\sum_{i=1}^nx_i)log \\theta + (n-\\sum_{i=1}^n x_i) log (1-\\theta)\\)\\)</p> <p>Si derivamos \\(dL(\\theta) / d\\theta\\) e igualamos a 0, resolviendo esa ecuando para \\(\\theta\\) encontramos que \\(\\theta = \\bar x_n\\). Este valor maximiza el logaritmo de la funci\u00f3n de verosimilitud y por ende tambi\u00e9n de la funci\u00f3n de verosimilitud en s\u00ed misma. Por lo tanto el MLE de \\(\\theta\\) es \\(\\hat \\theta = \\bar X_n\\)</p> <pre><code># Generamos 100 observaciones de una Bernoulli\nset.seed(150)\ndata = rbinom(100, 1, prob = 0.723)\n\n# Calculamos su promedio, que ya sabemos es la mejor estimaci\u00f3n para p dados los datos\nmean(data)\n</code></pre> <pre><code>## [1] 0.68\n</code></pre> <pre><code># Definimos funci\u00f3n de verosimilitud\n# Es la pdf de una Bernoulli para cada observaci\u00f3n y sumamos sus logaritmos (en negativo porque \n# el optimizador minimiza en vez de maximizar)\nLL = function( p){\n   R = dbinom(x = data, size = 1, prob = p)\n\n   -sum(log(R))  # Negativo porque log de probabilidades es &lt;0.\n }\n\n# Funci\u00f3n que busca los par\u00e1metros que minimzan el negativo de la log verosimilitud\n# Elegimos un valor inicial de p en el medio.\nstats4::mle(LL, start = list(p = 0.5) )\n</code></pre> <p><pre><code>## \n## Call:\n## stats4::mle(minuslogl = LL, start = list(p = 0.5))\n## \n## Coefficients:\n##         p \n## 0.6799996\n</code></pre> Vemos que la estimaci\u00f3n por MLE es id\u00e9ntica a la media. No corresponde con el verdadero valor del par\u00e1metro poblacional p debido a la muestra particular que fue seleccionada.</p> <p>Algunos comentarios finales:</p> <ul> <li>En algunos casos no es posible encontrar la soluci\u00f3n \u00f3ptima si no es por m\u00e9todos num\u00e9ricos.</li> <li>Cuando \\(n \\to \\infty\\) MLE converge en probabilidad al verdadero \\(\\theta\\). Por ende cuando \\(n \\to \\infty\\) el estimador bayesiano (que cumple la misma propiedad) y MLE ser\u00e1n muy parecidos entre s\u00ed y al verdadero \\(\\theta\\).</li> <li>MLE solo depende de las observaciones y no de c\u00f3mo y en qu\u00e9 orden fueron recolectadas.</li> </ul>","tags":["estadistica","R"]},{"location":"writing/2019/11/11/distintas-distancias/","title":"Distintas Distancias","text":"<pre><code>library(tidyverse)\n</code></pre> <p>Si tenemos un espacio euclideo, es decir, una linea, un plano o un hiperplano, que son los espacios t\u00edpicos de la geometr\u00eda cl\u00e1sica, podemos calcular la distancia entre dos puntos que se hayen en \u00e9l.</p> <p>Es decir, cu\u00e1l es la distancia entre los puntos A (1,1) y B (1,0) en un plano? Empecemos pensando en los casos donde todos los valores del vector son num\u00e9ricos.</p> <pre><code>A = c(0,0,1,1)\nB = c(0,0,1,0)\nrecta = c(1,1,1,0)\ndf = as.data.frame(matrix(data = c(A,B, recta),\n                          nrow = 4, \n                          ncol = 4,\n                          byrow = TRUE )) %&gt;%\n  rename( x0 = V1,\n          y0 = V2,\n          x1 = V3,\n          y1 = V4)\n\n\nggplot(data=df[1:2,], aes(x=x0, y=y0)) + \n  geom_segment(aes(xend=x1, yend=y1),\n               arrow = arrow(length = unit(0.3,\"cm\"))) + \n  geom_point( aes(x = x1, y = y1), \n              color = \"red\", size = 2)\n</code></pre> <p></p>","tags":["algebra","estadistica","r"]},{"location":"writing/2019/11/11/distintas-distancias/#distancia-euclideana","title":"Distancia Euclideana","text":"<p>La m\u00e9trica m\u00e1s habitual que se utiliza es la distancia euclideana, que consiste en la recta que une ambos puntos. </p> <pre><code>ggplot(data=df[1:2,], aes(x=x0, y=y0))+\n  geom_segment(aes(xend=x1, yend=y1),\n               arrow = arrow(length = unit(0.3,\"cm\"))) + \n  geom_point(aes(x = x1, y = y1), \n               color = \"red\", size = 2) + \n  geom_segment(data = df[3,], \n               aes(xend=x1, yend=y1),\n               color = \"blue\", \n               arrow = arrow(length = unit(0.3,\"cm\")))\n</code></pre> <p></p> <p>Esta distancia se calcula con: \\(\\(d(A,B) = d(B,A) = \\sqrt{(A_1 - B_1)^2 + (A_2 - B_2)^2 + ... + (A_n - B_n)^2}   = \\sqrt{\\sum_{i=1}^n (A_i - B_i)^2}\\)\\)</p> <p>Como se ve en la imagen, los puntos A y B pueden verse como vectores que inician en el origen (0,0). La distancia euclidea es a su vez la distancia entre sus puntas, que a su vez puede pensarse como un vector de desplazamiento (de A a B por ejemplo).</p> <p>En este caso la distancia euclidea es: \\(\\(d(A,B) = \\sqrt{ (1-1)^2 + (1 - 0)^2} = 1\\)\\) Y que es algo visible en el gr\u00e1fico.</p> <p>De manera m\u00e1s general, podemos definir toda una familia de distancias en el espacio euclideo. Las distancias de Minkowsky.</p> <p>La distancia Minkowsky de orden p es: \\(\\(d(A,B) = d(B,A) = \\Bigg({\\sum_{i=1}^n |A_i - B_i|^p}\\Bigg)^{1/p}\\)\\)</p> <p>Vemos que si p = 2, entonces la distancia de Minkowsky no es otra que la distancia euclideana.</p>","tags":["algebra","estadistica","r"]},{"location":"writing/2019/11/11/distintas-distancias/#distancia-de-manhattan","title":"Distancia de Manhattan","text":"<p>Otro valor que suele tomarse para p es p = 1, y eso corresponde a la distancia de Manhattan.</p> <p>Esta distancia se calcula con: \\(\\(d(A,B) = d(B,A) =  |A_1 - B_1| + |A_2 - B_2| + ... + |A_n - B_n|   =\\sum_{i=1}^n |A_i - B_i|\\)\\)</p> <p>Es b\u00e1sicamente la suma de las diferencias absolutas entre las distintas dimensiones de los vectores.</p> <p>Luce asi.</p> <pre><code>A = c(0,0,3,3)\nB = c(0,0,2,1)\nrecta = c(2,1,3,3)\nmanhattan1 = c(2,1,3,1)\nmanhattan2 = c(3,1,3,3)\n\ndf = as.data.frame(matrix(data = c(A,B, recta, manhattan1, manhattan2),\n                          nrow = 5, \n                          ncol = 4,\n                          byrow = TRUE )) %&gt;%\n  rename( x0 = V1,\n          y0 = V2,\n          x1 = V3,\n          y1 = V4)\n\n\nggplot(data=df[1:2,], aes(x=x0, y=y0)) + \n    geom_point( aes(x = x1, y = y1), \n              color = \"red\", size = 2) + \n      geom_segment(data = df[3,], \n               aes(xend=x1, yend=y1, color = \"blue\"),\n               #color = \"blue\", \n               arrow = arrow(length = unit(0.3,\"cm\"))) +\n      geom_segment(data = df[4,], \n               aes(xend=x1, yend=y1,  color = \"green\",),\n               #color = \"green\", \n               arrow = arrow(length = unit(0.3,\"cm\"))) + \n      geom_segment(data = df[5,], \n               aes(xend=x1, yend=y1),\n               color = \"green\", \n               arrow = arrow(length = unit(0.3,\"cm\"))) +\n      scale_colour_manual(name = 'the colour', \n         values =c('blue'='blue','green'='green'),\n         labels = c('Euclideana','Manhattan'))\n</code></pre> <p></p> <p>Vemos como el valor abosluto imposibilita ir en direcci\u00f3n diagonal. Lo que se logra es medir la distancia como si hubiera una grilla como la del gr\u00e1fico. Su nombre proviene de su utilizaci\u00f3n para medir distancias al interior de una ciudad (uno no puede cruzar las manzanas por el medio!).</p> <p>Para saber cual conviene utilizar hay que pensar en el problema en cuesti\u00f3n. </p> <ul> <li>Ya sea medir distancias en ciudades o donde haya restricciones de ese tipo puede que Manhattan sea m\u00e1s apropiado.  </li> <li>Por otra parte al no elevar al cuadrado le da menos pesos a las grandes distancias o mismo outliers por lo que puede ser otro motivo v\u00e1lido.  </li> <li>Por \u00faltimo, algunos trabajos argumentan que es m\u00e1s adecuada en problema de alta dimensionalidad (o mismo valores menores a 1 en el exponente de la formula de Minkowsky)</li> </ul>","tags":["algebra","estadistica","r"]},{"location":"writing/2019/11/11/distintas-distancias/#similaridad-coseno","title":"Similaridad coseno","text":"<p>La similaridad coseno se utiliza cuando se quiere ver la similitud \"angular\" entre dos observaciones y no la distancia en el plano. Es decir, vemos la direcci\u00f3n pero no la magnitud</p> <pre><code>A = c(0,0,1,1)\nB = c(0,0,2,2)\nC = c(0,0,5,0)\n\ndf = as.data.frame(matrix(data = c(A,B,C),\n                          nrow = 3, \n                          ncol = 4,\n                          byrow = TRUE )) %&gt;%\n  rename( x0 = V1,\n          y0 = V2,\n          x1 = V3,\n          y1 = V4)\n\n\nggplot(data=df[1:3,], aes(x=x0, y=y0 )) + \n  geom_segment(aes(xend=x1, yend=y1),\n               arrow = arrow(length = unit(0.3,\"cm\"))) + \n  geom_point( aes(x = x1, y = y1), \n              color = \"red\", size = 2) + \n  geom_text(aes(x=x1, y = y1, label = c(\"A\",\"B\",\"C\")),\n            vjust = -0.5)\n</code></pre> <p></p> <p>Si hicieramos la distancia euclideando entre A y B obtendriamos el valor de la distancia en el plano, sin embargo podemos ver que se encuentran sobre la misma recta y por lo tanto su direcci\u00f3n es la misma. La similaridad coseno mide el \u00e1ngulo entre dos puntos. En este caso el \u00e1ngulo entre A y B es 0, y por ende su similaridad coseno es 1. Ambas tendr\u00edan la misma similaridad con cualquier otro punto de la misma recta, por m\u00e1s alejado que est\u00e9. Respecto a C, tanto A y B tiene comparten el \u00e1ngulo por lo tanto la similaridad coseno entre A y C ser\u00e1 la misma que entre B y C.</p> <pre><code>cosA = c(1,1)\ncosB = c(2,2)\ncosC = c(5,0)\n\n# Similaridad coseno entre A y B\nlsa::cosine(cosA, cosB)[[1]]\n</code></pre> <pre><code>## [1] 1\n</code></pre> <pre><code># Similaridad coseno entre A y C\nlsa::cosine(cosA, cosC)[[1]]\n</code></pre> <pre><code>## [1] 0.7071068\n</code></pre> <pre><code># Similaridad coseno entre B y C\nlsa::cosine(cosC, cosB)[[1]]\n</code></pre> <pre><code>## [1] 0.7071068\n</code></pre> <p>Hay que tener en cuenta el contexto de nuestro problema para decidir qu\u00e9 medida de distancia usar. Por ejemplo la similaridad coseno se usa de manera est\u00e1ndar en an\u00e1lisis de texto (text mining).</p>","tags":["algebra","estadistica","r"]},{"location":"writing/2019/11/11/distintas-distancias/#distancia-de-mahalanobis","title":"Distancia de Mahalanobis","text":"<p>La distancia de Mahalanobis tiene la particularidad que mide la distancia entre un punto (P) y una distribuci\u00f3n de datos (D). Si tenemos una nube de puntos correspondiente a una distribuci\u00f3n D, cuanto m\u00e1s cerca est\u00e9 P del centro de masa (o \"promedio\") m\u00e1s cerca se encuetran P y D. Intuitivamente sirve para pensar si P puede pertenecer a D o no. Dado que la nube de puntos no tiene por qu\u00e9 ser una esfera (donde cada direcci\u00f3n tiene la misma cantidad de puntos), hay que tener en cuenta c\u00f3mo se dispersan los puntos alrededor del centro de masa.</p> <p>No es lo mismo, </p> <pre><code>esfera = as.data.frame(MASS::mvrnorm(1000, mu = c(3,3), \n                                     Sigma = matrix(c(1,0,0,1),\n                                                    nrow = 2,\n                                                    ncol = 2)))\n\nggplot(data = esfera, aes(x = V1, y = V2)) + \n  geom_point() + \n  geom_point(data = as.data.frame(matrix(c(6,2),ncol = 2)), \n             aes(x = V1, y = V2), color = \"red\") + \n  geom_text(data = as.data.frame(matrix(c(6,2),ncol = 2)),\n            aes(x = V1, y = V2,label = \"P\"),\n            vjust = 1.5, color = \"blue\") +\n  labs(title = \"Distribuci\u00f3n esf\u00e9rica\")\n</code></pre> <p></p> <p>que,</p> <pre><code>elipse = as.data.frame(MASS::mvrnorm(1000, mu = c(3,3), \n                                     Sigma = matrix(c(1,0.6,0.6,1),\n                                                    nrow = 2,\n                                                    ncol = 2)))\n\n\n\nggplot(data = elipse, aes(x = V1, y = V2)) + \n  geom_point() + \n  geom_point(data = as.data.frame(matrix(c(6,2),ncol = 2)), \n             aes(x = V1, y = V2), color = \"red\") + \n  geom_text(data = as.data.frame(matrix(c(6,2),ncol = 2)),\n            aes(x = V1, y = V2,label = \"P\"),\n            vjust = 1.5, color = \"blue\") +\n  labs(title = \"Distribuci\u00f3n El\u00edptica\")\n</code></pre> <p></p> <p>Los centros de masa son los mismos y lo \u00fanico que cambia es la matriz de variancias y covarianzas (o como se correlacionan las variables). La distancia de P al centro es la misma, pero est\u00e1 claro que en el caso esf\u00e9rico P se encuentra m\u00e1s cerca de la distribuci\u00f3n que en el caso el\u00edptico.</p> <p>Mahalanobis tiene en cuenta este aspecto ya que involucra la matriz de varianzas y covarianzas.</p> <p>La distancia entre el punto x y la distribuci\u00f3n con vector de medias \\(\\vec{\\mu}\\) y matriz de covarianzas S es: $$ D_M(\\vec{x}) = \\sqrt{(\\vec{x} - \\vec{\\mu})<sup>TS</sup>)$$}(\\vec{x} - \\vec{\\mu})</p> <p>Tanto el vector \\(\\vec{x}\\) como la distribuci\u00f3n pueden ser multivariadas (como se ve en los gr\u00e1ficos de arriba).</p> <p>Tener en cuenta que si tenemos dos puntos provenientes de la misma distribuci\u00f3n, podemos usar la distancia de Mahalanobis como una medida de disimilaridad: $$ D_M(\\vec{x},\\vec{y}) = \\sqrt{(\\vec{x} - \\vec{y})<sup>TS</sup>)$$ Veamos por ejemplo como queda la distancia de P a las distribuciones esf\u00e9ricas y el\u00edpticas graficadas.}(\\vec{x} - \\vec{y})</p> <pre><code># Caso Esf\u00e9rico\n\nmahalanobis(x = c(6,2), \n            center = c(3,3), \n            cov = matrix(c(1,0,0,1),\n                         nrow = 2,\n                         ncol = 2))\n</code></pre> <pre><code>## [1] 10\n</code></pre> <pre><code># Caso El\u00edptico\nmahalanobis(x = c(6,2), \n            center = c(3,3), \n            cov = matrix(c(1,0.6,0.6,1),\n                         nrow = 2,\n                         ncol = 2))\n</code></pre> <pre><code>## [1] 21.25\n</code></pre> <p>Queda claro que P es m\u00e1s cercano a la distribuci\u00f3n esf\u00e9rica que a la el\u00edptica.</p>","tags":["algebra","estadistica","r"]},{"location":"writing/2020/04/18/proceso-poisson-y-distribucion-exponencial/","title":"Proceso Poisson y distribucion exponencial","text":"<p>Basado en: https://stats.stackexchange.com/questions/2092/relationship-between-poisson-and-exponential-distribution https://towardsdatascience.com/the-poisson-distribution-and-poisson-process-explained-4e2cb17d459</p> <p>Un proceso que sigue un proceso de Poisson es aquel que tiene un cantidad de eventos promedio cada determinada unidad de medida (generalmente tiempo). Estos sucesos deben ser independientes y aleatorios pero la cantidad debe estar centrada alrededor del promedio ya mencionado. Una \u00faltima condici\u00f3n es que dos sucesos no pueden suceder en simult\u00e1neo.</p> <p>Para ejemplificar, podemos suponer que la cantidad de pacientes que llegan a la guardia de un hospital sigue un proceso de Poisson. </p> <p>Un proceso Poisson se puede \"descomponer\" en 2 conceptos.  </p> <ul> <li>Una disitribuci\u00f3n Poisson (no proceso!) que provee la funci\u00f3n de densidad de la cantidad de pacientes que ingresan al hospital. (Discreta)</li> <li>Una distribuci\u00f3n exponencial que modela el tiempo que transcurre entre cada paciente. (Continua)</li> </ul>","tags":["R","estadistica","Poisson","Exponencial"]},{"location":"writing/2020/04/18/proceso-poisson-y-distribucion-exponencial/#distribucion-poisson","title":"Distribuci\u00f3n Poisson","text":"<p>Esta distribuci\u00f3n sirve para modelar la cantidad de pacientes. Digamos que ingresan en promedio \\(\\lambda\\) pacientes por hora.</p> <p>La funci\u00f3n de probabilidad (probability mass function en ingl\u00e9s ya que es discreta) es:  \\(\\(P(K) = e^{-\\lambda}\\frac{\\lambda^k}{k!}\\)\\)</p> <p>Donde K es la cantidad de pacientes en una hora y \\(\\lambda\\) es como dijimos,  la cantidad promedio que ingresa por hora. La funci\u00f3n nos dice qu\u00e9 probabilidad hay de recibir K pacientes en una hora si en general llegan \\(\\lambda\\).</p> <p>Distintos \\(\\lambda\\) devuelven obviamente distintas probabilidades para cada valor de K. Vemos que a medida que crece \\(\\lambda\\) la densidad se parece cada vez m\u00e1s a una normal.</p> <pre><code>lambda = c(1,2,4,6,10)\nk = seq(0,max(lambda)*1.5)\ndf &lt;- expand.grid(lambda = as.factor(lambda), k = k) %&gt;%\n  mutate(poisson = dpois(k, as.numeric(as.character(lambda))))\n\nggplot(data = df, aes(x = k, y =poisson, colour = lambda)) + \n  geom_line() + \n  geom_point() + \n  ggtitle(\"Probabilidad por intervalo (1 hora)\") +\n  xlab(\"Cantidad K de pacientes\") + \n  ylab(\"\")\n</code></pre> <p></p> <p>\\(\\lambda\\) determina la forma de la dsitribuci\u00f3n y como es de esperar, esta se centra alrededor del par\u00e1metro ya que es la cantidad promedio en el intervalo. Una propiedad interesante es que la varianza de la disitribuci\u00f3n tambi\u00e9n es \\(\\lambda\\). Los pacientes que llegan al hospital siguen una distribuci\u00f3n \\(\\sim  P(\\lambda)\\).</p> <p>Otra caracter\u00edsica es que uno puede escalar la distribuci\u00f3n para cualquier intervalo. Es decir que si nuestro modelo era para cantidad de pacientes por hora, uno puede multiplicar \\(\\lambda\\) por 3 si quiere la distribuci\u00f3n cada 3 horas, o dividir por 6 si la quiere cada 10 minutos por ejemplo. Esto es asi porque en realidad en la funci\u00f3n de probabilidad de la distribuci\u00f3n Poisson, \\(\\lambda\\) est\u00e1 multiplicado por el intervalo t,pero se simplifica y se lo asume 1. Luego uno puede derivar para el lapso que desee multiplicando.</p>","tags":["R","estadistica","Poisson","Exponencial"]},{"location":"writing/2020/04/18/proceso-poisson-y-distribucion-exponencial/#distribucion-exponencial","title":"Distribuci\u00f3n Exponencial","text":"<p>Sabemos que llegan \\(\\lambda\\) pacientes por hora. Nos gustar\u00eda ahora saber la distribuci\u00f3n para el tiempo de espera hasta que llegue el pr\u00f3ximo paciente. Es decir, parados en el momento t, qu\u00e9 probabilidad hay de tener que esperar un minuto, 2, 10 hasta el pr\u00f3ximo paciente?</p> <p>El concepto es el siguiente. Si queremos saber la probabilidad de que haya que esperar al menos X minutos, es lo mismo que calcular la probabilidad de que la cantidad de pacientes en el momento t+x sea igual a la cantidad de momento t. Es decir, que no haya llegado nadie. \\(N_{t+x} = N_{t}\\).  </p> <p>Podemos calcular eso con la distribuci\u00f3n Poisson. Es simplemente la probabilidad de 0 pacientes en un intervalo x.</p> <p>$$P(N_{t+x} - N_t = 0) = e^{-\\lambda x}\\frac{\\lambda x^0}{0!} = e^{-\\lambda x} $$ La probabilidad de obtener un nuevo paciente en el intervalo x es 1 menos la probabilidad de no obtener ninguno,  por lo tanto: $$ P(X_t \\leq x) = 1 -  P(N_{t+x} - N_t = 0) = 1 - e^{-\\lambda x}$$ Este \u00faltimo resultado es la funci\u00f3n de probabilidad acumulada de la exponencial. La probabilidad de tener que esperar X o menos minutos depende de \\(\\lambda\\) y x.</p> <p>Con la derivada obtenemos la Funci\u00f3n de distribuci\u00f3n de la exponencial. \\(\\(f(x, \\lambda) = \\lambda e^{-\\lambda x}\\)\\)</p> <p>Si al hospital llegaran 10 personas por hora a la guardia, tendr\u00edamos la siguiente funci\u00f3n de densidad de la exponencial. Tener en cuenta que \\(\\lambda\\) = 10 en la poisson (10 casos por unidad de tiempo (hora)), sin embargo, en la exponencial queremos medirlo en minutos, por lo que usamos un \\(\\lambda\\) de 10/60.</p> <pre><code>lambda = c(10)\nt = seq(0,30, by = 1)\ndf2 &lt;- expand.grid(lambda = as.factor(lambda), t = t) %&gt;%\n  mutate(exponencial = dexp(t, as.numeric(as.character(lambda))/60))\n\nggplot(data = df2, aes(x = t, y =exponencial)) + \n  geom_line(colour = \"red\") + \n  geom_point(colour = \"red\") + \n  ggtitle(\"Funci\u00f3n de densidad de distribuci\u00f3n exponencial: lambda = 10/60\") +\n  xlab(\"Minutos\") +\n  ylab(\"Densidad\") +\n  scale_x_continuous(breaks = seq(0,30, by = 5))\n</code></pre> <p></p> <p>Por otro lado podemos ver la probabilidad acumulada hasta determinado minuto. Siguiendo el mismo ejemplo de 10 pacientes por hora (Poisson con \\(\\lambda = 10\\)), la acumulada de la distribuci\u00f3n exponencial tiene la siguiente forma.</p> <p>Hay alrededor de 80% de chances que un paciente llegue en los pr\u00f3ximos 10 minutos.</p> <pre><code>lambda = c(10)\nt = seq(0,max(lambda)*3, by = 1)\ndf2 &lt;- expand.grid(lambda = as.factor(lambda), t = t) %&gt;%\n  mutate(exponencial = pexp(t, as.numeric(as.character(lambda))/60))\n\nggplot(data = df2, aes(x = t, y =exponencial)) + \n  geom_line(colour = \"blue\") + \n  geom_point() + \n  ggtitle(\"Probabilidad de tener que esperar X minutos o menos\") +\n  xlab(\"Minutos\") + \n  ylab(\"\") +\n  scale_x_continuous(breaks = seq(0,30, by = 5))\n</code></pre> <p></p> <p>Por \u00faltimo, si lo quieren ver al rev\u00e9s. Podemos ver la probabilidad de tener que esperar al menos X minutos para que llegue el pr\u00f3ximo.</p> <p>Hay alrededor de 5% de chances de tener que esperar 20 minutos hasta el pr\u00f3ximo paciente</p> <pre><code>lambda = c(10)\nt = seq(0,max(lambda)*3, by = 1)\ndf2 &lt;- expand.grid(lambda = as.factor(lambda), t = t) %&gt;%\n  mutate(exponencial = pexp(t, as.numeric(as.character(lambda))/60, lower.tail = FALSE))\n\nggplot(data = df2, aes(x = t, y =exponencial)) + \n  geom_line(colour = \"darkgreen\") + \n  geom_point() + \n  ggtitle(\"Probabilidad de tener que esperar al menos X minutos\") +\n  xlab(\"Minutos\") + \n  ylab(\"\") +\n  scale_x_continuous(breaks = seq(0,30, by = 5)) + \n  scale_y_continuous(breaks = seq(0,1, by = 0.1))\n</code></pre> <p></p>","tags":["R","estadistica","Poisson","Exponencial"]},{"location":"writing/2020/04/25/distribucion-gamma/","title":"Distribucion Gamma","text":"","tags":["estadistica","Poisson","R","gamma"]},{"location":"writing/2020/04/25/distribucion-gamma/#origen-y-uso-habitual","title":"Origen y uso habitual","text":"<p>La distribuci\u00f3n Gamma es continua y siempre positiva. Se parametriza con dos par\u00e1metros que deben ser positivos.</p> <p>Lamentablemente no hay un consenso sobre c\u00f3mo llamar a los par\u00e1metros y prevalecen dos formas, bastante similares pero con distinto origen.</p> <ul> <li>La primera es con los par\u00e1metros shape \\(k\\) y scale \\(\\theta\\).</li> <li>La segunda es con los par\u00e1metros shape \\(\\alpha\\) y rate \\(\\beta\\).</li> </ul> <p>La relaci\u00f3n entre ambas es \\(k = \\alpha\\) y \\(\\theta = 1/\\beta\\). Obviamente cualquiera que se use va a resultar en los mismos resultados, pero hay que estar atento para lograr la parametrizaci\u00f3n adecuada.</p> <p>Yo prefiero la segunda opci\u00f3n, donde el rate \\(\\beta\\) puede relacionarse al rate \\(\\lambda\\) de una poisson.</p>","tags":["estadistica","Poisson","R","gamma"]},{"location":"writing/2020/04/25/distribucion-gamma/#por-que-nos-interesa-relacionarla-con-la-poisson","title":"Por qu\u00e9 nos interesa relacionarla con la Poisson?","text":"<p>Uno de los usos habituales y que resulta f\u00e1cil de entender es que si nos encontramos en un Proceso de Poisson (si no se recuerda ver ACA), suceden \\(\\lambda\\) eventos por per\u00edodo en promedio (la distribuci\u00f3n poisson nos ayuda con eso), el tiempo (medido en per\u00edodos) entre un evento y otro se puede modelar con una exponencial con par\u00e1metro rate = \\(\\lambda\\) (el mismo de la poisson), y ahora adicionamos que el tiempo medido en per\u00edodos hasta que suceda el k-\u00e9simo evento, se puede modelar con la distribuci\u00f3n gamma, parametrizada con shape = \\(k\\) (cantidad de eventos) y rate = \\(\\lambda\\) (el mismo de la poisson nuevamente.)</p> <p>Por ejemplo:</p> <p>Si podemos modelar la cantidad de veces que vamos por semana a comprar cerveza como una poisson con \\(\\lambda\\) = 2, es decir en promedio dos veces por semana, tendremos la siguiente distribuci\u00f3n.</p> <pre><code>set.seed(1)\nggplot() +\n  geom_bar(aes(x = rpois(10000,2)), fill = \"lightgreen\", color = \"black\") +\n  xlab(\"\") +\n  ylab(\"\") + \n  ggtitle(\"Simulaci\u00f3n de 10000 variables Poisson con rate = 2\") +\n  scale_x_continuous(breaks = seq(0,9)) + \n  theme_minimal()\n</code></pre> <p> Donde la mayor\u00eda de las semanas vamos alrededor de  2 veces.</p> <p>Podemos a su vez, modelar el tiempo entre cada evento con una exponencial. Se lo puede pensar como \u00bfcu\u00e1nto tiempo falta para que vaya de nuevo a comprar cerveza a partir del momento en que estoy parado?</p> <p>Usaremos una exponencial, pero para verlo en d\u00edas, que ser\u00eda lo apropiado, cambiamos \\(\\lambda = 2\\) por \\(\\lambda = 2/7\\), que ser\u00eda el rate por d\u00eda.</p> <pre><code>set.seed(2)\nggplot() +\n  geom_histogram(aes(x = rexp(10000, 2/7)),bins = 100, fill =\"darkgreen\", color = \"black\") +\n  xlab(\"\") +\n  ylab(\"\") + \n  ggtitle(\"Simulaci\u00f3n de 10000 variables Exponenciales con rate = 2/7\") +\n  scale_x_continuous(breaks = c(seq(0,10),15,20,25,30,35,40)) + \n  theme_minimal()\n</code></pre> <p> Vemos que en general faltan 1 o 2 d\u00edas para que tengamos que ir de nuevo, aunque si tomamos el promedio veremos que es 3.5 dias, lo cuales l\u00f3gico porque venimos de una poisson con rate de 2 veces por semana.</p> <p>Si ahora queremos ver en cuantos d\u00edas habremos ido 5 veces, podemos usar la distribuci\u00f3n gamma, con \\(shape = 5\\) (porque queremos ver el 5 evento), y \\(rate = 2/7\\) porque es el rate diario.</p> <pre><code>set.seed(3)\nggplot() +\n  geom_histogram(aes(x = rgamma(10000, shape = 5, rate =  2/7)),bins = 100, fill = \"darkred\", color =\"black\") +\n  xlab(\"\") +\n  ylab(\"\") + \n  ggtitle(\"Simulaci\u00f3n de 10000 variables Gamma con shape = 5  y rate = 2/7\") +\n  scale_x_continuous(breaks = seq(0,60, by = 5)) + \n  theme_minimal()\n</code></pre> <p></p> <p>Podemos ver que la distribuci\u00f3n gamma es asim\u00e9trica en este caso y en general faltan unos 12-16 d\u00edas. Si tomamos el promedio vemos que es de 17.5 d\u00edas, lo cual tiene sentido ya que es 5 veces el tiempo promedio de espera, que era 3.5 d\u00edas.</p> <p>La media de una gamma puede calcularse r\u00e1pidamente como \\(media = \\frac{shape}{rate} = \\frac{5}{2/7} = 17.5\\)</p> <p>Hay una clara relaci\u00f3n entre la distribuci\u00f3n Exponencial y la Gamma. Primero, como ya vimos, la exponencial modela el tiempo hasta el pr\u00f3ximo evento en un proceso Poisson y la Gamma hasta el k-\u00e9simo evento. Podemos pensar a la distribuci\u00f3n Gamma como la suma de K distribuciones Exponenciales con un mismo rate!</p> <p>Yendo m\u00e1s all\u00e1, en realidad, la distribuci\u00f3n Gamma es una familia de distribuciones, y la Exponencial no es m\u00e1s que un caso particular de la Gamma con k = 1. Si Gamma nos permite saber el tiempo hasta el k-esimo evento, y la Exponencial es hasta el primer evento, entonces la Exponencial como caso particular de la Gamma parece obvio.</p>","tags":["estadistica","Poisson","R","gamma"]},{"location":"writing/2020/04/25/distribucion-gamma/#un-poco-de-formulas","title":"Un poco de formulas","text":"<p>La funci\u00f3n de densidad de la distribuci\u00f3n Gamma, utilizando \\(\\alpha\\) y \\(\\beta\\) es: \\(\\(\\frac{\\beta^{\\alpha}}{\\Gamma (\\alpha)}x^{\\alpha - 1}e^{-\\beta x}\\)\\)</p> <p>donde \\(\\Gamma (\\alpha)\\) = \\((\\alpha - 1)!\\) </p> <p>Cuidado con las distintas maneras de nombrar a los par\u00e1metros. En la literatura posiblemente vean \\(\\alpha\\) y \\(\\beta\\) cuando usen shape y rate. Aqu\u00ed para el ejemplo de las cervezas reemplazamos \\(\\alpha\\) por \\(k\\) y \\(\\beta\\) por \\(\\lambda\\) para relacionarlo con la distribuci\u00f3n Poisson.</p> <p>El equivalente con esa notaci\u00f3n ser\u00eda: \\(\\(\\frac{\\lambda^{k}}{\\Gamma (k)}x^{k - 1}e^{-\\lambda x}\\)\\)</p> <p>Como dijimos si reemplazamos k por 1, obtenemos la funci\u00f3n de densidad de la Exponencial.</p> <p>Otras distribuciones que son casos particulares de la Gamma son la Erlang (es Gamma pero con valores discretos de K, la exponencial tambi\u00e9n es un caso particular de Erlang con k= 1) y la Chi-Cuadrado</p>","tags":["estadistica","Poisson","R","gamma"]},{"location":"writing/2020/04/25/distribucion-gamma/#desestimar-el-significado-de-shape-y-scale","title":"Desestimar el significado de Shape y Scale","text":"<p>Ya sea que prefiramos shape y scale o shape y rate como parametrizaci\u00f3n, sus nombres en ingl\u00e9s llevan a pensar que la dsitribuci\u00f3n var\u00eda su forma con shape y su escala con scale. Eso no es tan as\u00ed y puede llevar m\u00e1s a confusiones que otra cosa. Ambos par\u00e1metros pueden afectar tanto la forma y escala, por eso me parece m\u00e1s sencillo pensarlo con \\(k\\) Y \\(\\lambda\\), al menos en el \u00e1mbito de los procesos Poisson. Igualmente, no olvidar que la distribcui\u00f3n Gamma se puede usar para otros campos que no son situaciones de un Proceso de Poisson y esa interpretaci\u00f3n de los par\u00e1metros puede ser poco apropiada.</p> <pre><code>k = c(2,9)\nrate = c(1,2)\nx= seq(0,10, by = 0.1)\n\ndf &lt;- expand.grid(lambda = as.factor(rate), k = k, x = x) %&gt;%\n  mutate(gamma = dgamma(x,k, as.numeric(as.character(lambda))),\n         combination = as.factor(paste0(\"k = \",k,\", lambda = \",lambda)))\n\nggplot(data = df, aes(x = x, y =gamma, color = combination)) + \n  geom_line() + \n  #geom_point() + \n  ggtitle(\"Funci\u00f3n de Densidad para distintos par\u00e1metros de una Distribuci\u00f3n Gamma\") +\n  xlab(\"Per\u00edodos\") + \n  ylab(\"\") + \n  scale_color_brewer(palette = \"Set1\")\n</code></pre> <p></p>","tags":["estadistica","Poisson","R","gamma"]},{"location":"writing/2020/05/03/anova/","title":"ANOVA","text":"<pre><code>library(tidyverse)\nlibrary(patchwork)\n</code></pre> <p>ANOVA refiere a \"Analysis of Variance\" en ingl\u00e9s y corresponde a una serie de procedimientos estad\u00edsiticos que permiten estudiar diferencias de medias poblacionales, basado en muestras.  Es una t\u00e9cnica muy difundida para comparar medias de 2 o m\u00e1s grupos. Espec\u00edficamente queremos ver si todos los grupos comparten media o al menos uno difiere. En el caso m\u00e1s simple, de comparar dos medias, el resultado es equivalente al test t de comparaci\u00f3n de medias  por lo que ANOVA se considera una generalizaci\u00f3n de este.</p> <p>El test de hip\u00f3tesis ser\u00eda: \\(\\(H_0: \\mu_1 = ... = \\mu_k\\)\\) \\(\\(H_1: \\text{las medias no son iguales}\\)\\) ANOVA tiene tambi\u00e9n una serie de supuestos que hay que tener en cuenta.  </p> <ul> <li>Independencia de las observaciones.</li> <li>Normalidad en los residuos. Podemos pensarlo como normalidad dentro de cada grupo, siendo el residuo la parte no explicada por la media del grupo. En muestras chicas puede ser problem\u00e1tico si no se cumple (reduce la potencia del test). Con muestras grandes deber\u00eda cumplirse por Teorema Central del L\u00edmite.</li> <li>Homocedasticidad. Se supone que cada grupo tiene misma varianza. Si la muestra no es muy chica ANOVA es bastante robusto con este supuesto, si no, hay alternativas no par\u00e1metricas por ejemplo.</li> </ul>","tags":["estadistica","anova","R"]},{"location":"writing/2020/05/03/anova/#un-ejemplo-simulado","title":"Un ejemplo simulado","text":"<p>Generamos primero un set de datos donde la media de 3 grupos es distinta y vamos paso a paso con los c\u00e1lculos.</p> <pre><code>set.seed(24)\ndf = data.frame(grupo1 = rnorm(n = 35, mean = 3, sd = 1),\n                grupo2 = rnorm(n = 35, mean = 6, sd = 1),\n                grupo3 = rnorm(n = 35, mean = 9, sd = 1))\n</code></pre> <p>Tenemos 3 grupos de 35 observaciones, cada uno proveniente de poblaciones con medias notoriamente distintas. Veamos como resultaron las medias muestrales.</p> <pre><code>sapply(df, FUN = mean)\n</code></pre> <pre><code>##   grupo1   grupo2   grupo3 \n## 2.916989 5.910171 8.904245\n</code></pre> <p>Vi\u00e9dolo gr\u00e1ficamente vemos que son muy dispares y ANOVA deber\u00eda captar estas diferencias. En el segundo gr\u00e1fico, la linea vertical represnta la media general del dataset</p> <p> Veamos como resulta analizar esto con ANOVA.  </p>","tags":["estadistica","anova","R"]},{"location":"writing/2020/05/03/anova/#calculos","title":"C\u00e1lculos.","text":"<p>Obviamente existen paquetes estad\u00edsticos para realizar este an\u00e1lisis rapidamente pero iremos paso por paso. La l\u00f3gica es comparar la media de las poblaciones y para ello nos basamos en la varianza. M\u00e1s precisamente en la descomposici\u00f3n de la varianza.</p> <p>\\(\\(SC_{Total} = SC_{Entre} +  SC_{Dentro}\\)\\) La suma de errores cuadrados de TODO el dataset se puede descomponer entre el desv\u00edo cuadrado de cada grupo frente a la media general (Entre) m\u00e1s el desv\u00edo cuadrado de cada observaci\u00f3n respecto a su media grupal.</p> <p>Siendo m\u00e1s intuitivos. Los suma de los desv\u00edos cuadrados de cada observaci\u00f3n respecto a la media general 5.91 pueden ser vistos como la diferencia entre medias grupales (qu\u00e9 tan lejos est\u00e1 cada pico del gr\u00e1fico de la media grupal) m\u00e1s qu\u00e9 tan dispersos est\u00e1n los datos dentro de cada grupo.  </p> <p>Cuanto m\u00e1s grande sea la brecha entre la variabilidad entre grupos y la variabilidad al interior de los grupos, m\u00e1s probable es que las medias poblacionales sean distintas. Es decir, si la variabilidad total se explica m\u00e1s por la diferencia entre medias grupales que por la diferencia entre desvi\u00f3s al interior, entonces m\u00e1s evidencia en favor de distintas medias grupales. Si el ratio no es tan grande, entonces tenemos menos fuerza para afirmar tal cosa.</p> <p>Para poder comparar correctamente, no se mira directamente \\(SC_{Entre}\\) vs \\(SC_{Dentro}\\) ya que estos dependen del tama\u00f1o de la muestra, sino que se los normaliza primero.  \\(SC_{Entre}\\) se normaliza por sus grados de libertad siendo k-1 (cantidad de grupos menos 1) y  \\(SC_{Dentro}\\) se normaliza con N-K (observaciones totales menos cantidad de grupos).</p> <p>Ese estad\u00edstico F, que sigue la distribuci\u00f3n reci\u00e9n mencionada sera nuestro est\u00e1distico para testear la Hip\u00f3tesis.</p> \\[F = \\frac{\\frac{SC_{Entre}}{K-1}}{\\frac{SC_{Dentro}}{N-K}}\\] <p>Donde: \\(\\(SC_{Entre} = \\sum_{i=1}^k{n_i (\\bar{x}_i} - \\bar{x})^2\\)\\) \\(\\(SC_{Dentro} = \\sum_{i=1}^K\\sum_{j=1}^{n_k}{(x_j - \\bar{x}_i)^2}\\)\\) Luego como en cualquier test de hip\u00f3tesis, comparamos el estad\u00edstico F con la distribuci\u00f3n te\u00f3rica si la hip\u00f3tesis nula fuera cierto y seg\u00fan el valor de alfa que hayamos elegido, rechazamos o no la hip\u00f3tesis nula. Para ilustrar, la dsitribuci\u00f3n F tiene la siguiente forma con los grados de libertad de nuestro ejemplo.</p> <p></p> <p>Donde la regi\u00f3n en rojo es el area de la curva posterior al 95% de la distribuci\u00f3n. Si nuestro estad\u00edstico cae en la zona rojo podemos rechazar la hip\u00f3tesis nula con alfa =0.05</p> <p>Obtengamos los n\u00fameros con la funci\u00f3n aov.</p> <pre><code>res = aov(valor ~ grupo, data = df_long)\nsummary(res)\n</code></pre> <pre><code>##              Df Sum Sq Mean Sq F value Pr(&gt;F)    \n## grupo         2  627.3  313.66     326 &lt;2e-16 ***\n## Residuals   102   98.1    0.96                   \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n</code></pre> <p>La tabla que devuelve la funci\u00f3n es justamente todo lo que fuimos viendo. Sum Sq es la suma de desv\u00edos cuadrados. La fila de grupo corresponde a Entre y Residuals corresponde a Dentro. DF son los grados de libertad (K-1) y (N-K). Mean Sq es la divisi\u00f3n de Sum Sq por sus grados de libertad. Ser\u00edan el numerador y denominador del estad\u00edstico F. F value es simplemente la divisi\u00f3n de los Mean Sq. Obtenemos un estad\u00edstico de 326(!). A partir de 3 aprox ya pod\u00edamos rechazar la hip\u00f3tesis nula. El p-value (la \u00faltima columna) es virtualmente 0.</p> <p>Dado este resultado, podemos rechazar la hip\u00f3tesis nula y asegurar con el 95% de confianza que las medias poblacionales no son iguales. Era un caso medio extremo pero sirve de ejemplo.</p> <p>Lo que no nos dice ANOVA es si todas son distintas o cu\u00e1l es diferente al resto. Para ello hay que hacer estudios posteriores pero no entramos en detalles ac\u00e1.</p>","tags":["estadistica","anova","R"]},{"location":"writing/2020/05/03/anova/#detalle-tecnico","title":"Detalle t\u00e9cnico","text":"<p>Como asumimos que los residuos son normales, entonces elevarlos al cuadrado nos devuelve una distribuci\u00f3n Chi-Cuadrado. Las sumas de residuos al cuadrado son entones Chi-Cuadrado con los grados de libertad que mencionamos. Si dividimos dos distribuciones Chi-Cuadrado, normalizadas por sus grados de libertad, obtenemos una distribuci\u00f3n F con grados de libertad equivalentes a los de ambas Chi-Cuadrado.</p>","tags":["estadistica","anova","R"]},{"location":"writing/2020/05/03/anova/#un-caso-de-medias-iguales","title":"Un caso de medias iguales","text":"<pre><code>res2 = aov(valor ~ grupo, data = df2_long)\n\nsummary(res2)\n</code></pre> <pre><code>##              Df Sum Sq Mean Sq F value Pr(&gt;F)\n## grupo         2   0.00  0.0014   0.001  0.999\n## Residuals   102  98.14  0.9621\n</code></pre> <p>Aqu\u00ed es el otro extremo. El valor del estad\u00edstico F es casi 0, por lo tanto el p-value es casi 1. No hay evidencia para rechazar la hip\u00f3tesis nula.</p>","tags":["estadistica","anova","R"]},{"location":"writing/2020/05/03/anova/#conclusiones","title":"Conclusiones","text":"<p>ANOVA c\u00f3mo m\u00e9todo para comparar medias poblacionales es muy sencillo de aplicar y bastante robusto frente a inconsistencias en los supuestos. Permite dar una medida objetiva de si es posible o no rechazar la hip\u00f3tesis nula, m\u00e1s all\u00e1 de que uno pueda tener una primera impresi\u00f3n visual.</p> <p>Para ir un paso m\u00e1s all\u00e1, ANOVA se puede relacionar directamnte con las regresiones lineales. Anova tal como lo presentamos es equivalente a correr una regresi\u00f3n donde la variable independiente es el grupo al que pertenece la observaci\u00f3n. Las generalizaciones como ANCOVA, MANOVA, etc, tambi\u00e9n tienen su correlato en regresi\u00f3n. Esto sucede porque seg\u00fan el campo de estudio se eligieron caminos y convenciones distintos de an\u00e1lisis, llevando a distintas ramas que al final hacen lo mismo, pero genera confusi\u00f3n al intentar entender la estad\u00edstica como un todo.</p>","tags":["estadistica","anova","R"]},{"location":"writing/2020/07/11/de-r-a-python-1/","title":"De R a Python 1","text":"<p>Serie que documenta cuestiones pr\u00e1cticas que voy descubriendo a medida que empiezo a incursionar en Python un poco m\u00e1s enserio. Son m\u00e1s que nada recordatorios para el futuro de mec\u00e1nicas que hoy entiendo, pero me voy a olvidar.</p> <p>Muchos de los objetos no van a tener relaci\u00f3n entre s\u00ed o no se puede correr el c\u00f3digo directo  ya que son copy/paste random de scripts.</p>","tags":["R","Python"]},{"location":"writing/2020/07/11/de-r-a-python-1/#usar-objetos-de-otros-scripts","title":"Usar objetos de otros scripts","text":"<p>Si uno genera modelos, dataframes, etc en otro script por prolijidad y quiere utilizarlos en  el principal (o cualquiera en realidad) lo aconsejable es exportarlo como objeto pickle (algo  asi como los RDS en R.)</p> <pre><code>library(reticulate)\n</code></pre> <pre><code>import pickle\nimport pandas as pd\n\n# exportar. Objeto, archivo, permisos\npickle.dump(OBJETO, open(\"working/qualifying.p\", \"wb\"))\n\n# importar\nleer = pd.read_pickle('archivo.p')\n</code></pre>","tags":["R","Python"]},{"location":"writing/2020/07/11/de-r-a-python-1/#seleccionar-columas-de-dataframe-por-patron-en-el-nombre","title":"Seleccionar columas de dataframe por patr\u00f3n en el nombre","text":"<p>Para seleccionar columnas basados en si contiene determinado string en su nombre y no solo por nombre completo o por \u00edndice. </p> <pre><code># Recordemos que iloc selecciona por \u00edndice\n# Funci\u00f3n Lambda  que convierte el indice de columna en strings y devuelve mascara (True/false)\n# si contiene determinado patr\u00f3n. Creo que puede ponerse cualquier Regex\ndf2 = df.iloc[:, lambda df:df.columns.str.contains('_points')] # select column based on name\n</code></pre> <p>Si queremos combinar esto con otras columnas con otro patr\u00f3n no encontr\u00e9 manera m\u00e1s sencilla por el momento que combinar por separado. Quiz\u00e1s es muy tedioso si son muchas.</p> <pre><code># Notar que en point_vars le pasamos la m\u00e1scara al listado de columnas nuevamente\n# para quedarnos con el nombre real y poder sumarlo a las otras listas\n# luego lo convertimos en lista porque el objeto es de tipo \u00edndice si no.\ntarget = ['position']\nqualy_vars = ['grid', 'dif_to_min_perc']\npoint_vars = list(results.columns[results.columns.str.contains('_points')])\n\nvars_keep = target + qualy_vars + point_vars\n</code></pre>","tags":["R","Python"]},{"location":"writing/2020/07/11/de-r-a-python-1/#juntar-dataframes-por-indice","title":"Juntar dataframes por indice","text":"<p>Los DF vienen por default con un \u00edndice. Si uno trabaja con una copia del DF original para generar nuevas columnas el \u00edndice se mantiene (si no lo reseteamos claro). Tambi\u00e9n \u00fatil si se tienen varias tablas con mismo \u00edndice.</p> <p>Esto permite juntar tablas sin tener que hacer un merge explicito por determinadas columnas si no tenemos esos keys.</p> <pre><code>results = results.join(driver_points_merge) # join by index (no need to merge with column)\n</code></pre>","tags":["R","Python"]},{"location":"writing/2020/07/11/de-r-a-python-1/#ifelse","title":"Ifelse","text":"<p>El equivalente de IFELSE en R para rapidamente crear una columna basado en otras, fila por fila.</p> <pre><code>import numpy as np\n#               = condicion, valor si True, valor si False\ndf['position'] = np.where(df['position'] &gt; 1, 0, 1)\n</code></pre>","tags":["R","Python"]},{"location":"writing/2020/07/11/de-r-a-python-1/#dropear-columna-de-df","title":"Dropear columna de DF","text":"<p>\u00datil para asegurar que sacan el target de las X...</p> <pre><code>X = df.drop(columns=\"position\")\n</code></pre>","tags":["R","Python"]},{"location":"writing/2020/07/11/de-r-a-python-1/#remplazar-determinado-valor-por-nan-u-otro","title":"Remplazar determinado valor por NaN (u otro)","text":"<p>df.replace</p> <pre><code>qualifying = qualifying.replace('\\\\N', np.nan)\n</code></pre>","tags":["R","Python"]},{"location":"writing/2020/07/11/de-r-a-python-1/#apply-aplicar-funciones-a-cada-fila-o-columna","title":"APPLY. Aplicar funciones a cada fila o columna","text":"<p>Permite aplicar una funci\u00f3n por fila o columna.La funcion se aplica sobre la serie (la fila o columna) La serie mantiene los indices. Si usamos apply con axis = 1 que cada serie es una fila entera,  podemos llamar a la celda correspondiente usando ['columna']</p> <p>Apply es como las distintas versiones de apply de R y/o MAP del tidyverse cuando se aplica a un DF.</p> <pre><code>import pandas as pd\nrectangles = [\n    { 'height': 40, 'width': 10 },\n    { 'height': 20, 'width': 9 },\n    { 'height': 3.4, 'width': 4 }\n]\n\nrectangles_df = pd.DataFrame(rectangles)\nrectangles_df\n\n\n# Suma de todas las celdas (\"filas\") por columna\n</code></pre> <pre><code>##    height  width\n## 0    40.0     10\n## 1    20.0      9\n## 2     3.4      4\n</code></pre> <pre><code>suma_por_columna = rectangles_df.apply(sum)\nprint(suma_por_columna)\n\n# Suma de todas las celdas (\"columnas\") por filas\n</code></pre> <pre><code>## height    63.4\n## width     23.0\n## dtype: float64\n</code></pre> <pre><code>suma_por_fila = rectangles_df.apply(sum, axis = 1)\nprint(suma_por_fila)\n</code></pre> <pre><code>## 0    50.0\n## 1    29.0\n## 2     7.4\n## dtype: float64\n</code></pre>","tags":["R","Python"]},{"location":"writing/2020/07/11/de-r-a-python-1/#apply-lambda-para-pasar-funciones-custom-en-el-momento","title":"Apply Lambda para pasar funciones custom en el momento","text":"<pre><code>import pandas as pd\nrectangles = [\n    { 'height': 40, 'width': 10 },\n    { 'height': 20, 'width': 9 },\n    { 'height': 3.4, 'width': 4 }\n]\n\nrectangles_df = pd.DataFrame(rectangles)\n\ndef multiplicar_2(x):\n   return x*2\n\n# Caso donde paso una funcion propia predefinida\nrectangles_df.apply(multiplicar_2)\n\n\n# Lo mismo pero definido en el momento\n</code></pre> <pre><code>##    height  width\n## 0    80.0     20\n## 1    40.0     18\n## 2     6.8      8\n</code></pre> <pre><code>rectangles_df.apply(lambda x: x*2)\n</code></pre> <pre><code>##    height  width\n## 0    80.0     20\n## 1    40.0     18\n## 2     6.8      8\n</code></pre>","tags":["R","Python"]},{"location":"writing/2020/07/11/de-r-a-python-1/#calculos-by-group","title":"Calculos by group","text":"<p>Como el bygroup de tidyverse.</p> <pre><code># Equivalente a  groupby(raceid) %&gt;% summarise(newcol = min(best_qualy_ms))\nmin_qualy_by_race = qualifying.groupby('raceId')['best_qualy_ms'].min()\n</code></pre>","tags":["R","Python"]},{"location":"writing/2020/07/11/de-r-a-python-1/#by-group-mas-complejo-con-calculo-acumulado-en-determinada-ventana-de-obs-por-cada-fila","title":"By Group m\u00e1s complejo, con calculo acumulado en determinada ventana de obs. por cada fila","text":"<pre><code># suma acumulada de los ultimos 4 periodos (rolling)\n# luego el gorupby(level = 0).shift() es para lagearlo por grupo\n# el ultimo reset_index es para quitar el indice de este ultimo agrupado\ndriver_points.groupby('driverId')['points'].rolling(4, min_periods = 4).sum().groupby(level = 0).shift().fillna(0).reset_index(level = 0)['points']\n</code></pre>","tags":["R","Python"]},{"location":"writing/2020/07/18/disitrbucion-dirichlet-como-prior-de-mulitnomial/","title":"Distribucion Dirichlet como prior de Multinomial","text":"<p>Basado en: http://www.mas.ncl.ac.uk/~nmf16/teaching/mas3301/week6.pdf http://www.inf.ed.ac.uk/teaching/courses/mlpr/assignments/multinomial.pdf</p> <p>La distribuci\u00f3n Dirichlet es una distribuci\u00f3n multivariada para un conjunto de cantidades \\(\\theta_i,...,\\theta_m\\) donde \\(\\theta_i &gt;= 0\\) y \\(\\sum_{i=1}^m \\theta_i = 1\\). Esto la hace una candidata \u00fatil para modelar un conjunto de probabilidades de una partici\u00f3n (un un conjunto de eventos mutuamente excluyentes). Es decir, un grupo de probabilides de eventos excluyentes, que sumen 1. Podemos remplazar los \\(\\theta\\) por \\(p\\) si es m\u00e1s claro que hablamos de probabilidades luego.</p> <p>La PDF es:</p> \\[f(\\theta_i,...,\\theta_m; \\alpha_i.., \\alpha_m) =   \\frac{\\Gamma(\\sum_i{\\alpha_i})}{\\prod_{i=1}^m \\Gamma(\\alpha_i)}\\prod_{i = 1}^m \\theta_i^{(\\alpha_1-1)}\\] <p>Donde la funci\u00f3n \\(\\Gamma\\) es \\(\\Gamma(\\alpha) = (\\alpha -1)!\\). Para m\u00e1s detalles ver ac\u00e1. Los \\(\\alpha_i\\) son par\u00e1metros de la distribuci\u00f3n y deben ser mayores a 0. Cuando m = 2, obtenemos una funci\u00f3n \\(beta(\\alpha_1, \\alpha_2)\\) como caso particular de la Dirichlet.</p>","tags":["estadistica","binomial","multinomial","dirichlet"]},{"location":"writing/2020/07/18/disitrbucion-dirichlet-como-prior-de-mulitnomial/#dirichtlet-en-inferencia-bayesiana","title":"Dirichtlet en Inferencia Bayesiana.","text":"<p>De la misma manera que la distribuci\u00f3n Beta suele usarse como prior de la Distribuci\u00f3n Binomial ya que es una distribuci\u00f3n conjugada para ese caso, la distribuci\u00f3n Dirichlet suele usarse para distribuciones Multinomiales, es decir donde hay m\u00e1s de 2 categor\u00edas posibles (m\u00e1s de 2 \\(p_i\\)). Tambi\u00e9n es distribuci\u00f3n conjugada. Es simplemente la versi\u00f3n multinomial de la beta.  </p> <p>La distribuci\u00f3n multinomial es la siguiente:</p> \\[\\frac{n!}{\\prod_{i = 1}^m x_i!}\\prod_{i=1}^m p_i^{x_i}\\] <p>Cuando m = 2, es la distribuci\u00f3n binomial.</p> <p>Si tuvieramos un experimento que se puede modelar como una multinomial y queremos estimar los \\(p_i\\) podemos utilizar los estimadores de m\u00e1xima verosimilitud (frecuentista) o ir por el camino de bayesiano donde comenzamos con un prior para cada p, que modelaremos con la Dirichlet. El prior de cada \\(p_i\\) va a ser definido con la elecci\u00f3n de los \\(\\alpha\\).</p> <p>Yendo por el camino bayesiano vamos a tener nuestra distribuci\u00f3n posterior: $$ P(p | x) \\propto P(x|p) * P(p)$$ donde \\(P(x|p)\\) no es otra cosa que la distribuci\u00f3n multinomial y \\(P(p)\\) es nuestro prior de \\(p\\) dado por la Dirichlet. Omitimos el denominador que es normalizador ya que es una constante.</p> <p>Multiplicamos entonces la PDF multinomial por la Dirichlet y obtenemos:</p> <p>Importante notar que efectivamente cambiamos \\(\\theta\\) por \\(p\\) en la Dirichlet para que sea consistente con la multinomial.</p> \\[\\frac{n!}{\\prod_{i = 1}^m x_i!}\\prod_{i=1}^m p_i^{x_i} * \\frac{\\Gamma(\\sum_i{\\alpha_i})}{\\prod_{i=1}^m \\Gamma(\\alpha_i)}\\prod_{i = 1}^m p_i^{(\\alpha_1-1)} \\\\ \\propto \\prod_i p_i^{\\alpha_i + x_i -1}\\] <p>Para la proporcionalidad, quitamos todo lo que es factorial (y \\(\\Gamma\\)) ya que es constante y combinamos los exponentes de base \\(p_i\\).</p> <p>Vemos entonces que nuestra distribuci\u00f3n posterior es propocional a ese t\u00e9rmino, que si vemos, es una Dirichlet para la cual nos falta el t\u00e9rmino constante! Por eso se dice que es una prior conjugada, ya que la posterior es de la misma familia que la prior (con otros valores claro.) Es entonces una Dirichlet con par\u00e1metros \\(\\alpha_i + x_i\\) y podemos completar el t\u00e9rmino faltante obteniendo:  $$ \\frac{\\Gamma(\\sum_i{\\alpha_i + x_i})}{\\prod_{i=1}^m \\Gamma(\\alpha_i + x_i)}\\prod_{i=1}^m p_i^{(\\alpha_i + x_i-1)}$$</p> <p>He ah\u00ed nuestra distribuci\u00f3n posterior para los valores de \\(p\\) de la multinomial.</p> <p>Para calcular r\u00e1pidamente la esperanza de cada \\(p_i\\) hacemos simplemente: \\(\\(E(p_i) = \\frac{\\alpha_i + x_i}{\\sum (\\alpha_i +  x_i)}\\)\\)</p> <p>Si obtenemos nueva informaci\u00f3n podemos repetir el proceso, pero nuestra nueva prior deber\u00eda ser la posterior previamente calculada. Y as\u00ed vamos agregando informaci\u00f3n a medida que se recolecta y actualizando nuestra inferencia acerca de \\(p_i\\)</p> <p>Aclaraci\u00f3n: La proporci\u00f3n de cada \\(\\alpha_i\\) iniciales en la Dirichlet prior sobre la suma de todos los \\(\\alpha_i\\) es nuestro prior de \\(p_i\\). A mayores valores absolutos, mayor peso al prior respecto a los datos, ya que nuestro nuevo \\(p_i\\) es funci\u00f3n del \\(\\alpha_i\\) y \\(x_i\\). Revisar bien como ajustar los \\(alpha\\) seg\u00fan la magnitud de \\(x\\), si es que hay que hacerlo.</p>","tags":["estadistica","binomial","multinomial","dirichlet"]},{"location":"writing/2020/07/18/disitrbucion-dirichlet-como-prior-de-mulitnomial/#ejemplo","title":"Ejemplo","text":"<p>Queremos modelar la compra de remeras de basquet en una tienda. Entra un cliente al azar y tiene determinadas probabilidades de comprar una remera de los Lakers, una de los Celtics, una de San Antonio o cualquier otro equipo.  </p> <p>En un primer momento no sabemos las proporciones y empezamos con unos priors \\(\\alpha_1 : \\alpha_4 = [8,6,4,2]\\) que corresponde a 40%, 30%, 20% y 10% respectivamente.</p> <p>Recolectamos los datos de 100 clientes y vemos que las ventas fueron las siguientes: Lakers : 45 Celtics: 22 Spurs: 27 Otros: 6  </p> <p>Calculando rapidamente con la f\u00f3rmula de la Esperanza las probabildades que se derivan de nuestra posterior obtenemos:</p> <p>Lakers = 0.442 Celtic = 0.233 Spurs  = 0.258 Otro   = 0.067  </p> <p>Para ser m\u00e1s prolijos habr\u00eda que agregar la varianza de cada \\(p\\). A agregar en un futuro..</p> <p>Si hubieramos calculado los p  de m\u00e1xima verosimilitud no ser\u00eda m\u00e1s que la proporci\u00f3n de cada equipo en los datos, sin tener en cuenta nuestro prior. Vemos que ac\u00e1 est\u00e1n obviamente cercanos a la proporci\u00f3n en los datos pero se inclinan hacia el prior. Recordar que el peso de los priors va a verse afectar por los \\(\\alpha\\) elegidos y por la cantidad de datos recolectados.</p> <p>En ML es bastante \u00fatil para el caso donde una nueva categor\u00eda aparece en el test set. Si no fue vista en el training le va a dar probabilidad 0 mientras que con un prior podemos salvar ese problema. En NLP es bastante habitual usar la distribuci\u00f3n Dirichlet como prior. Investigar por ese lado.</p>","tags":["estadistica","binomial","multinomial","dirichlet"]},{"location":"writing/2020/10/06/non-negative-matrix-factorization.en-us/","title":"Non Negative Matrix Factorization","text":"<p>Please follow this link It was made with Flexboard (a package to do dashboards in R) so I think it's only visualized correctly in laptops/pc because of the layout.</p>","tags":["estadistica","nnmf","nba","english"]},{"location":"writing/2020/10/15/counter-strike-chance-of-winning.en-us/","title":"Counter Strike: chance of winning","text":"<p>This CS GO Kaggle link has data about several competitive CS GO matches. In a few words:  </p> <ul> <li>those are 5 vs 5 matches where each team tries to kill the other or complete a task (planting or defusing the bomb depending the role you are playing) before the time expires.  </li> <li>The goal is to win 16 rounds before the other team.  </li> <li>After 15 rounds both teams switch sides/role.</li> </ul> <p>The data has mostly information about each time a player damages another one (and eventually kills it), some grenades usage and some general data of each round as the amount of money spent by each team and the result of that round.  </p> <p>In here I have followed Namita Nandakumar hockey example to obtain and model some basic winning probability based on the lead and how many rounds have been played so far.  </p> <p>This is how probability of winning looks as the game progresses, grouped by how much the current winner is leading. (Averaging leads greater than 4 to keep it clean ). The thin line is the empirical probability, based solely on segmenting the data. The thick line is a local regression with its standard deviation. </p> <p>So, as we see there is some noise around the trend and the approximation wiggles a bit as you go through X. We would like to have a model where winning by some amount is always better if you are closer to 16. Let's say it is not crazy to assume that if you are winning by 3, 15 to 12, you should always have higher chances to win than if you are leading 6-3.  </p> <p>Namita shows that xgboost is a nice tool to impose that kind of constraint to a simple model using the monotone constraint parameter.</p> <pre><code>params = list(objective = \"binary:logistic\",\n              eval_metric = \"logloss\",\n              max_depth = 2,\n              eta = 0.1,\n              monotone_constraints = c(1,1)) \n</code></pre> <p>What we get is a model that follows the constraints, although has some bias for the lower leading categories. Nevertheless is a quick approach to approximate the probabilities in a credible way. You could use the dataset to explore other stuff since it has some rich information about locations.</p> <p></p>","tags":["english","estadistica","statistics","xgboost"]},{"location":"writing/2021/01/18/softmax-vs-sigmoid.en-us/","title":"Softmax vs sigmoid","text":"<p>When using Neural Nets for a multiclass classification problem it's standard to have a softmax layer at the end to normalize the probabilities for each class. This means that the output of our net is a vector of probabilities (one for each class) that sums to 1. If there isn't a softmax layer at the end, then the net will output a value in each of the last cells (one for each class) but without a delimited range. Just a set of numbers where usually the highest is the one with the most probable class but it's not obvious how to value the differences between them.</p> <p>So, you have a ordered set of numbers, you know which one is the most probable but you want to transform that into clear probabilities. You use the softmax layer. </p> <p>You could use a sigmoid activation function in the last cell to have individual probabilities. For each class, it transforms the output of the net into a probability. However the sum of those probabilities is not guaranteed to sum 1, actually it won't in practice. It's a simple proxy but you can get better intuitions with softmax.</p> <p>We will compare how these two approaches affect the last group of weights by inspecting the gradient after calculating the loss for an observation.</p> <p>I'm using the reticulate package in R to include Python code in Rmarkdown. Pretty nice.</p> <pre><code>library(reticulate)\n</code></pre> <p>We import pytorch to handle tensors and neural net functions.</p> <pre><code>import numpy as np\nimport torch\nimport torch.nn.functional as F\n</code></pre> <pre><code>torch.manual_seed(99)\n</code></pre> <pre><code>## &lt;torch._C.Generator object at 0x00000262714CF730&gt;\n</code></pre> <ul> <li>1 obs  </li> <li>5 features (X)  </li> <li>3 possible classes (index 1 = class 2)  </li> <li>W. 3 output cells, each one with 5 weights (one per feature)  </li> <li>W1 = W2 because we run it twice (two scenarios) and we can't re use the same weights because of the gradient calculated</li> </ul> <pre><code>X = torch.randn(5)\nW1 = torch.randn(3,5)\nW2 = W1.detach().clone() \ny = torch.tensor([1]) \n</code></pre> <p>We transform everything to positives to make it cleaner and we add the requires_grad_() characteristic that tells pytorch that those tensors need the gradient backpropagated during training</p> <pre><code>X = X.abs()\nW1 = W1.abs().requires_grad_()\nW2 = W2.abs().requires_grad_()\n</code></pre> <p>We define both losses (softmax and sigmoid).  </p> <p>Softmax </p> <ul> <li>Weights * input: cell value</li> <li>we change dimension of output to use it as input of softmax</li> <li>We calculate the softmax (probabilities of each class that sum 1)</li> <li>Apply log because we will use the negative log likelihood</li> <li>We calculate the loss (log of softmax probabilities vs actual class)</li> </ul> <p>Sigmoid </p> <ul> <li>Weights * input: cell value</li> <li>we change dimension of output to use it as input of sigmoid</li> <li>We calculate the sigmoid (probabilities of each class individually)</li> <li>Apply log because we will use the negative log likelihood</li> <li>We calculate the loss (log of sigmoid probabilities vs actual class)</li> </ul> <pre><code># funcion con softmax al final\ndef softmax_loss(W):\n    z = W @ X\n    z = z.unsqueeze(0)\n    z = torch.softmax(z, dim=1)\n    z = torch.log(z)\n    return F.nll_loss(z, y)\n\n# funcion con una sigmoidea por activacion\ndef sigmoid_loss(W):\n    z = W @ X\n    z = z.unsqueeze(0)\n    z = torch.sigmoid(z)\n    z = torch.log(z)\n    return F.nll_loss(z, y)\n</code></pre> <p>We run the forward pass and calculate the loss for the sigmoid first. Then we look for the gradient. As we can see in the results, only the weights that go to the correct class' output cell are modified. Classes one and three rest untouched. This is because the sigmoid activation just has the individual weights (and cross entropy only look to the correct class)</p> <pre><code>out_sigmoid = sigmoid_loss(W1)\nout_sigmoid.backward()\nW1.grad\n</code></pre> <p><pre><code>## tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n##         [-0.0452, -0.0867, -0.0564, -0.0492, -0.0549],\n##         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]])\n</code></pre> On the contrary, when running the same net but with softmax layer we see that all the weights are updated. The correct class has gradient with the same sign that for the sigmoid example but the other two classes have in this case opposite sign gradients (which makes sense since you want them to go in the other direction). This happens because the softmax includes the other classes in each cell since they are needed to normalize and return probabilities that sum up to 1.</p> <pre><code>out_softmax = softmax_loss(W2)\nout_softmax.backward()\nW2.grad\n</code></pre> <p><pre><code>## tensor([[ 0.5393,  1.0346,  0.6731,  0.5868,  0.6552],\n##         [-0.5576, -1.0697, -0.6959, -0.6066, -0.6775],\n##         [ 0.0183,  0.0351,  0.0228,  0.0199,  0.0222]])\n</code></pre> This is a simple case with just one layer of weights so we can clearly see this. If you had a fully connected net with more layers, this is valid just for the last one because the gradient is backpropagated and the weights from \"other paths\" still affect the cell that corresponds to the second class.  </p>","tags":["estadistica","Python","AI","Machine Learning"]},{"location":"writing/2021/01/18/softmax-vs-sigmoid.en-us/#conclusion","title":"Conclusion","text":"<p>The net should evolve during training in a similar way with both last layer activations but the way they do it is different and we try to show in here why. In the end, the sigmoid still reflects the preference for one of the classes and during each epoch it will go through the desired path but just updating some of the weights and not all at the same time.</p>","tags":["estadistica","Python","AI","Machine Learning"]},{"location":"writing/2021/07/11/spark.en-us/","title":"Spark and Pyspark","text":"","tags":["Machine Learning","Python","Pyspark","Spark"]},{"location":"writing/2021/07/11/spark.en-us/#whats-spark","title":"What's Spark?","text":"<p>prueba The definition says:  </p> <p>Spark is a fast and general processing engine compatible with Hadoop data. It can run in Hadoop clusters &gt;through YARN or Spark's standalone mode, and it can process data in HDFS, HBase, Cassandra, Hive, and any &gt;Hadoop InputFormat. It is designed to perform both batch processing (similar to MapReduce) and new &gt;workloads like streaming, interactive queries, and machine learning.</p> <p>Basically is a framework to work with big amounts of data stored in distributed systems instead of just one machine. This allows parallelization and hence much faster calculations. It's biggest difference with plain Hadoop is that Spark uses RAM to process data while Hadoop doesn't.  </p> <p>Not being a data engineer myself I can tell you that you can use Spark to work with data stored in HDFS, S3 buckets or a data lake for example. All distributed systems.  </p> <p>Since those usually store huge big amount of data you can see how all this relate. The use case I have been exposed to, as a data scientist, is to query this distributed data and process it before using it for some purpose (modeling, reporting, etc).</p>","tags":["Machine Learning","Python","Pyspark","Spark"]},{"location":"writing/2021/07/11/spark.en-us/#how-to-use-it","title":"How to use it?","text":"<p>I haven't deployed a distributed storage system myself but I think it's safe to assume that amount of data is gathered in big organizations and probably some data engineer has already done all the setup. You just want to access the data from an environment connected to the spark cluster. </p> <p>There are several languages that can interact with Spark. Scala is the original one but you could use Java or Python. As data scientist we are probably more familiar with Python so I will show you Pyspark</p>","tags":["Machine Learning","Python","Pyspark","Spark"]},{"location":"writing/2021/07/11/spark.en-us/#pyspark","title":"Pyspark","text":"<p>Pyspark is an API to work with Spark using Python. In order to run you need also Java installed and Apache Spark. In our fictional organization a data engineer might have set up a server with Jupyter notebooks linked to the data lake and with all the dependencies.</p> <p>There are probably ways to connect to the remote spark server from your local machine but I haven't done that.</p> <p>So, Pyspark allows you to query the datalake/bigdata storage from a jupyter notebook and then convert that to a Pandas Dataframe and work as you are used to.</p> <p>Spark/Pyspark has a particular syntax that is quite clear but has some particularities based on the parallelization notion. For example, many functions don't actually retrieve all the data, that only happens when you decide to. For example <code>show()</code> or <code>collect()</code> do retrieve the data (and can take a while if you are working with a lot of data) while <code>filter()</code> or <code>withColumn()</code> don't.</p> <p>Another thing to notice is that you will need to create/initiate a sparkContext before actually being able to query data.</p> <p>To understand this and have a good amount of examples regarding the functions and syntax I highly recommend THIS SITE.</p>","tags":["Machine Learning","Python","Pyspark","Spark"]},{"location":"writing/2021/07/11/spark.en-us/#how-to-practice","title":"How to practice?","text":"<p>You can practice Pyspark queries and scripts by installing Pyspark in your local machine despite not having a cluster running distributed data. With Pyspark installed you can create some data and use it as it was real. You will be able to use all the functions and check them by yourself.</p> <p>How to install it? You can check THIS GUIDE FOR WINDOWS.</p> <p>I have struggled a bit to make it work so these are some things I learned during the way. </p> <ul> <li>I have downloaded Java 8 since that's what the guide says and use that at my current organization.</li> <li>To avoid creating an account in Oracle to download Java you can check THIS SOLUTION.</li> <li>When creating Environment variables avoid blank spaces</li> <li>If Pyspark doesn't run because can't find Java. Check the %JAVA_HOME% path.</li> <li>If the error is related to missing Python3 , check the %PYTHONPATH% and create in the anaconda path a copy of <code>python.exe</code> but rename it <code>python3.exe</code></li> </ul>","tags":["Machine Learning","Python","Pyspark","Spark"]},{"location":"writing/2022/01/17/bias-variance-tradeoff.en-us/","title":"Bias Variance Tradeoff","text":"<p>Mean squared error (MSE) is a measure of how far our prediction is from the true values of the dependent variable. It's the expectation of the squared error.</p> <p>The squared error being:</p> \\[(Y - \\hat \\mu(x))^2\\] <p>where Y is the true value and \\(\\hat \\mu(x)\\) is the prediction for a given x.</p> <p>We can decompose it into:</p> \\[(Y - \\hat \\mu(x))^2 \\\\ = (Y - \\mu(x) + \\mu(x) - \\hat \\mu(x)^2) \\\\ = (Y - \\mu(x))^2 + 2(Y - \\mu(x))(\\mu(x) - \\hat \\mu(x)) + (\\mu(x) - \\hat \\mu(x))^2\\] <p>So, that's the squared error. The MSE is the expectation of that.  </p> <p>The expectation is a linear operator so we can apply it independently to different terms of a summation. The expectation of the first term is the variance of the error intrinsic to the DGP. The second term goes to 0 because involves \\(E(Y-\\mu(x))\\) that is the expectation of the error and that's equal to 0. The third term reamins as it is since doesn't involve random variables.  </p> \\[MSE(\\hat \\mu(x)) = \\sigma^2_x + (\\mu(x) - \\hat \\mu(x))^2\\] <p>This is our first bias-variance decomposition. The first term is the intrinsic difficulty of the problem to model, is the variance of the error and can not be reduced, it is what it is. The second term is how off our predictions are regarding the true expected value for that particular X.  </p> <p>This would be fine if we wouldn't need to consider \\(\\hat \\mu(x)\\) a random variable itself, since it is dependent on the specific dataset we are using. Given another dataset our estimation would be different despite using the same model methodology. What we actually want is the MSE of the method used \\(\\hat M\\) and not only the result of a particular realization.</p> \\[MSE(\\hat M_n(x)) = E[(Y - \\hat M_n(X))^2 | X=x] \\\\ = ... \\\\ = \\sigma^2_x + (\\mu(x) -  E[\\hat M_n(x)])^2 - V[\\hat M_n(x)] \\] <p>This is our 2<sup>nd</sup> bias-variance decomposition. The first term is still the irreducible error. The second term is the bias of using \\(\\hat M_n\\) to approximate \\(\\mu(x)\\). Is the approximation bias/error. The third term is the variance of the estimate of the regression function. If our estimates have high variance we can have large errors despite using an unbiased approximation.  </p> <p>Flexible methods will be able to approximate \\(\\mu(x)\\) closely, however usually using more flexible methods involve increasing the variance of the estimate. That's the bias-variance tradeoff. We need to evaluate how to balance that, sometimes including some bias reduce much more the error by decreasing the variance. Usually larger N decreases the MSE since it decreases bias and variance error.</p>","tags":["estadistica","Machine Learning"]},{"location":"writing/2022/01/17/bias-variance-tradeoff.en-us/#reference","title":"Reference","text":"<p>Based on 1.4.1 from Advanced data analysis from a elementary point of view.</p>","tags":["estadistica","Machine Learning"]},{"location":"writing/2022/01/18/linear-smoothers.en-us/","title":"Linear Smoothers","text":"","tags":["algebra","estadistica","Machine Learning","statistics"]},{"location":"writing/2022/01/18/linear-smoothers.en-us/#linear-regression-as-smoothing","title":"Linear regression as smoothing","text":"<p>Let's assume the DGP (data generating process) is: $$ Y = \\mu(x) + \\epsilon$$ where \\(\\mu(x)\\) is the mean Y value for that particular x and \\(\\epsilon\\) is an error with mean 0.</p> <p>When running OLS we are trying to approximate \\(\\mu(x)\\) with a linear function of the form \\(\\alpha + \\beta x\\) and trying to retrieve the best \\(\\alpha\\) and \\(\\beta\\) minimizing the mean-squared error.  </p> <p>The conclusions don't change but the math gets easier if we assume both X and Y are centered (mean=0). With that in mind we can write down the MSE and optimize to get the best parameters.</p> \\[MSE(\\alpha, \\beta) = \\mathbb{E}[(Y - \\alpha - \\beta X)^2] \\\\ = \\mathbb{E}[\\mathbb{E}[(Y - \\alpha - \\beta X)^2 | X]] \\\\ = \\mathbb{E}[\\mathbb{V}[Y|X]] + \\mathbb{E}[Y- \\alpha - \\beta X | X])^2] \\\\ = \\mathbb{E}[\\mathbb{V}[Y|X]] + \\mathbb{E}[(\\mathbb{E}[Y- \\alpha - \\beta X | X])^2]\\] <p>Deriving with respect to \\(\\alpha\\) and \\(\\beta\\) for optimization.. The first term can be dropped since doesn't include any parameter.</p> <p>$$\\frac{\\partial MSE}{\\partial \\alpha} =   \\mathbb{E}[2(Y - \\alpha - \\beta X)(-1)] \\  \\mathbb{E}[Y - a - b X] =  0 \\  a =  \\mathbb{E}[Y] - b  \\mathbb{E}[X] = 0  $$  when Y and X are centered..</p> <p>and  $$\\frac{\\partial MSE}{\\partial \\beta} =   \\mathbb{E}[2(Y - \\alpha - \\beta X)(-X)] \\  \\mathbb{E}[XY] - b\\mathbb{E}[X^2] = 0 \\ b = \\frac{Cov[X,Y]}{\\mathbb{V}[X]} $$</p> <p>The optimal beta is a function of the covariance between Y and X, and the variance of X.</p> <p>Putting together \\(a\\) and \\(b\\) we get \\(\\mu(x) = x  \\frac{Cov[X,Y]}{\\mathbb{V}[X]}\\)</p> <p>Replacing with the values from the sampled data we get an estimation of \\(a\\) and \\(b\\).  </p> <p>Remember they are 0 centered so variance and covariance get simplified.</p> \\[ \\hat a = 0 \\\\ \\hat b = \\frac{\\sum_i y_i x_i}{\\sum_i x_i^2}\\] <p>With all this we can see how OLS is a smoothing of the data. Writing in terms of the data points: $$\\hat \\mu(x) = \\hat b x \\ = x  \\frac{\\sum_i y_i x_i}{\\sum_i x_i^2} \\ = \\sum_i y_i \\frac{x_i}{\\sum_j x_j^2} x \\ = \\sum_i y_i \\frac{x_i}{n \\hat \\sigma_x^2} x $$ where \\(\\hat \\sigma_x^2\\) is the sample variance of X. In words, our prediction is a weighted average of the observed values \\(y_i\\) of the dependent variable, where the weights are proportional to how far \\(x_i\\) is from the center (relative to the variance), and proportional to the magnitude of \\(x\\). If \\(x_i\\) is on the same side of the center as \\(x\\), it gets a positive weight, and if it's on the opposite side it gets a negative weight. (Shalizi 2017)</p> <p>If \\(\\mu(x)\\) is really a straight line, this is fine, but when it's not, that the weights are proportional to how far they are to the center and not the point to predict can lead to awful predictions.</p>","tags":["algebra","estadistica","Machine Learning","statistics"]},{"location":"writing/2022/01/18/linear-smoothers.en-us/#alternative-smoothers","title":"Alternative smoothers","text":"<p>For that, other methods smooth the data in another ways to help mitigate that.</p> <p>As quick examples, we have KNN regression where the smoothing is done using only close observations to the one to predict (and getting quite noisy since depend a lot on the sample points around a small area).  </p> <p>Kernel smoothers are a variant where depending on the kernel selected we get different smoothing. The main idea is that we use a windowd of data with the idea of putting more weight to points close to the one to predict. Could be Gaussian weight around X for example, or uniform around a window. Note this is different than KNN regression since we do not take the average of those points, we get a regression for that area. A nice thing about this smoothers (and KNN regression) is that if we want to predict points far from the training data we won't get a linear extrapolation as with OLS but it will be pushed towards the closest data points we had in training.</p>","tags":["algebra","estadistica","Machine Learning","statistics"]},{"location":"writing/2022/01/23/remarks-on-r2.en-us/","title":"Remarks on R2","text":"","tags":["estadistica","statistics","Machine Learning"]},{"location":"writing/2022/01/23/remarks-on-r2.en-us/#r2-depends-on-the-variance-on-the-variance-of-the-predictors","title":"R2 depends on the variance on the variance of the predictors","text":"<p>Quoting from Shalizi[^1] Assuming a true linear model $$ Y = aX + \\epsilon$$ and assuming we know \\(a\\) exactly. The variance of Y will be \\(a^2\\mathbb{V}[X] + \\mathbb{V}[\\epsilon]\\). So \\(R^2 = \\frac{a^2\\mathbb{V}[X]}{a^2\\mathbb{V}[X] + \\mathbb{V}[\\epsilon]}\\) This goes to 0 as \\(\\mathbb{V}[X] \\rightarrow  0\\) and it goes to 1 as  \\(\\mathbb{V}[X] \\rightarrow  \\infty\\). \"It thus has little to do with the quality of the fit, and a lot to do with how spread out the predictor variable is. Notice also how easy it is to get a high \\(R^2\\) even when the true model is not linear!\"</p> <p>Below a quick comparison between two linear relationships, one with much higher variance than the other in the predictor. Added a different constant for better display in plot.</p> <pre><code>library(tidyverse)\n\nx1 = rnorm(1000, mean=0, sd=1)\nx2 = rnorm(1000, mean=0, sd=10)\nerror = rnorm(1000, mean=0, sd=0.5)\n\ny1 = x1 + error\ny2 = 10 + x2 +  error\n\ndf = data.frame(x1,x2,y1,y2)\n\nmodel1 = lm(\"y1 ~ x1\")\n</code></pre> <pre><code>## Error in eval(predvars, data, env): object 'y1' not found\n</code></pre> <pre><code>model2 =  lm(\"y2 ~ x2\")\n</code></pre> <pre><code>## Error in eval(predvars, data, env): object 'y2' not found\n</code></pre>","tags":["estadistica","statistics","Machine Learning"]},{"location":"writing/2022/01/30/inference-is-not-valid-in-the-dataset-used-for-model-selection.en-us/","title":"Inference is not valid in the dataset used for model selection.","text":"<p>Let's say we have a dataset and we want to fit a model to it and do some inference such as obtaining the coefficients and look for their confidence intervals.</p> <p>For such a task we would first need to find a model that we think approximates to the real data generating process behind the phenomenon. This will be the model  selection step. Then we would look at the output of our model and get the standard error of the coefficients or calculate the confidence interval or any other similar task. This will be the inference step.  </p> <p>The issue here is that, if we don't know the true model and we do model selection, our own model will be a random object. Why? Because the particular dataset we are using is also a set of random variables. Other datasets might return another model formula as the best between our options since that particular dataset would have other observations and particularities.  </p>","tags":["estadistica","statistics","Machine Learning"]},{"location":"writing/2022/01/30/inference-is-not-valid-in-the-dataset-used-for-model-selection.en-us/#main-problem","title":"Main problem:","text":"<p>since we are selecting a model based on a particular dataset, the standard errors and p-values will be smaller than then actual ones.  </p> <p>\"That means there is some extra randomness in your estimated parameters (and everything else), which isn't accounted for by formulas which assume a fixed model. This is not just a problem with formal model-selection devices like cross-validation. If you do an initial, exploratory data analysis before deciding which model to use - and that's generally a good idea - you are, yourself, acting as a noisy, complicated model-selection device\" (Sharizi 2017)</p> <p>The most straightforward way to deal with this (if you are using independent observations) is to split the data, do model selection in one part and then fit the best model in the other part. Your second fit will be the one useful for inference. You could fit the model to the full data but that would include the part used for model selection and you would still get false, overconfident standard errors.</p> <p>Let's see an example. We will generate data following a somewhat \"complicated\" model with interactions. We will split the data in two equal size parts. One for model selection and one for inference. We will then fit a couple formulas to model selection part and pick the one with the minimum RMSE. We will compare the standard errors obtained in the model selection part and the ones obtained fitting that model to the inference part.</p> <p>Thanks to BrunoRodrigues for this post that I used as guideline to fit models with Cross Validation in R.</p> <p>We start by generating the data, including interactions.</p> <pre><code>set.seed(1)\nN = 5000\nb0 = 4\nb1 = 1\nb2 = 2\nb3 = 3\nb4 = 4\nb5 = 5\n\nx1 = runif(N, 0, 10)\nx2 = rnorm(N, 20, 3)\nx3 = runif(N, 20, 40)\nerror = rnorm(N, 0, 200)\n\ny = b0 + b1*x1 + b2*x2 + b3*x3 + b4*x1*x2 + b5*x2*x3 + error\n\n\ndf = tibble(y, x1, x2, x3)\n</code></pre> <p>We do the first split, df_selection will be the one used to try different models and pick one. df_inference will be used to do the actual inference given the model selected.</p> <pre><code>prop = 0.5\n\nselection_inference_split = initial_split(df, prop=prop)\n\ndf_selection = training(selection_inference_split)\ndf_inference = testing(selection_inference_split)\n</code></pre> <p>To select a model using df_selection we will use Cross validation to try to get the model that best generalizes. We will generate 30 split of 70% of the data and use the other 30% to calculate RMSE metric.</p> <pre><code>validation_data &lt;- mc_cv(df_selection, prop = 0.7, times = 30)\n</code></pre> <p>We create two functions, my_lm() will run a linear regression for the training part of each split of CV and get the prediction for the testing part of each split. We will run this for a couple of formulas. return_model will fit the model to the whole training data to extract the parameters and standard errors we get if we use the same dataset that was used to do model selection.</p> <pre><code>my_lm &lt;- function(formula, split, id){\n\n    analysis_set = analysis(split)  \n\n    model &lt;- lm(formula = formula, data=analysis_set)\n\n    assessment_set &lt;- assessment(split)\n\n\n    pred = tibble::tibble(\"id\" = id,\n        \"formula\" = formula,\n        \"truth\" = assessment_set$y,\n        \"prediction\" = unlist(predict(model, newdata = assessment_set)))\n\n}\n\n\nreturn_model = function(formula){\n\n\n    model &lt;- lm(formula = formula, data=df_selection)\n    output = list(model$coefficients, summary(model))\n\n}\n</code></pre> <p>We will try 5 formulas. The first one is the actual data generating process and should the best in terms of RMSE. We will exclude that one for model selection since the aim of this is to simulate a scenario where we don't know the actual formula behind the data. We calculate it just for reference but we will pick one of the other 4 models for inference.</p> <pre><code>formulas = list(\"y ~ x1 + x2 +x3 + x1*x2 + x2*x3\", \n                \"y ~ .\", \n                \"y ~ x1 + x2\", \n                \"y ~ x1 + x2 + x3 + x1*x2\",\n                \"y ~ x1 + x2 + x3 + x2*x3\")\nresults = data.frame()\n\nmodels = list()\nfor (formula in formulas){\n\nresults_selection &lt;- map2_df(.x = validation_data$splits,\n                           .y = validation_data$id,\n                           ~my_lm(formula = formula, split = .x, id = .y))\n\nmodel = return_model(formula)\n\n\nresults = rbind.data.frame(results, results_selection)\nmodels = c(models, model )\n\n}\n</code></pre> <p>We retrieve the mean RMSE across the splits, calculated in the test part of each split. We can see that the real model is the best in terms of RMSE. Between the others, we can see  that the one including the x2:x3 interaction is the best.  So, we will keep that one as our \"model selected\"</p> <pre><code>results %&gt;%\n    group_by(id, formula) %&gt;%\n    rmse(truth, prediction) %&gt;%\n    group_by(formula) %&gt;%\n    summarise(mean_rmse = mean(.estimate)) %&gt;%\n    as.data.frame()\n</code></pre> <pre><code>##                           formula mean_rmse\n## 1                           y ~ .  219.4756\n## 2                     y ~ x1 + x2  625.0173\n## 3        y ~ x1 + x2 + x3 + x1*x2  217.3185\n## 4        y ~ x1 + x2 + x3 + x2*x3  198.9802\n## 5 y ~ x1 + x2 +x3 + x1*x2 + x2*x3  196.4747\n</code></pre> <p>We can check the parameters and the standard errors when fitted to the whole selection dataset.</p> <pre><code>## \n## Call:\n## lm(formula = formula, data = df_selection)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -854.07 -132.91   -0.97  137.65  714.53 \n## \n## Coefficients:\n##              Estimate Std. Error t value Pr(&gt;|t|)    \n## (Intercept) -245.1084   138.9684  -1.764   0.0779 .  \n## x1            82.7919     1.3540  61.148   &lt;2e-16 ***\n## x2            15.7118     6.8628   2.289   0.0221 *  \n## x3            -1.5177     4.5626  -0.333   0.7394    \n## x2:x3          5.1676     0.2256  22.906   &lt;2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 199.1 on 2495 degrees of freedom\n## Multiple R-squared:  0.947,  Adjusted R-squared:  0.9469 \n## F-statistic: 1.115e+04 on 4 and 2495 DF,  p-value: &lt; 2.2e-16\n</code></pre> <p>And let's see what happens if we fit the same model to the inference set.</p> <pre><code>model_test = lm(formula=formulas[[5]], data=df_inference)\n\nsummary(model_test)\n</code></pre> <p><pre><code>## \n## Call:\n## lm(formula = formulas[[5]], data = df_inference)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -656.47 -138.67   -5.64  130.21  773.99 \n## \n## Coefficients:\n##              Estimate Std. Error t value Pr(&gt;|t|)    \n## (Intercept) -438.7059   140.2618  -3.128 0.001782 ** \n## x1            81.4724     1.3622  59.812  &lt; 2e-16 ***\n## x2            23.4856     6.9475   3.380 0.000735 ***\n## x3             3.6309     4.5942   0.790 0.429417    \n## x2:x3          4.9750     0.2275  21.869  &lt; 2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 199.4 on 2495 degrees of freedom\n## Multiple R-squared:  0.9473, Adjusted R-squared:  0.9472 \n## F-statistic: 1.121e+04 on 4 and 2495 DF,  p-value: &lt; 2.2e-16\n</code></pre> First we can see that the parameters have changed a bit. In second place we can see that the standard errors are generally bigger in comparison to the parameter for the inference set and will generate a wider confidence interval.</p> <pre><code>ggplot(data = ratio_df) +\n  geom_point(aes(x=parameter, y=ratio, col=set), size=3) +\n  theme(legend.title = element_blank()) +\n  theme_light() +\n  xlab(\"\") +\n  ylab(\"Ratio\") +\n  ggtitle(\"Absolute ratio between SD and Estimate\")\n</code></pre> <p></p> <p>My idea is to add a plot with the confidence intervals so the effect can be seen directly but I don't have the time today. Anyways, it is clear that the standad error to parameter ratio is bigger in the inference set, showing that the inference in the same dataset as model selection is invalid as it is overconfident in the results.</p>","tags":["estadistica","statistics","Machine Learning"]},{"location":"writing/2022/03/25/weighted-regression/","title":"Weighted regression","text":"<p>Weighted regression consists on assigning different weights to each observation and hence more or less importance at the time of fitting the regression.  </p> <p>On way to look at it is to think as solving the regression problem minimizing Weighted Mean Squared Error(WSME) instead of Mean Squared Error(MSE)</p> <p>\\(\\(WMSE(\\beta, w) = \\frac{1}{N} \\sum_{i=1}^n w_i(y_i - \\overrightarrow {x_i} \\beta)^2\\)\\) Intuitively, we are looking fot the coefficients that minimize MSE but putting different weights to each observation. OLS is a particular case where all the \\(w_i = 1\\)</p> <p>Why doing this? A few reasons (Shalizi 2015. Chapter 7.1)  </p> <ul> <li> <p>Focusing Accuracy: We want to predict specially well some particular points or region of points, maybe because that's the focus for production or maybe because being wrong at those observations has a huge cost, etc. Using Weighted regression will do an extra effort to match that data.</p> </li> <li> <p>Discount imprecision: OLS returns the maximum likelihood estimates when the residuals are independent, normal with mean 0 and with constant variance. When we face non constant variance OLS no longer returns the MLE.  The logic behind using weighted regression is that makes no sense to pay equal attention to all the observations since some of them have higher variance and are less indicative of the conditional mean. We should put more emphasis on the regions of lower variance, predict it well and \"expect to fit poorly where the noise is big\". The weights that will return MLE are \\(\\frac{1}{\\sigma_i^2}\\)</p> </li> <li> <p>Sampling bias: If we think or know that the observations in our data are not completely random and some subset of the population might be under-represented (in a survey for example or because of data availability) it might make sense to weight observation inversely to the probability of being included in the sample. Under-represented observations will get more weights and over-represented less weight. Another similar situation is related to covariate shift. If the distribution of variable x changes over time we can use a weight designed as the ratio of the probability density functions. </p> <p>\"If the old pdf was p(x) and the new one is q(x), the weight we'd want to is \\(w_i=q(x_i)/p(x_i)\\)</p> </li> <li> <p>Other: Related to GLM, when the conditional mean is a non linear function of a linear predictor. (Not further explained in the book at this point)</p> </li> </ul> <p>Is there a scenario where OLS is better than Weighted regression? Assuming we can compute the weights.</p>","tags":["estadistica","statistics","Python","Machine Learning"]},{"location":"writing/2022/03/25/weighted-regression/#example","title":"Example.","text":"<p>First we will see the impact of using weighted regression, using a simulated scenario where we actually know the variance of the error of each observation. This is not realistic but useful to see it in action.</p> <pre><code>library(tidyverse)\n</code></pre> <p>We generate 1000 datapoints with a linear relation between y and x. Intercept = 0, slope = 5. We let the variance of the error depend on the value of x. Higher values of x are associated with higher values of the variance of the error.</p> <p><pre><code>set.seed(23)\nn=1000\nx = runif(n,0,10)\nerror = rnorm(n,0, x/1.5)\ndf = data.frame(x)\ndf = df %&gt;% mutate(y = 5*x + error)\n</code></pre> Visually..</p> <pre><code>ggplot(data=df, aes(x=x, y=y)) +\n  geom_point(alpha=0.3) + \n  # geom_smooth(color=\"blue\") +\n  # geom_smooth(method = \"lm\", mapping = aes(weight = (1/sqrt(x)^2)),\n  #             color = \"red\", show.legend = FALSE) +\n  NULL\n</code></pre> <p></p>","tags":["estadistica","statistics","Python","Machine Learning"]},{"location":"writing/2022/03/25/weighted-regression/#linear-regression","title":"Linear regression","text":"<pre><code>ols = lm(formula = \"y~x\", data=df)\nsummary(ols)\n</code></pre> <p><pre><code>## \n## Call:\n## lm(formula = \"y~x\", data = df)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -14.868  -1.720  -0.137   1.918  14.722 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(&gt;|t|)    \n## (Intercept)  0.19192    0.24278   0.791    0.429    \n## x            4.95585    0.04148 119.489   &lt;2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 3.855 on 998 degrees of freedom\n## Multiple R-squared:  0.9347, Adjusted R-squared:  0.9346 \n## F-statistic: 1.428e+04 on 1 and 998 DF,  p-value: &lt; 2.2e-16\n</code></pre> We get an intercept of 0.19, non-significant when the actual value is 0 and a slope of 4.96 when the actual value is 5.</p>","tags":["estadistica","statistics","Python","Machine Learning"]},{"location":"writing/2022/03/25/weighted-regression/#weighted-linear-regression","title":"Weighted linear regression","text":"<pre><code>wols = lm(formula = \"y~x\", data=df, weights = (1/sqrt(x)^2) )\nsummary(wols)\n</code></pre> <pre><code>## \n## Call:\n## lm(formula = \"y~x\", data = df, weights = (1/sqrt(x)^2))\n## \n## Weighted Residuals:\n##     Min      1Q  Median      3Q     Max \n## -4.8880 -0.8601 -0.0016  0.8936  4.6535 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(&gt;|t|)    \n## (Intercept) 0.001483   0.030072   0.049    0.961    \n## x           4.993473   0.021874 228.286   &lt;2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 1.498 on 998 degrees of freedom\n## Multiple R-squared:  0.9812, Adjusted R-squared:  0.9812 \n## F-statistic: 5.211e+04 on 1 and 998 DF,  p-value: &lt; 2.2e-16\n</code></pre> <p>We get an intercept of 0, non-significant too but much closer to 0 and with lower standard error and a slope of 4.99 also much closer to the actual value of 5 and with lower standard error.</p> <p>Conclusion: if we know the right weights we can get better estimates from a linear regression in case of heteroscedasticity.  </p>","tags":["estadistica","statistics","Python","Machine Learning"]},{"location":"writing/2024/09/05/expectation_maximization_poisson/","title":"Expectation Maximization for Poisson process","text":"","tags":["algebra","estadistica","Machine Learning","statistics"]},{"location":"writing/2024/09/05/expectation_maximization_poisson/#the-problem","title":"The problem","text":"<p>What if you want to run a regression to estimate the coefficients and retrieve the data generating process of some data BUT you are in a scenario with censored data? How does that affect my estimation? Can I do better?</p>","tags":["algebra","estadistica","Machine Learning","statistics"]},{"location":"writing/2024/09/05/expectation_maximization_poisson/#censored-data","title":"Censored data","text":"<p>In short, you have censored data when some observation is unobserved or constrained because of some specific reason which is natural and unavoidable.</p>","tags":["algebra","estadistica","Machine Learning","statistics"]},{"location":"writing/2024/09/05/expectation_maximization_poisson/#unobserved","title":"Unobserved","text":"<p>For instance, in survival analysis, if the subject is not yet dead (luckily) you can not observe the time of death yet and hence you don't know if he will die tomorrow or in two years. You can't observe yet the death date.  </p>","tags":["algebra","estadistica","Machine Learning","statistics"]},{"location":"writing/2024/09/05/expectation_maximization_poisson/#constrained","title":"Constrained","text":"<p>For goods with limited demand, once you deplete your stock, by definition you can't sell more and you can't observe all the demand that you would have if more items were able to be sold. Or an Airline , when selling seats, can't observe the full demand after all the seats have been sold, maybe more people were willing to flight.</p> <p>We will simulate an example of the latest case, for an airline with simple toy data.</p> <pre><code>import numpy as np\nimport statsmodels.api as sm\nfrom scipy.stats import poisson\nimport matplotlib.pyplot as plt\n</code></pre> <p>We create some fake data, where seats sold are generated from a poisson distribution, with an intercept (2) and a coefficient related to how many days are left to the departure (-0.2), the further from the departure, the less seats are sold.</p> <p>What we also do, is that on the last date, we constrain the demand. We don't get the full seats that would have been sold under a poisson distribution but the amount minus 3. Only ourselves know that because we want to tweak the data. In real life we would see data similar to the one generated and we couldn't see the actual sales that would have been present in a complete poisson generating process (that actually is how the tickets are sold in our example)</p> <p><pre><code># Step 1: Generate data\nnp.random.seed(100)\nn_samples = 20\nn_features = 1\nsubstract_sales = 3\n\n# Generate features\nX = np.random.normal(size=(n_samples, n_features))\nX = np.array(range(n_samples+1, 1, -1))\nX = sm.add_constant(X)  # Add intercept term\n\n# True coefficients\nbeta_true = np.array([2, -0.2])\n\n# Generate Poisson-distributed target values\nlinear_pred = np.dot(X, beta_true)\nlambda_true = np.exp(linear_pred)\ny = np.random.poisson(lambda_true)\n# y\n\n# Right-censoring threshold in the last date (when the fare is closed)\ncensor_threshold = np.concatenate([(y+1)[:-1],np.array([y[-1]-substract_sales])])\ny_censored = np.where(y &gt; censor_threshold, censor_threshold, y)\nis_censored = (y &gt; censor_threshold)\n</code></pre> Maybe it's easier to visualize. The green curve is the actual lambda parameter for each data, based on the intercept and the real coefficient multiplied by days to departure. The blue dots are the actual data points we see for all dates except from the last one. The grey dot is the data we should see if there was no limit of how many seats to sell, following the poisson distribution. The red dot is the actual data point we have, the last day the airline sold all the remaining seats and couldn't fulfill the true demand and hence we see lower sales than the ones generated by the poisson distribution.  </p> <pre><code># Plot the data\nplt.xlabel('Days to departure')\nplt.ylabel('Bookings')\nplt.title('Data Plot')\nplt.plot(X[:-1, 1], y[:-1], 'o')\nplt.plot(X[:, 1], lambda_true, label='Lambda True', color=\"green\")\n# plt.plot(X[:, 1], lambda_est, label='Lambda Estimated')\nplt.scatter(X[-1, 1], y[-1:],  color=\"grey\", label=\"Real unseen demand\" )\nplt.scatter(X[-1, 1], y[-1:]-substract_sales, color='red', label='Constrained')\nplt.legend()\nplt.show()\n</code></pre> <p></p>","tags":["algebra","estadistica","Machine Learning","statistics"]},{"location":"writing/2024/09/05/expectation_maximization_poisson/#esimation","title":"Esimation","text":"","tags":["algebra","estadistica","Machine Learning","statistics"]},{"location":"writing/2024/09/05/expectation_maximization_poisson/#poisson-regression","title":"Poisson Regression","text":"<p>First we estimate the parameters using a poisson regression. We assume the data follows a poisson process and we don't do anything to manage the constrained data. The results are kind of ok, we get some closeness to the true parameters but it is clearly biased.</p> <pre><code>model_censored = sm.GLM(y_censored, X, family=sm.families.Poisson())\nresults_censored = model_censored.fit()\nprint(f'Estimated Censored coefficients: {results_censored.params}')\n</code></pre> <pre><code>## Estimated Censored coefficients: [ 1.86976922 -0.21124541]\n</code></pre>","tags":["algebra","estadistica","Machine Learning","statistics"]},{"location":"writing/2024/09/05/expectation_maximization_poisson/#expectation-maximization","title":"Expectation Maximization","text":"<p>OK, here is our alternative. What we can do, a bit more sophisticated, is to apply EM algorithm, which is a iterative process, to estimate the coefficients of the poisson regression, including the knowledge we have, that there might be constrained data.</p> <pre><code># Step 2: Initialize parameters\nbeta_est = np.zeros(n_features + 1)\ntol = 1e-4\nmax_iter = 1000\n\nfor iteration in range(max_iter):\n    # Step 3: E-step\n    # Estimate the expected values of censored data\n    lambda_est = np.exp(np.dot(X, beta_est))\n    expected_y = np.where(\n        is_censored,\n        (censor_threshold + 1) / (1 - poisson.cdf(censor_threshold, lambda_est)),\n        y_censored\n    )\n    # Ensure expected_y values are valid\n    expected_y = np.nan_to_num(expected_y, nan=np.mean(y_censored), posinf=np.max(y_censored), neginf=0)\n    # Step 4: M-step\n    # Update parameter estimates using Poisson regression\n    model = sm.GLM(expected_y, X, family=sm.families.Poisson())\n    results = model.fit(method=\"lbfgs\")\n    # results = model.fit_regularized(L1_wt=0, alpha=0.1) \n    new_beta_est = results.params\n\n    # Check convergence\n    if np.linalg.norm(new_beta_est - beta_est) &lt; tol:\n        break\n\n    beta_est = new_beta_est\n</code></pre> <pre><code>## &lt;string&gt;:7: RuntimeWarning: divide by zero encountered in divide\n</code></pre> <pre><code>print(f'Estimated coefficients: {beta_est}')\n</code></pre> <p><pre><code>## Estimated coefficients: [ 2.11015996 -0.23573144]\n</code></pre> We can see our estimates are of course not perfect but the intercept is closer to the true parameter. Let's visualize the results to have a clear intuition.</p> <p><pre><code>uncensored_predictions = results.predict(X)\ncensored_predictions = results_censored.predict(X)\n</code></pre> Promising! For the furthest dates we see a bias in both approaches, we are not doing better than the Poisson regression, but neither worse. As we move closer the the departure, the EM algorithm predictions get closer and closer to the true lambdas, while the regular poisson regression continues it's biased trajectory. The EM procedure adjusted the coefficients to better match the constrained data.</p> <pre><code>plt.plot(X[:, 1], lambda_true, label='Lambda True', color=\"green\")\nplt.plot(X[:, 1], uncensored_predictions, label='Uncensored Predictions (EM)', color=\"blue\")\nplt.plot(X[:, 1], censored_predictions, label='Censored Predictions', color=\"red\")\nplt.xlabel('Days to departure')\nplt.ylabel('Lambda - Poisson regression')\nplt.title('Lambda Predictions')\nplt.legend()\nplt.show()\n</code></pre> <p></p>","tags":["algebra","estadistica","Machine Learning","statistics"]},{"location":"writing/2025/03/10/deep-dive-into-llms/","title":"Deep Dive into LLMs Like ChatGPT - Karpathy","text":"<p>Original video from Andrej Karpathy. Masterpiece.</p> <p>Fineweb</p> <p>Tokenization. From words to tokens. Tokens are not words and punctuation, they can be the root of words, they can be some sequence of letters without explicit meaning. This will change depending on the model. (tiktokenizer para verlo en accion)</p> <p>How it works? From words to bits with encoding could be the first step. From words to 1 and 0. But this becomes a super large representation because we only have two symbols. We can group every 8 bits into 256 different bytes. [0 to 255]  The sequence is much shorter because we have more symbols. We can use this, but in SOTA we go beyond that. We use Byte-pair encoding which looks for common pairs of bytes and we create a new symbols starting from 256, and we can do this many times. More symbols, shorter representation. Gpt4 ends up with +100k symbols.</p>","tags":["Machine Learning"]},{"location":"writing/2025/03/10/deep-dive-into-llms/#neural-networks","title":"Neural Networks","text":"<p>We take windows of tokens of flexible  length up to some maximum (4, 8, 16k). Too much could be computationally expensive.</p> <p>The idea is to predict the next token. The window used is the context. We do this for every context and token of the training data. The process will adjust the probabilities of each next token. They are initialized at random and in the end they should match the statistical properties of the dataset.</p> <p>Training is done via Neural Network, the mathematical expression is updated via weights. Input is the token sequence, output is the probability of each token as the next one. In the middle there is the NN architecture with transformers and etc. First parts includes the embedding into numerical representation.</p>","tags":["Machine Learning"]},{"location":"writing/2025/03/10/deep-dive-into-llms/#inference","title":"Inference","text":"<p>Put an initial token and sample from the output probability distribution, this is your next token. We do that again, but now the context is 2 tokens, and so on.</p>","tags":["Machine Learning"]},{"location":"writing/2025/03/10/deep-dive-into-llms/#gpt-2-train-and-inference","title":"GPT-2 train and inference","text":"<p>Useful because the technical parts are still relevant only that now are bigger and more complex.</p> <p>Base model is the model that comes out after training. It's an inference machine, just token prediction but it's not useful for chat for example. Some companies release their base models but not all of them. GPT2 was released. A base model release requires, the model architecture and the model weights.</p> <p>Llama 3 is another one more recent. 2024, 405 billions parameters</p> <p>Base model are somewhat good at memorization (regurgitation) which is not desirable. If you paste the first sentence of a wikipedia page it will probably output the exact rest of the article up until some point and then deviate.</p> <p>Wikipedia also has more weight in the model because the source is truthful. I'm not sure if this is because the wikipedia extract appears more times in the corpus because of citations and so or because some sources have more importance than other from pretraining methodology. </p> <p>Base model is still useful to some extent without being an assistant if you are clever with the prompt.</p> <p>Few shot prompt.  The model has some in-context learning, which is that the model can understand a pattern in the prompt. In the video, AK prompts a list of english words with their korean translation and left the last one without translating to make inference from that point.</p> <p>He also shows that you can generate some assistant type of inference via in-context learning by passing an example of human-assistant interaction and making it generate the answer to you actual question via inference.</p>","tags":["Machine Learning"]},{"location":"writing/2025/03/10/deep-dive-into-llms/#post-training","title":"Post training","text":"<p>Pretraining is all that we saw before. Get data from the web, tokenize it and create a base model that predicts next token. It's not an assistant, it's like a internet text generator. That's all included in pretraining and it's the expensive part, the one that takes millions of dollars and a lot of time.</p> <p>Post training Much less computation than pretraining and it's the step that moves us from a token generator to an assistant.</p> <p>Because this is a neural network we can't explicitly program the assistant or give them a personality or make it refuse some kind of questions. We can only do that via neural networks training on datasets.</p> <p>Programming by example. And the examples requires human labelers. We train the model on this responses and try to imitate that behaviour.</p> <p>We substitute the training dataset of the model, we remove all the internet text and we start using the conversation dataset. We keep training the model but know with this dataset and the model will pick the statistics of this new dataset and how the conversations should happen. (Supervised Finetuning aka SFT)</p> <p>Post training in SOTA can be in 3 hours for example vs 3 months of training in pre training and thousands of CPUs. This is because post training the dataset is human created and much smaller.</p>","tags":["Machine Learning"]},{"location":"writing/2025/03/10/deep-dive-into-llms/#how-do-we-go-from-conversations-in-the-new-dataset-to-tokens","title":"How do we go from conversations in the new dataset to tokens?","text":"<p>We need to encode and decode in some specific way. Each model has a slightly different methodology, but gpt-4o has for example a few extra tokens that represent the beginning of the new character talking (user or assistant), then a token for the user or the assistant, then a token for the start of the actual message, then the message tokenized  and then a token for the end of the message. Then we go again, same token representing the beginning, then the other token of user/assistant, etc</p> <p>So, when we go to chatgpt and ask a question it's sent to the backend encoded with the above format and they add the tokens for the start of a new message from the assistant and run inference there, they let the LLM complete all the next tokens.</p> <p>InstructGPT paper on SFT:First paper to talk about post-training. Mentions the heavy human labeler part from where the post training datasets with conversations emerged and some of the instructions the labelers received. The dataset from OpenAI is not released, but OpenAssistant is an open source alternative with a similar format.</p> <p>Currently LLMs are being used to help create this datasets of conversations. No need for that much human effort. But in the end the root of all this conversations is the initial human labelers following OpenAI and other companies instructions. In the end, chatgpt for example, is answering in the tone and guided by those examples, so it's kind of recreating how the labelers wrote. It's a labeler text generation machine. </p> <p>\"What would a human labeler say in this conversation?\"  You are talking to a simulation of an average labeler (who is probably some skilled person but still)</p>","tags":["Machine Learning"]},{"location":"writing/2025/03/10/deep-dive-into-llms/#hallucinations","title":"Hallucinations","text":"<p>They exist because the model is sampling from the training dataset statistics trying to answer something even if it's not the truth. The problem has been improved over the years but it's still relevant.</p> <p>How to fix it?</p> <p>We need to include in the post training dataset some conversations where the answer is that it doesn't know.</p>","tags":["Machine Learning"]},{"location":"writing/2025/03/10/deep-dive-into-llms/#mitigation-1-model-interrogation","title":"Mitigation #1: model interrogation","text":"<p>What Meta did for LLama is super clever . We don't know what the model knows or not exactly so we need to let it decide in some way. They assume there is some internal representation of lack of knowledge, some neuron that gets activated when it doesn't \"know\" something. So, what they did to include that pattern is to take random text (from wikipedia lets say) and they used an LLM to create a few questions with factual answers about that text. They interrogate the model with those questions and compare the answer to the actual truth (also another LLM as judge, no need for human). They did it a few times per question. If the model answered correctly then the conversation output is fine and all good. But if the model hallucinates and answers wrongly (as judged by another LLM based on the actual truth) then the answer to that question in the conversation dataset becomes \"Sorry, I don't know\". If you add some amount of answers like this (because of course you can't just add all question that don't have a true answer) then the model will get that pattern, that when that unknown neuron related to lack of knowledge gets activated, then answering I don't know is what it should do. This worked quite well to mitigate hallucinations!</p>","tags":["Machine Learning"]},{"location":"writing/2025/03/10/deep-dive-into-llms/#mitigation-2-search","title":"Mitigation #2: Search","text":"<p>Allow the model to search the internet. Allow the model to use Tools. We do this by introducing new tokens, in this case special tokens for search_start and search_end with a query in the middle. The Assistant will look up that query in a browser and will copy paste the information it gets just after the special tokens, so the internet information is now in the context. It goes directly into the model, like refreshing our memory as humans.</p> <p>To add this functionality we need again to teach the model by example, adding a bunch of examples in the dataset on how to use the search.</p> <p>Knowledge in the parameters == Vague recollection (e.g. of something you read 1 month ago) Knowledge in the tokens of the context window == Working memory</p>","tags":["Machine Learning"]},{"location":"writing/2025/03/10/deep-dive-into-llms/#models-need-tokens-to-think","title":"Models need tokens to think","text":"<p>Given the neural network architecture, there is a finite amount of computation that can be given for each token. Given the context your forward/inference pass will predict the next token using the network capability but it's finite/limited. We should try to expand/distribute the computation, \"the thinking\" between many tokens to use the full neural network computation power for each token, so we end up using more computation in total for our answer. In concrete, he shows a simple math problem. If we aim for the model to answer directly, we are forcing the neural network to use it's context and finite computation to answer in a single attempt. Everything that comes after that answer will be a post hoc justification. While if we aim for the model to elaborate and go step by step (disguised CoT?) it will use full computation for each step and by the time it outputs the answer, it will have a good detailed context to provide that final \"calculation\"</p> <p></p> <p>This is the same reason why models are not good at counting. Too much expected from a single forward pass, finite computation.</p> <p>\"use code\" it's a great way to make the model good at those tasks, because the model is good at copy pasting and code gives the right answer. So, you can just copy the string to code and then use python to actually count the number of letters or whatever. Same for calculation. It's much more likely to have the right answer than relying on the \"mental arithmetic\" of the model.</p> <p>It's also interesting to understand why a model might be good at solving complex phD level math problems but fail at simple tasks like: \"what is bigger 9.11 or 9.9?\"  which usually is answered wrongly or randomly.</p> <p>One hypothesis he mentions is that some research team said that the bible has 9.11 &gt; 9.9 in terms of verses and this can create confusion to the neural network but it's a problem not fully understood.</p>","tags":["Machine Learning"]},{"location":"writing/2025/03/10/deep-dive-into-llms/#reinforcement-learning","title":"Reinforcement Learning","text":"<p>The last major stage, some times is included  as part of post training but it's really a next separate major step.</p> <p>It's like going to school.</p> <p>He compares the training of  a model to a textbook, general explanations are like the pretraining, then the examples given in the book is like the post training with examples of how things should be solved (how to answer like an assistant) and then there are exercises which the student doesn't have the solution and needs to try to solve. You might have the final answer but not the path towards it. Reinforcement learning is like this last step.</p> <p>The motivation is that we as humans (labelers) don't know what's the best way for the LLM to solve a specific problem, such as a math problem. He shows a few options, like going straight to the answer, doing some arithmetic, talking in native english and giving the answer, putting the problem as a system of equations, etc. What's easier for us might not be easy for the LLM, so we need to try what approach gives best results.</p> <p>So, the idea is to generate multiple (thousands) solutions for some problem which isn't trivial and store the stochastic solutions / inferences / token sequence that led to a right answer among all the tries. Some will get the right answer, some don't. And then, the model will be retrained based on the right solutions. So, it's not human labeled anymore, it's just trying solutions and re-train on the ones that were correct so the network learns to keep doing that for similar situations in the future.</p> <p>Pre and post training are quite standard and used across all providers but the reinforcement learning step is in an earlier stage and not standardized, different providers are trying different approaches and how some details in the process are handled (which is a simple idea overall) has high impact and is not trivial, those details in how we select what is \"the best answer\" among the correct ones for example play a big role.</p>","tags":["Machine Learning"]},{"location":"writing/2025/03/10/deep-dive-into-llms/#deepseek-r1","title":"Deepseek R1","text":"<p>The paper was innovative and game changer in part because is  open and explicit about RL while openAI and other kept the details for themselves.</p> <p>With RL, the model learns over time to give better answers to the questions and it's using more and more tokens to do it. It \"discovers\" that trying many paths and backtracking and trying again it's better to get a good answers. Chain of thoughts emerge without being hardcoded anywhere by researchers (would be impossible too, it's something the model needs to discover)</p> <p>A \"thinking/reasoning\" model is one that has been trained with Reinforcement Learning</p> <p>ChatGPT 4o is not a reasoning one, is SFT montly (learn by example, just finetuned, no RL. He says there is a bit of RL but we should think about them as SFT really). DeepSeek uses RL.  o1 and o3 are also RL ones.</p>","tags":["Machine Learning"]},{"location":"writing/2025/03/10/deep-dive-into-llms/#alphago","title":"AlphaGo","text":"<p>RL made it possible for the model to beat top players ELO while supervised learning was not capable. RL is not restricted to human kind of plays and that's how move 37 happened, a play that was not expected by top level players but that actually was really powerful. This happened because the training wasn't guided by supervised learning but by RL (the AI playing against itself kind of)</p>","tags":["Machine Learning"]},{"location":"writing/2025/03/10/deep-dive-into-llms/#learning-in-unverifiable-domains-reinforcement-learning-from-humand-feedback","title":"Learning in Unverifiable domains (Reinforcement learning from Humand Feedback)","text":"<p>The previous problems where easily verifiable, we could just compare in RL if the solution was correct by checking the final output of the LLM vs the right answer, maybe by direct comparison or using LLM as judge where we ask another LLM to check if the solution provided by the model is consistent with the actual solution (currently that approach is quite reliable) but this can't be done in unverifiable domains such as \"write a joke about pelicans\", \"write a poem\", etc</p> <p>For the pelican jokes, in principle you could use humans to judge if the joke is funny and reward it but as you need to evaluate thousands of generations for thousands of prompts, this becomes unfeasible. We need another strategy. This paperintroduced the RL-HF subject</p> <p>RLHF approach STEP 1 :Take 1000 prompts, generate 5 options, order them from best to worst. STEP 2: Train a neural net simulator of human preferences (\"reward model\") STEP 3: Run RL as usual, but using the simulator instead of actual humans</p> <p>The reward model is not a perfect human simulator but it's currently good enough to work meaningfully. </p>","tags":["Machine Learning"]},{"location":"writing/2025/03/10/deep-dive-into-llms/#upside","title":"Upside","text":"<p>We can run RL in arbitrary domains (even unverifiable ones) and empirically it gives better results.</p> <p>He says that probably this improves the model due to discriminator - generator gap. It's easier for a human to discriminate than to generate. It's easier to say which jokes are good or bad than to create the good ones. The labeler doesn't need to create a good joke, it just leaves that hard task to the model and the labeler points out which are good and which are bad</p>","tags":["Machine Learning"]},{"location":"writing/2025/03/10/deep-dive-into-llms/#downsides","title":"Downsides","text":"<p>RL is done with respect to a lossy simulation of humans. It might be misleading, we generate orders based on a model that might not reflect the actual human judgement.</p> <p>RL discovers ways to \"game\" the reward model.</p> <p>It happens that after a lot of updates, the jokes that are considered the top are non sensical. At first, we some initial updates the jokes might improve but after some point in time they become much worse, like a top joke could be \"the the the the the\" and somehow that gets a high score by the reward model. Those weird top answers are adversarial examples. Somehow the RL get some answers that go through little paths that somehow  fire good scores without making human sense. The reward model are massive neural nets and they have cracks.</p> <p>You could get this non sensical answers and add them to your dataset with very low ranking to make it learn that this is not a good joke but this is an infinite process, there will always be more adversarial examples to be found by the neural net.</p> <p>What to do? Just train the RL for some time and crop the training, don't go too far so you avoid the adversarial example generation.</p> <p>This is true for RLHF, not RL . Plain RL can be run indefinitely because you can't really game the answer, you are looking for a specific answer and the neural net will find ways, even non standard ways, to find that answer but it's totally verifiable. RLHF is different, and a reward function can be gamed, so RLHF can't be run forever while plain RL yes.</p>","tags":["Machine Learning"]},{"location":"writing/2025/01/06/entropy/","title":"Entropy and information","text":"<p>Term that comes from information theory. The most intuitive way to think about information of a variable is to relate to the degree of surprise on learning the value of the variable X. This definition was mentioned both in Deep Learning, Bishop and in Hamming, and the former is the text I was just reading before starting this note.</p> <p>So, having a variable X with <code>p(x)</code>, what's <code>h(x)</code> , the information of observing X? This quantity <code>h(x)</code> should be a monotonic function of <code>p(x)</code>. Remember, information is tied to the surprise, observing an almost sure event, high p(x), reveals less information than an unexpected event,low p(x). In the extreme, observing a known value, gives 0 information.</p> <p>How to define the information mathematically comes (in some way intuitively) by the definition that, observing two independent variables <code>x</code> and <code>y</code> should provide an amount of information equal to the sum of the individual informations.</p> \\[h(x,y) = h(x) + h(y)\\] <p>We know that for independent events \\(p(x, y) = p(x)*p(y)\\) </p> <p>It can be derived then that  </p> \\[h(x) = - \\log_2 p(x)\\] <p>The log provides the summation part coming from a multiplication. The negative ensure 0 or positive values. Remember that we are taking the log of a value between 0 and 1.</p> <p>Now, there is another important term, entropy. It summarizes the average amount of information that is transmitted if a sender wishes to transmit the value of a random variable to a receiver.  The entropy is the expectation of the information, with respect to the distribution p(x).  </p> \\[H[x] = - \\sum_x p(x) \\log_2 p(x)\\] <p>For p(x) = 0, where the log would bring problem, we consider \\(p(x) \\log p(x)\\)=0</p> <p>Classical information theory uses \\(\\log_2\\) because it relates to bits and the amount of bits required to send a message but the book changes to \\(\\ln\\) because is much more used in ML and it's just a different unit to measure entropy. </p>","tags":["Machine Learning"]},{"location":"writing/2025/07/10/llama-index-and-rag-starter-point/","title":"Llama Index and RAG starter point","text":"<p>This is me trying and playing a bit with the starter guide of Llama Index. Basic discovery of how to use this. Actually their starter is more complex, goes into agents right away, so this was more what I was looking for.</p>","tags":["Machine Learning"]},{"location":"writing/2025/07/10/llama-index-and-rag-starter-point/#creating-the-environment","title":"Creating the environment","text":"<p>Poetry already installed and configured in windows to use Conda environments. Not sure how?Look here</p> <pre><code>conda create --name rag python=3.12\n\nconda activate rag\npoetry init\npoetry add llama-index\npoetry add sentence-transformers\npoetry add llama-index-embeddings-huggingface\n</code></pre> <p>llama-index uses by default embedding from OpenAI. It requires the API key (and paying of course.) Should be cheap but I'll try using local embeddings to see how it goes, using Huggingface as I used for other projects via sentence-transformers.</p> <p>For local embedding model, we load the model from hugging face and we update the embed_model in Settings.</p> <pre><code>embed_model = HuggingFaceEmbedding(\n    model_name=\"BAAI/bge-small-en-v1.5\",\n    device=\"cpu\",\n    embed_batch_size=8,\n)\n\nSettings.embed_model = embed_model\n</code></pre> <p>I think this could work alright in terms of speed for now.</p>","tags":["Machine Learning"]},{"location":"writing/2025/07/10/llama-index-and-rag-starter-point/#ollama","title":"Ollama","text":"<p>I installed Ollama from their website Added Ollama to Environment Variables</p> <pre><code>ollama pull gemma3\nollama pull gemma3:4b\n</code></pre> <p>I've been using them in the llama_index_starter.py to avoid using any API. but with my cpu only computer (32gb ram) everything was really slow. gemma3 in the terminal was super slow (~30s) , gemma3:4b much faster (~2s) but when integrating into llama index with the retrieval, it was slow too</p> <p>I feel like there is no usage for local LLMs in my current computer. Maybe if I use a server or collab this could work.</p>","tags":["Machine Learning"]},{"location":"writing/2025/07/10/llama-index-and-rag-starter-point/#groq","title":"Groq","text":"<p>I found that they have a generous free tier (500k tokens per day for some models) that should be enough to test things and do some minimum POC. I can top up later or use another provider, that's the magic of Llama-index, it should be easy to change the provider.</p> <p>Also, Groq onboarding couldn't be easier. Log in, they give you API key, and that's it.</p> <p><code>poetry add llama-index-llms-groq</code></p> <pre><code>from llama_index.llms.groq import Groq\nSettings.llm = Groq(model=\"llama-3.1-8b-instant\",\n                api_key=GROQ_API_KEY,\n                request_timeout=360.0)\n</code></pre> <p>That's it, I'm using Groq. In the Dashboard we can see usage, logs, etc, super cool.</p>","tags":["Machine Learning"]},{"location":"writing/2025/02/21/image-similarity-ecommerce/","title":"E-commerce Image Similarity via Visual Embeddings","text":"<p>How I implemented an API to retrieve similar images from an E-commerce in 3 steps</p> <p>In this post, we explore a system to identify similar articles solely based on e-commerce images. The approach is designed with two primary objectives in mind:</p> <p>Do you want to see how it looks? Check my portfolio example!</p>","tags":["Machine Learning"]},{"location":"writing/2025/02/21/image-similarity-ecommerce/#objectives","title":"Objectives","text":"<ol> <li> <p>Catalog Similarity:     Determine which items in the client's catalog resemble each other using only their photos.</p> </li> <li> <p>External Querying:     Although not implemented in the current API, the plan is to eventually allow querying with external images. The envisioned workflow is to source images from suppliers, compare them with the client's catalog, and perform this embedding generation locally to keep the API lightweight.</p> </li> </ol>","tags":["Machine Learning"]},{"location":"writing/2025/02/21/image-similarity-ecommerce/#proposed-solution","title":"Proposed Solution","text":"<p>The core idea is to use a pretrained image model to extract embeddings from each photo. Once these embeddings are available, we can perform similarity searches to find items that are visually alike.</p> <p>For our implementation, we experimented with both OpenAI's clip-ViT-B-32 and ResNet. In general, both models produced comparable results, though we opted for CLIP in our main experiments.</p>","tags":["Machine Learning"]},{"location":"writing/2025/02/21/image-similarity-ecommerce/#implementation-steps","title":"Implementation Steps","text":"","tags":["Machine Learning"]},{"location":"writing/2025/02/21/image-similarity-ecommerce/#step-1-download-catalog-images","title":"Step 1: Download Catalog Images","text":"<ul> <li>Script: <code>embeddings/download_images/get_images.py</code></li> <li>Details:     This script downloads all catalog images from the e-commerce using a <code>ThreadPool</code> to speed up the process.</li> </ul>","tags":["Machine Learning"]},{"location":"writing/2025/02/21/image-similarity-ecommerce/#step-2-generate-and-index-embeddings","title":"Step 2: Generate and Index Embeddings","text":"<ul> <li>Script: <code>embeddings/clip_faiss.py</code></li> <li>Details:     The script generates embeddings for each photo and stores them in a Faiss index, which is saved under <code>embeddings/faiss_index/</code>. Note: Since the process is deterministic, a simple overwrite will not impact the results. Idempotent as they call it.</li> </ul> <p>Additional notebooks are available to illustrate the process, check results, and experiment with alternative models and tests.</p>","tags":["Machine Learning"]},{"location":"writing/2025/02/21/image-similarity-ecommerce/#step-3-query-the-faiss-index","title":"Step 3: Query the Faiss Index","text":"<ul> <li>API Functionality:     The Faiss index is already built. We expose an API endpoint where you can pass an <code>article_id</code> (used during the embedding generation) and retrieve the most similar items. Validation:     As a sanity check, querying an article should return itself as the top match with a distance of 0.</li> </ul>","tags":["Machine Learning"]},{"location":"writing/2025/02/21/image-similarity-ecommerce/#conclusion","title":"Conclusion","text":"<p>By leveraging pretrained image models and efficient similarity search with Faiss, this approach provides a scalable method for identifying visually similar items in an e-commerce catalog. This system not only improves internal catalog management but also sets the groundwork for integrating external image queries in the future.</p>","tags":["Machine Learning"]},{"location":"writing/2025/01/28/kullback-leibler-divergence/","title":"Kullback-Leibler divergence","text":"<p>To understand KL divergence we need to first understand Entropy. The most important thing to have in mind though is that entropy can be thought as a measure of \"information\", but what I like the most, as a measure of expected surprise that one gets for every observed value of the distribution.</p> <p>For a highly dense distribution, you will almost sure get a value from the dense region and the expected surprise will be really low (but you are highly surprised when you see a value off that region!)</p>","tags":["Machine Learning"]},{"location":"writing/2025/01/28/kullback-leibler-divergence/#relative-entropy","title":"Relative entropy","text":"<p>How this relates to KL? Well, Kullback-Leibler is a divergence but is also called relative entropy. This means, how that measure of entropy differs between two distributions. I find that easier to grasp.</p> <p>Usually we have a true distribution \\(p(x)\\) and an estimated distribution \\(q(x)\\) that we use to approximate \\(p(x)\\). KL divergence can help us understand how good it does the  job.</p> <p>If entropy is: </p> <p>\\(H[x] = - \\sum_x p(x) \\ln p(x)\\) (originally \\(\\log_2\\) but \\(\\ln\\) works too and it's used everywhere )</p> \\[KL(p||q) = - \\int{p(x) \\ln q(x)dx} - (-\\int{p(x) \\ln p(x)dx})\\] \\[ = - \\int{p(x) \\ln \\frac{q(x)}{p(x)}dx}\\] <p>The first row is clear, is just the difference in entropies.  This is relative entropy between p(x) and q(x).</p> <p>Important: KL divergence is not symmetrical. \\(KL(p||q) \\neq KL(q||p)\\) So, KL is not a metric of distance (but can be thought as if). It's actually a divergence.</p>","tags":["Machine Learning"]},{"location":"writing/2025/01/28/kullback-leibler-divergence/#why-its-not-symmetrical","title":"Why it's not symmetrical?","text":"<p>I think about it this way. This is a dissimilarity between one distribution and how we approximate it. Think about two totally different distributions (awful approximations):</p> <ul> <li>one highly centered around one specific value </li> <li>the other with a uniform-ish shape, highly dispersed.</li> </ul> <p>The difference in \"surprise\" you get from both ways approximation is not the same.</p> <p>If you are approximating the highly dense distribution with the uniform one, you are approximating it with a distribution that surprises you  in general \\(\\ln q(x)\\), let's say moderately high everywhere, even for the specific dense region.</p> <p>But the other way, if you approximate the dispersed distribution with the dense one, you are using a distribution with high surprise in most of the region of the dispersed distribution and really low surprise in one specific value.</p> <p>This term \\(\\int{p(x) \\ln q(x)dx}\\) behaves differently in both scenarios and there is no guarantee or need that they should match.</p>","tags":["Machine Learning"]},{"location":"writing/2025/01/28/kullback-leibler-divergence/#references","title":"References","text":"<p>Deep Learning, Bishop Wikipedia</p>","tags":["Machine Learning"]},{"location":"writing/2025/01/28/mutual-information/","title":"Mutual Information","text":"<p>When two variables \\(x\\) and \\(y\\) are independent, their joint distribution will factorize into the product of their marginals \\(p(x,y) = p(x)p(y)\\). If the variables are not independent, we can gain some idea of whether they are \"close\" to being independent by considering the KL Divergence between the joint distribution and the product of the marginals, given by:</p> \\[I[x,y] = KL(p(x,y)||p(x)p(y))\\] \\[=  - \\int \\int p(x,y) \\ln (\\frac{p(x)p(y)}{p(x,y)}) \\] <p>which is called the mutual information between \\(x\\) and \\(y\\).</p> <p>Thus, the mutual information represents the reduction in uncertainty about \\(x\\) by virtue of being told the value of \\(y\\) (or vice versa)</p> <p>From a Bayesian perspective, we can view \\(p(x)\\) as the prior distribution for \\(x\\) and \\(p(x|y)\\) as the posterior distribution after we have observed new data \\(y\\). The mutual information therefore represents the reduction in uncertainty about \\(x\\) as a consequence of the new observation \\(y\\).</p>","tags":["Machine Learning"]},{"location":"writing/2025/07/10/how-to-use-poetry-with-conda-environments/","title":"How to use Poetry with Conda environments","text":"<p>Poetry uses by default the system installed python and creates a new environment using that one. I prefer creating a new env with conda, install whatever python version I want and work in there.</p> <p>1) Create an environment with Conda and activate it</p> <p>2) Have setup (once, globally) that Poetry uses the current environment python version <pre><code>poetry config virtualenvs.create false\n</code></pre></p>","tags":["Machine Learning"]},{"location":"writing/2024/12/03/motivation/","title":"Motivation","text":"<p>It's a tough topic because everyone has a different perception and it's hard to share emotions but I feel what I call motivation really has an impact on me. Sometimes is a silent impact, I'm talking now about lack ok motivation, noticeable only when it comes back. You don't know what you don't know. You don't know how much energy and willingness to do things you should have if you never realized it.  </p> <p>My biggest adulthood lack of motivation came from jobs. I can't complain, I work in software/Machine learning, good salaries, remote work if desired, etc, but still, a day to day that is not fulfilling has devastating effects. Even more, probably fully remote work post pandemic plays a role in this despite I think the net effect is positive as I can't value enough the commute time regained.</p> <p>The difference between being motivated to do something and being indifferent is the largest gap possible. If you truly desire something and work for it the odds of succeding increase exponentially. </p>","tags":["Mental Health","Work-Life Balance","Personal Growth"]},{"location":"writing/2024/12/03/motivation/#things-ive-realized-that-affect-my-motivation","title":"Things I've realized that affect my motivation:","text":"<ul> <li>Sleep. I have regular issues sleeping. Usually after 2 days of bad sleep my brain doesn't work anymore. I work poorly, I get anxious because I can't get anything done nor I can think properly. I sleep bad again and so on. Disaster.</li> <li>Anxiety. It's related to sleep but not always. Feeling I can't do something or that I don't understand some topic or how to solve a problem, makes me anxious and after a while I want to quit. I trust I can understand or solve complex machine learning topics but usually not having a clear North is really stressful. If only I could have someone guiding a bit, everything looks better. Not knowing if you are on the right path and you have a short time to figure out something is horrible. For instance, we need to solve X problem. You ask a few days for research, you accumulate papers or blogposts, but sometimes none is exactly your solution, and then all have something different, and then you don't know what to read and all are long pieces of text, and they mention other topics you don't know. I feel anxious just by writing this, but one needs to make peace with the fact that you can't have a phD in every topic to solve. Maybe in none if you are just in industry and you are responsible for multiple projects, and things will be done suboptimally probably. But it's hard to really accept it and on top of that, is you have a boss or some coleague asking for this, the stress is twice as big, at least for me. Fear of disappointing. Maybe that's another whole note.  </li> <li>Daily meetings. Daily standup or just status meetings are terrible for me. I feel the pressure to explain myself every day, to tell someone else what did I do for 8 hours and sometimes, when motivations it's at a low level, is not that much, or maybe I am just researching without having grasped full understanding so it seems unfruitful, and this goes back to anxiety. Every day feeling the need to have something meaningful to share. Currently I don't have daily meetings, I have some freedom to work and then put up to speed my manager. I feel more free and funny enough, I feel that I do more progress on a daily basis this way.</li> <li>Social media. You can see unrealistic success stories all day long that feel like someone found the way to live in a 5 minute revelation and minimum effort. All fake, all lies but you can quickly fall in that trap of feeling less than others. You just have to compare yourself with previous you, not others that are even probably fake. On top of that, when you realize all the time you get back you feel like your days are longer and you can fight the anxiety better. At some point I realized this and when I automatically reached my phone, which happened really often, to open Twitter, I would hit my wrist (without hurting!) and took a deep breath, then drop the phone. You get back 5/10 minutes of time you would use in social media, and that accumulates fast.</li> </ul> <p>I've quit because of this, because of not being happy, because of being stressed every morning by lack of progress. Maybe I wasn't up to the task, maybe if you know exactly what you are doing you can move forward steadily without worrynig about this but I'm sure there was another time in a project where I felt all this lack of motivation and it was not because of \"skill issue\" but because of continuous urgency. Every morning I could (or maybe not, you don't know until you check your phone) with some urgent message of modifying something because yadda yadda the client. Sometimes it made sense, others.. not so much, and that feeling of being alert and thinking about slack messages all the time was awful, you can't focus, you can't feel you are working in peace in something. </p>","tags":["Mental Health","Work-Life Balance","Personal Growth"]},{"location":"writing/2024/12/03/motivation/#consequence","title":"Consequence","text":"<p>Eventually I quit all that and started learning about how to set up a job board, reading , drinking coffee, I took a 6 month sabbatical, at least, industry sabbatical, but I would spend time in the computer learning, working in the job board, etc. But I was free and owner of my own time, no one expecting anything. If I wanted to do nothing and just play with my dog all afternoon, there was no daily standup the next morning to dread. I could enjoy things without worrying.</p> <p>Unfortunately in those six months I didn't make a fortune nor won the jackpot so I went back to industry but without ruhsing. I looked for jobs that at least, before joining, made me want to join. Maybe because of the area, maybe because of the technology and in some case, maybe because it seemed chill. I had my share of rejections and processes that went nowhere but I ended up in a startup with a really enjoyable day to day structure. I'm really grateful about it, I have a couple of meetings per weeks and that's it. I can do things at my own pace (given some realistic timelines), I can share ideas with my manager but I don't need to impress anyone on a daily basis. You could think that I'm chilling but not, I work hard, I learn a lot of stuff and I put the best of me because I feel comfortable and grateful to how my manager handles the startup. </p>","tags":["Mental Health","Work-Life Balance","Personal Growth"]},{"location":"writing/2024/12/03/motivation/#conclusions","title":"Conclusions","text":"<ul> <li>Fix your sleep. Try everything and don't give up for too much time.  You can try:<ul> <li>Magnesium</li> <li>Having dinner earlier</li> <li>Start relaxing one hour before (lights down, no screens, reading a bit, etc). This is the most unrealistic for me, can be done once, not regularly if you are anxious.</li> <li>Drink some relaxing tea.</li> <li>Legal drugs (alprazolam or similar, check with doctor.)</li> <li>Nose strips</li> <li>Meditate</li> </ul> </li> </ul> <p>You need to find what's the main cause but if it's only \"being anxious\", start trying stuff, at least you will feel doing something about it.</p> <ul> <li>If you can afford it, change your job, take a sabbatical, take some time and look for what you really want.</li> </ul>","tags":["Mental Health","Work-Life Balance","Personal Growth"]},{"location":"writing/2025/01/26/obsidian-workflow/","title":"Obisidan Workflow","text":"<p>This is my first personal order for Obsidian with some actual rules and not improvising everything.</p> <p>I've read Kepano's way and this other guy I think both are useful in some way but I' sticking closer to Kepano. Not copying as he has a lots of templates with structured information in the YAML as he seems to create a lot of lists and rankings. Currently I'm using Obsidian a lot for technical notes, daily notes, paper annotation but also some listing as books I've read, movies, etc. It's a mix and I'm not sure I know what info to put for everything that is not a book, or game. Like, notes from some technical topic I can put the area or the author but there is no ranking.</p> <p>Also, I like folders and he hates them. I'll do the following.</p> <ul> <li>Have folders by general topic to order the notes (book, movies,  companies I work for, projects). Notes will be written where they belong the most. For general technical topics (such as Xgboost, I might create a data science or technical folder with all there. I'll put reasonable tags, many notes in different folders might share tags)</li> <li>Notes across folders might share useful information. Maybe I have some deployment technical note on a company that could apply for another project, or even I'll want to find it without remembering where I applied it, so, I'll also add tags so I can see everything together using dataview</li> <li>I'll try to add relevant information usable by dataview in some cases, such as Author for books, or technical notes.</li> <li>I'll have a [[tags]] folder with relevant tags with queries from dataview so I can have stuff organized.</li> <li>I'll keep tags in english for technical stuff but for books, series, etc where is more natural to remember in spanish (I'm from Argentina) and won't be shared probably I'll ues them in spanish (such as \"policial\", \"novela\", etc which are words that I never use in english). </li> </ul>","tags":["Work-Life Balance","Personal Growth"]},{"location":"writing/2024/06/04/reflections-on-quitting/","title":"Reflections on quitting my ML job","text":"<p>As I'm starting my sabbatical journey I am reading some posts of Jason Liu since he seems to have a career similar to something I would like to if I got into ML and LLM riding the hype wave. Furthermore I find his writing pleasant and his content could be useful even as a solopreneur. </p> <p>One of my goals for this period of time is to write more. To take more notes since I struggle memorizing without them (or even with them but at least I can read a summary later) and I want to actually do more. More of everything, less thinking about and more actual doing. From shipping products, to really learning and that includes writing.</p> <p>Reading his post and starting now my journey, a real action would be to take notes about his post, which I found useful, at least some bits of it. Not taking notes would be less writing, less doing, less memorizing. </p>","tags":["Mental Health","Work-Life Balance","Machine Learning","Personal Growth","COVID-19"]},{"location":"writing/2024/06/04/reflections-on-quitting/#choosing","title":"Choosing","text":"<p>Right now, I feel more at this point</p> <p>\"This despair arises from the realization of one's absolute freedom and the responsibility for creating one's own essence and purpose.\"</p> <p>Lately, last few years probably, I have started to realize that quote. We can go a long way by following the usual paths, at least usual to our surroundings. In my case, without major distress that turns everything upside down, it was high school, university, get a job, get married, retire. At least, that's something I (many?) thought as given, a fate that if didn't screw it, it would happen automatically.</p> <p>And as I was applied and I did good in school, I got the first 3 steps quite easily. I never really thought of going out of that path and saw the ones doing so as outliers or with greater safety nets to fail. In some cases it could be true, in others it was probably me being short sighted, I guess it was not my fault but just lack of adult life.  </p> <p>As years go by, I start questioning the meaning of what I'm doing. Is my job meaningful? Does it create value or help anyone? Corporate world feels like a charade. Despite I was working in analytics and studying and building ML models, I couldn't see if that was worth the effort and time. Once you go past the hype of learning models and cool tech bits, looking over that it feels empty. I changed jobs. Still the same, I was dreading in boredom and rat race. Needing to \"impress\" people or feeling that I need to be there for work 9-5 each day without feeling motivated was awful. I quit after a few months willing to take some time off. What am I doing? I have no purpose and my day to day means nothing. I like seeing my friends and family, traveling, etc but the regular life has a lot more things and time to fill. I can't make this for 30 more years.</p> <p>Fortunately, tech and ML pays high salaries so I felt safe. I could take some time off, I can always look for other job, etc. But the feeling of \"I need to do something different\" was there. I started looking for other opportunities, looking for purpose in jobs, looking for motivation. I was in despair as I understood that I needed to do my own way and no one was doing it for me. </p> <p>Ironically, I took another job quit quickly because it paid much more and I could just try it, maybe I was just in the wrong place. Seemed to work better, it was less of a charade, I had more time for crafting and working, I got some motivation back as I felt at least more comfortable daily. Not that I had purpose really but working was at least with less pressure. The time zone differences helped because I didn't feel like 9 hours a day I was supposed to be there, with someone 1 click away of sending a slack message to me. I stayed two years. Earning good money compared to my spending, saving and \"happy\". Eventually everything started to decay, the job was less free, the business request were more urgent and I quickly lost motivation and started to fall in despair again. What am I doing? Who cares about this parquet file with funny numbers?</p> <p>I quit, this time for good. Despair again, realization, I need to find something for myself, or try at least. I fear for its complexity, I fear if I can do it, if I can make a living in another way. I'm taking some time to rest but I know eventually I will need to figure things out. On my own, making my own way, and I see how no one will do it for me.</p> <p>As a side note, finding purpose, finding your way, etc was also a thing when I thought about romantic relationships. Finding someone that you really care about and that cares about you is not easy at all and it doesn't happen magically as I thought as a kid. I am not going to expand about it here but it was another topic that made me realize about our own fate and efforts.</p> <p>Side side note, retirement is another one. I don't see my national retirement plan as something you can live off. I see my family, that luckily does well but despite that nothing is granted and we can support the elder in my family because our own safety net. A younger me didn't know that but as my twenties went by I started to see a lot more of adult/real life. Eye opening period of my life.</p> <p>How to be lucky</p> <p>\"Okay, I'm focused on getting X, but let's not forget to read the headlines.\"</p> <p>High Agency and be the plumber</p> <p>Reminder to myself, focus on bringing solutions and not the shiny new tool. I think I'm good at high agency or at being responsible and wanting to finish what I commit to. I need to work on focusing on which solution am I bringing. Finding the right niche and actually bringing value. In my case with sportsjobs.online, not just throwing things into it, but making it clear what I am providing. For other topics related to ML and LLM I need to decide what I'll focus on this time coming in.</p> <p>Impostor Syndrome I'm the classical example of not trusting myself  and thinking stuff like this.</p> <p>but at the end of the day, you must just think I have shit taste and that you've somehow tricked me into thinking you're good when you're an impostor? Right?</p> <p>I need to stop with that. Quitting now I had plenty of nice words for every colleague, including the desire from managers that I stay or I come back if I get bored of not having a job. Of course, as I write that, I think in the back of my mind of exceptions and that technical colleagues were less effusive as my managers and etc. but all of that is probably not true. I'm going against all evidence and just guessing and making things in my head.</p> <p>How to Be Good at Many Things Consistency. Every one says this. I need to do it the right way now that I'll have the time. No excuses.</p> <p>Do things, practice, keep going for it. Everything will be easier and quicker.</p> <p>And I need to be grateful for what I have and how lucky I am to be able to get a sabbatical time to try to change the path I'm going.</p>","tags":["Mental Health","Work-Life Balance","Machine Learning","Personal Growth","COVID-19"]},{"location":"writing/2024/12/29/taking-notes/","title":"Taking notes is life changing.","text":"<p>I constantly feel that my memory is failing me more and more even for things that I put effort of retaining. Why is a more complex topic, I'm not sure, some medical condition? chronical bad sleep? nothing wrong just this is it and everyone has this poor memory? </p> <p>The feeling is like when you read some code you wrote few weeks/months ago and you can't remember anything nor why you did it this way. Well, that but for a lot of stuff.</p> <p>Despite the cause I've decided to help myself and stop thinking \"I will remember this, it's super important\" and I began taking notes regularly. This helped me in a huge way for personal topics but also for work and technical subjects.</p> <p>It helps in two ways:</p> <p>1) Writing helps memorizing things, you are going through it again and you need to organize a bit your ideas to put them on paper. 2) I have a place to rest on where I can find information I should have memorized.</p> <p>I started doing it randomly for everyday things, like things I want to buy for the house, places I would like to visit, places I've gone. This Christmas I'm also writing the gifts I gave, and what I received. I hate the feeling of someone telling me \"Hey, this is the shirt you gave me!\" and I'm speechless for a second and it's obvious I don't remember, or to avoid giving twice the same gift. I'm expanding these notes as I encounter situations where I regret the status of my memory.  </p> <p>But taking notes is also huge for me in terms of Work and research.  </p> <p>Some examples: </p> <ul> <li>Daily notes on what I've done in my full time job (YYYY-MM-DD). I can always come back if someone asks, sometimes I put some briefs about decisions made on meetings. Specially useful for Mondays where I forget what I did/talked on Friday.  </li> <li>Notes on how I did something that I did for the first time. In my job or in my side businesses, including decisions, commands, installation processes. I find myself coming back to these really often and I think this saves my huge amounts of time, stress and frustration. It's surprising how I forget THE command I've been running twice a day for some deployment test if I have to come back to that topic two weeks later. Something that seems impossible to forget at some point just vanishes. Also, super useful for my side business where I setup something once (DB, platform, server, whatever) and I need to revisit how I did it or what resource I followed in case I have to do it again.  </li> <li>Studying. I'm also taking side notes on books and papers that I later write down in the form of more structured texts. What I understood about papers, doubts, summaries. As usual, while reading I feel I understand but then if I need to revisit the paper without notes it feels like I need to re read it. Many times I read my notes and I feel surprised as I don't remembered a lot of contents, is like the note was given to me by someone else.</li> </ul>","tags":["Mental Health","Work-Life Balance","Personal Growth"]},{"location":"writing/archive/2025/","title":"2025","text":""},{"location":"writing/archive/2024/","title":"2024","text":""},{"location":"writing/archive/2022/","title":"2022","text":""},{"location":"writing/archive/2021/","title":"2021","text":""},{"location":"writing/archive/2020/","title":"2020","text":""},{"location":"writing/archive/2019/","title":"2019","text":""},{"location":"writing/archive/2018/","title":"2018","text":""},{"location":"writing/category/ai/","title":"AI","text":""},{"location":"writing/category/machine-learning/","title":"Machine Learning","text":""},{"location":"writing/category/personal/","title":"Personal","text":""},{"location":"writing/category/estadistica/","title":"estadistica","text":""},{"location":"writing/category/statistics/","title":"statistics","text":""},{"location":"writing/category/python/","title":"Python","text":""},{"location":"writing/category/r/","title":"R","text":""},{"location":"writing/category/algebra/","title":"algebra","text":""},{"location":"writing/category/matematica/","title":"matematica","text":""},{"location":"writing/category/blog/","title":"blog","text":""},{"location":"writing/page/2/","title":"My words, sometimes technical, sometimes not","text":""},{"location":"writing/page/3/","title":"My words, sometimes technical, sometimes not","text":""},{"location":"writing/page/4/","title":"My words, sometimes technical, sometimes not","text":""},{"location":"writing/page/5/","title":"My words, sometimes technical, sometimes not","text":""},{"location":"writing/category/machine-learning/page/2/","title":"Machine Learning","text":""},{"location":"writing/category/r/page/2/","title":"R","text":""},{"location":"writing/category/estadistica/page/2/","title":"estadistica","text":""},{"location":"writing/category/estadistica/page/3/","title":"estadistica","text":""}]}