
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="Franco Betteo - Sr. Data Scientist, Machine Learning Engineer and AI Consultant with experience in CPG, retail, sports analytics and more.">
      
      
        <meta name="author" content="Franco Betteo">
      
      
        <link rel="canonical" href="https://fbetteo.com/writing/">
      
      
        <link rel="prev" href="../services/">
      
      
        <link rel="next" href="category/ai/">
      
      
      <link rel="icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.5.49">
    
    
      
        <title>My words, sometimes technical, sometimes not - Franco Betteo</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.6f8fc17f.min.css">
      
        
        <link rel="stylesheet" href="../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CFira+Code:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Fira Code"}</style>
      
    
    
      <link rel="stylesheet" href="../stylesheets/extra.css">
    
    <script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      
  


  
  

<script id="__analytics">function __md_analytics(){function e(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],e("js",new Date),e("config","G-9PSZTJX51H"),document.addEventListener("DOMContentLoaded",(function(){document.forms.search&&document.forms.search.query.addEventListener("blur",(function(){this.value&&e("event","search",{search_term:this.value})}));document$.subscribe((function(){var t=document.forms.feedback;if(void 0!==t)for(var a of t.querySelectorAll("[type=submit]"))a.addEventListener("click",(function(a){a.preventDefault();var n=document.location.pathname,d=this.getAttribute("data-md-value");e("event","feedback",{page:n,data:d}),t.firstElementChild.disabled=!0;var r=t.querySelector(".md-feedback__note [data-md-value='"+d+"']");r&&(r.hidden=!1)})),t.hidden=!1})),location$.subscribe((function(t){e("config","G-9PSZTJX51H",{page_path:t.pathname})}))}));var t=document.createElement("script");t.async=!0,t.src="https://www.googletagmanager.com/gtag/js?id=G-9PSZTJX51H",document.getElementById("__analytics").insertAdjacentElement("afterEnd",t)}</script>
  
    <script>"undefined"!=typeof __md_analytics&&__md_analytics()</script>
  

    
    
    
<meta name="google-site-verification" content="sTlnUEhcBU3K5YuzTyLOLr1IF6e9zoBRLK5w9Lm-AmQ" />

  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="youtube" data-md-color-primary="indigo" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#my-words-sometimes-technical-sometimes-not" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow md-header--lifted" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href=".." title="Franco Betteo" class="md-header__button md-logo" aria-label="Franco Betteo" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Franco Betteo
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              My words, sometimes technical, sometimes not
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="youtube" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-hidden="true"  type="radio" name="__palette" id="__palette_0">
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
          <a href="javascript:void(0)" class="md-search__icon md-icon" title="Share" aria-label="Share" data-clipboard data-clipboard-text="" data-md-component="search-share" tabindex="-1">
            
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7s-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91s2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08"/></svg>
          </a>
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/fbetteo/blog" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.7.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
  </div>
  <div class="md-source__repository">
    fbetteo/blog
  </div>
</a>
      </div>
    
  </nav>
  
    
      
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href=".." class="md-tabs__link">
          
  
    
  
  Home

        </a>
      </li>
    
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../services/" class="md-tabs__link">
        
  
    
  
  Services

      </a>
    </li>
  

      
        
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="./" class="md-tabs__link">
          
  
    
  
  Writing

        </a>
      </li>
    
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="https://sportsjobs.online" class="md-tabs__link">
        
  
    
  
  Job Board

      </a>
    </li>
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../nba_salaries/" class="md-tabs__link">
          
  
    
  
  NBA salaries legacy model

        </a>
      </li>
    
  

      
    </ul>
  </div>
</nav>
    
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="Franco Betteo" class="md-nav__button md-logo" aria-label="Franco Betteo" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    Franco Betteo
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/fbetteo/blog" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.7.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
  </div>
  <div class="md-source__repository">
    fbetteo/blog
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
    
    
      
      
        
      
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href=".." class="md-nav__link">
      
  
  <span class="md-ellipsis">
    Home
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../services/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Services
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
      
        
          
        
      
        
      
        
      
    
    
      
        
        
      
      
        
      
    
    
      
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" checked>
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="./" class="md-nav__link md-nav__link--active">
              
  
  <span class="md-ellipsis">
    Writing
  </span>
  

            </a>
            
              
              <label class="md-nav__link md-nav__link--active" for="__nav_3" id="__nav_3_label" tabindex="">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            Writing
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
      
        
          
          
        
      
    
    
      
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_3_2" >
        
          
          <label class="md-nav__link" for="__nav_3_2" id="__nav_3_2_label" tabindex="">
            
  
  <span class="md-ellipsis">
    Archive
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_2">
            <span class="md-nav__icon md-icon"></span>
            Archive
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="archive/2025/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    2025
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="archive/2024/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    2024
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="archive/2022/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    2022
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="archive/2021/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    2021
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="archive/2020/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    2020
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="archive/2019/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    2019
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="archive/2018/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    2018
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
      
        
          
          
        
      
    
    
      
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_3_3" >
        
          
          <label class="md-nav__link" for="__nav_3_3" id="__nav_3_3_label" tabindex="">
            
  
  <span class="md-ellipsis">
    Categories
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_3">
            <span class="md-nav__icon md-icon"></span>
            Categories
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="category/ai/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    AI
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="category/machine-learning/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Machine Learning
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="category/personal/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Personal
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="category/python/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Python
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="category/r/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    R
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="category/algebra/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    algebra
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="category/blog/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    blog
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="category/estadistica/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    estadistica
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="category/matematica/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    matematica
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="category/statistics/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    statistics
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="https://sportsjobs.online" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Job Board
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
          
        
      
    
    
      
      
        
      
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../nba_salaries/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    NBA salaries legacy model
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#showering" class="md-nav__link">
    <span class="md-ellipsis">
      Showering
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#how-karpathy-uses-llms" class="md-nav__link">
    <span class="md-ellipsis">
      How Karpathy uses LLMs
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#llama-index-and-rag-starter-point" class="md-nav__link">
    <span class="md-ellipsis">
      Llama Index and RAG starter point
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#how-to-use-poetry-with-conda-environments" class="md-nav__link">
    <span class="md-ellipsis">
      How to use Poetry with Conda environments
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#deep-dive-into-llms-like-chatgpt-karpathy" class="md-nav__link">
    <span class="md-ellipsis">
      Deep Dive into LLMs Like ChatGPT - Karpathy
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#e-commerce-image-similarity-via-visual-embeddings" class="md-nav__link">
    <span class="md-ellipsis">
      E-commerce Image Similarity via Visual Embeddings
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#kullback-leibler-divergence" class="md-nav__link">
    <span class="md-ellipsis">
      Kullback-Leibler divergence
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#mutual-information" class="md-nav__link">
    <span class="md-ellipsis">
      Mutual Information
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#obisidan-workflow" class="md-nav__link">
    <span class="md-ellipsis">
      Obisidan Workflow
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#entropy-and-information" class="md-nav__link">
    <span class="md-ellipsis">
      Entropy and information
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
  <div class="md-content" data-md-component="content">
    <div class="md-content__inner">
      <header class="md-typeset">
        <h1 id="my-words-sometimes-technical-sometimes-not">My words, sometimes technical, sometimes not<a class="headerlink" href="#my-words-sometimes-technical-sometimes-not" title="Permanent link">&para;</a></h1>
<p>I previously had a <a href="https://fbetteo.netlify.app">blog</a> where I used to write about technical topics in english or spanish (lately only english). Here you can find all that old content and anything new that I publish, this is the actual <strong>source of truth</strong>.</p>
<p>You can expect to find topics around statistics, AI, machine learning, learning to do business or software in general but also about myself.</p>
<p><a class="md-button md-button--secondary" href="https://x.com/franbetteo"><span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M22.46 6c-.77.35-1.6.58-2.46.69.88-.53 1.56-1.37 1.88-2.38-.83.5-1.75.85-2.72 1.05C18.37 4.5 17.26 4 16 4c-2.35 0-4.27 1.92-4.27 4.29 0 .34.04.67.11.98C8.28 9.09 5.11 7.38 3 4.79c-.37.63-.58 1.37-.58 2.15 0 1.49.75 2.81 1.91 3.56-.71 0-1.37-.2-1.95-.5v.03c0 2.08 1.48 3.82 3.44 4.21a4.2 4.2 0 0 1-1.93.07 4.28 4.28 0 0 0 4 2.98 8.52 8.52 0 0 1-5.33 1.84q-.51 0-1.02-.06C3.44 20.29 5.7 21 8.12 21 16 21 20.33 14.46 20.33 8.79c0-.19 0-.37-.01-.56.84-.6 1.56-1.36 2.14-2.23"/></svg></span> Follow me on X</a></p>
      </header>
      
        <article class="md-post md-post--excerpt">
  <header class="md-post__header">
    
      <nav class="md-post__authors md-typeset">
        
          <span class="md-author">
            <img src="https://cdn.sportsjobs.online/personal_profile_pic.jpg" alt="Franco Betteo">
          </span>
        
      </nav>
    
    <div class="md-post__meta md-meta">
      <ul class="md-meta__list">
        <li class="md-meta__item">
          <time datetime="2025-08-16 00:00:00+00:00">2025-08-16</time></li>
        
          <li class="md-meta__item">
            in
            
              <a href="category/personal/" class="md-meta__link">Personal</a></li>
        
        
          
          <li class="md-meta__item">
            
              1 min read
            
          </li>
        
      </ul>
      
    </div>
  </header>
  <div class="md-post__content md-typeset">
    <h2 id="showering"><a class="toclink" href="2025/08/16/showering/">Showering</a></h2>
<p>Showering is the last wall against massive brain rot.</p>
<p>You are alone, you feel safe, and your brain doesn't expect interruptions.
No one will enter nor talk to you. There is peace in that.</p>
<p>It's relaxing and demands low attention. You can wander.</p>
<p>You can't distract yourself with social media, doomscrolling, nor chase the dopamine.</p>
<p>Showering has this combination of attributes hard to find and that allows you to think, to find solutions with peace of mind, away from the daily distractions.</p>
<p>It's the only shelter to really use your brain, to focus on thoughts. Without this space, there is nowhere to hide from social media, there is no place to avoid your brain being targeted.</p>
<p>You can reflect on your life, solve problems from work, find peace from stress.</p>
<p>The water and privacy hold the fort.</p>
<p>If the shower falls, we are dead.</p>
    
  </div>
</article>
      
        <article class="md-post md-post--excerpt">
  <header class="md-post__header">
    
      <nav class="md-post__authors md-typeset">
        
          <span class="md-author">
            <img src="https://cdn.sportsjobs.online/personal_profile_pic.jpg" alt="Franco Betteo">
          </span>
        
      </nav>
    
    <div class="md-post__meta md-meta">
      <ul class="md-meta__list">
        <li class="md-meta__item">
          <time datetime="2025-07-25 00:00:00+00:00">2025-07-25</time></li>
        
          <li class="md-meta__item">
            in
            
              <a href="category/ai/" class="md-meta__link">AI</a>, 
              <a href="category/machine-learning/" class="md-meta__link">Machine Learning</a></li>
        
        
          
          <li class="md-meta__item">
            
              4 min read
            
          </li>
        
      </ul>
      
    </div>
  </header>
  <div class="md-post__content md-typeset">
    <h2 id="how-karpathy-uses-llms"><a class="toclink" href="2025/07/25/how-karpathy-uses-llms/">How Karpathy uses LLMs</a></h2>
<p><a href="https://www.youtube.com/watch?v=EWvNQjAaOHw">Original video from Andrej Karpathy.</a></p>
<hr />
<p>Models are good at writing.</p>
<p>We collaborate with the assistant in the creation of the context window, both providing tokens, by message or by generation.</p>
<p><strong>We must be careful with the context</strong> <br />
The longer the context, the more the model can get "distracted" by old tokens, reducing accuracy.<br />
With longer context, generation becomes a bit more expensive (computationally) and so the model is slowed down a bit. <br />
It's the working memory. We should keep it simple and short to make it work better. If the long context is relevant well, then use it of course.
He suggests to start new conversations to clean up the context and obviously when you change subjects.</p>
<h5 id="thinking-models"><a class="toclink" href="2025/07/25/how-karpathy-uses-llms/#thinking-models">Thinking models</a></h5>
<p>He uses 4o usually but when he thinks the answers could be better, he tries a thinking model. Of course, he doesn't do this for simple questions but for example, for not obvious coding problems.</p>
<h4 id="how-to-use-search-tool"><a class="toclink" href="2025/07/25/how-karpathy-uses-llms/#how-to-use-search-tool">How to use Search Tool</a></h4>
<p>Think about it as googling and inserting a bunch of internet text in the context and then it goes back to your question and tries to answer with all the relevant information got from the internet.</p>
<p>Some models detect that they need to search because the question is recent and they use it automatically but  if you know it's needed, just use the search tool. Questions that need recent information require search because the pretraining happened several months ago and have a training cutoff.</p>
<h4 id="deep-research"><a class="toclink" href="2025/07/25/how-karpathy-uses-llms/#deep-research">Deep Research</a></h4>
<p>...</p>
<h4 id="file-upload"><a class="toclink" href="2025/07/25/how-karpathy-uses-llms/#file-upload">File Upload</a></h4>
<p>Similar, it probably just uploads the text into context.
He starts by asking "can you summarize this paper?"</p>
<p>He reads and uses LLMs. He copy/paste the chapter he is reading to the LLM. "Please summarize this chapter to starts". He reads summary, then he reads the actual book and ask questions. His retention and understanding increases a lot. Specially useful for fields you are not an expert or old books with different language / context / culture.</p>
<h4 id="code-interpreter"><a class="toclink" href="2025/07/25/how-karpathy-uses-llms/#code-interpreter">Code interpreter</a></h4>
<p>Use python to answer questions, such as calculations that you should do with a calculator at least.</p>
<h4 id="advanced-data-analysis"><a class="toclink" href="2025/07/25/how-karpathy-uses-llms/#advanced-data-analysis">Advanced Data analysis</a></h4>
<p>Kind of a Junior data analyst.
Needs verification, it might do some assumptions without telling or hallucinate.</p>
<h4 id="claude-artifacts"><a class="toclink" href="2025/07/25/how-karpathy-uses-llms/#claude-artifacts">Claude Artifacts</a></h4>
<p>He asked for Flashcards based on the chapter of a book and then asked the artifact to create an app to use those flashcards and the app is usable in the browser.</p>
<p>He doesn't use much but he finds useful to create diagrams.</p>
<h4 id="cursor"><a class="toclink" href="2025/07/25/how-karpathy-uses-llms/#cursor">Cursor</a></h4>
<p>He uses apps for AI coding, Cursor right now. Using web interpreter is too slow.</p>
<h4 id="audio"><a class="toclink" href="2025/07/25/how-karpathy-uses-llms/#audio">Audio</a></h4>
<p>He speak to models regularly (in the phone or computer)</p>
<h5 id="microphone"><a class="toclink" href="2025/07/25/how-karpathy-uses-llms/#microphone">Microphone</a></h5>
<p>The microphone is to transcript what you say into text (in cellphone)</p>
<p>In computer you don't have the microphone button, you have the audio logo. He then uses some app to transcripts (whisper superwhisper   )
But this doesn't work super well for libraries and programs, and etc. He types that kind of content.
Anyways, this is "fake audio" since in reality is sending the audio as text to the context</p>
<p>There are text to audio apps if you are not using chatgpt which has the functionality </p>
<h5 id="real-audio"><a class="toclink" href="2025/07/25/how-karpathy-uses-llms/#real-audio">Real audio</a></h5>
<p>Advanced voice mode in chatgpt. 
Here the voice is handled natively in the model, converting into tokens and outputting audio if you want (maybe it's the only option)
It's a bit annoying and rejects many requests but still really insteresting.</p>
<h4 id="images"><a class="toclink" href="2025/07/25/how-karpathy-uses-llms/#images">Images</a></h4>
<p>Transform the images into tokens and fill the context. In the end the transformer/model doesn't know that the input originally was an image, they are just tokens for it, but we can know at the decondig stage.</p>
<p>For real use cases, he shows a nutritional table and he wants to know more about the "ingredients".
He uses 2 stages, first transcribe the image, so we can be sure that the model is reading correctly the image.
And then ask questions about the content.</p>
<p>Also for evaluating mathematical formulas.
Paste image, transcript and then ask questions.</p>
<p>Dalle3 outputs (images) are not the direct output of the neural net. It generates a caption and under the hood sends it to another model that is an image generator.</p>
<h4 id="video"><a class="toclink" href="2025/07/25/how-karpathy-uses-llms/#video">Video</a></h4>
<p>In advanced mode, there is a video mode where you can ask questions about what you are pointing your phone to.</p>
<h4 id="memory"><a class="toclink" href="2025/07/25/how-karpathy-uses-llms/#memory">Memory</a></h4>
<p>Every new chat erases the whole context but there is a way to keep something in memory across chats (when you see "Memory updated"). Usually you need to invoke it, ask for it to remember.</p>
<p>These memories (what it knows about you) are always prepended to the contexts so it's always available with some things personalized for you.</p>
<p>Custom Instructions. You can tune chatgpt to your like, give it identity and traits.</p>
<h4 id="custom-gpts"><a class="toclink" href="2025/07/25/how-karpathy-uses-llms/#custom-gpts">Custom GPTs</a></h4>
<p>He uses them mostly for specific actions, like generate flashcards for korean vocabulary</p>
    
  </div>
</article>
      
        <article class="md-post md-post--excerpt">
  <header class="md-post__header">
    
      <nav class="md-post__authors md-typeset">
        
          <span class="md-author">
            <img src="https://cdn.sportsjobs.online/personal_profile_pic.jpg" alt="Franco Betteo">
          </span>
        
      </nav>
    
    <div class="md-post__meta md-meta">
      <ul class="md-meta__list">
        <li class="md-meta__item">
          <time datetime="2025-07-10 00:00:00+00:00">2025-07-10</time></li>
        
          <li class="md-meta__item">
            in
            
              <a href="category/ai/" class="md-meta__link">AI</a>, 
              <a href="category/machine-learning/" class="md-meta__link">Machine Learning</a></li>
        
        
          
          <li class="md-meta__item">
            
              2 min read
            
          </li>
        
      </ul>
      
    </div>
  </header>
  <div class="md-post__content md-typeset">
    <h2 id="llama-index-and-rag-starter-point"><a class="toclink" href="2025/07/10/llama-index-and-rag-starter-point/">Llama Index and RAG starter point</a></h2>
<p>This is me trying and playing a bit with the <a href="https://docs.llamaindex.ai/en/stable/getting_started/customization/#frequently-asked-questions-faq">starter guide</a> of Llama Index. Basic discovery of how to use this. Actually their starter is more complex, goes into agents right away, so this was more what I was looking for.</p>
<h3 id="creating-the-environment"><a class="toclink" href="2025/07/10/llama-index-and-rag-starter-point/#creating-the-environment">Creating the environment</a></h3>
<p>Poetry already installed and configured in windows to use Conda environments. Not sure how?<a href="https://fbetteo.com/writing/2025/07/10/how-to-use-poetry-with-conda-environments/">Look here</a></p>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a>conda<span class="w"> </span>create<span class="w"> </span>--name<span class="w"> </span>rag<span class="w"> </span><span class="nv">python</span><span class="o">=</span><span class="m">3</span>.12
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>conda<span class="w"> </span>activate<span class="w"> </span>rag
</span><span id="__span-0-4"><a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>poetry<span class="w"> </span>init
</span><span id="__span-0-5"><a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a>poetry<span class="w"> </span>add<span class="w"> </span>llama-index
</span><span id="__span-0-6"><a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a>poetry<span class="w"> </span>add<span class="w"> </span>sentence-transformers
</span><span id="__span-0-7"><a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a>poetry<span class="w"> </span>add<span class="w"> </span>llama-index-embeddings-huggingface
</span></code></pre></div>
<p>llama-index uses by default embedding from OpenAI. It requires the API key (and paying of course.)
Should be cheap but I'll try using local embeddings to see how it goes, using Huggingface as I used for other projects via sentence-transformers.</p>
<p>For local embedding model, we load the model from hugging face and we update the embed_model in Settings.</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-1-1"><a id="__codelineno-1-1" name="__codelineno-1-1" href="#__codelineno-1-1"></a><span class="n">embed_model</span> <span class="o">=</span> <span class="n">HuggingFaceEmbedding</span><span class="p">(</span>
</span><span id="__span-1-2"><a id="__codelineno-1-2" name="__codelineno-1-2" href="#__codelineno-1-2"></a>    <span class="n">model_name</span><span class="o">=</span><span class="s2">&quot;BAAI/bge-small-en-v1.5&quot;</span><span class="p">,</span>
</span><span id="__span-1-3"><a id="__codelineno-1-3" name="__codelineno-1-3" href="#__codelineno-1-3"></a>    <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cpu&quot;</span><span class="p">,</span>
</span><span id="__span-1-4"><a id="__codelineno-1-4" name="__codelineno-1-4" href="#__codelineno-1-4"></a>    <span class="n">embed_batch_size</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
</span><span id="__span-1-5"><a id="__codelineno-1-5" name="__codelineno-1-5" href="#__codelineno-1-5"></a><span class="p">)</span>
</span><span id="__span-1-6"><a id="__codelineno-1-6" name="__codelineno-1-6" href="#__codelineno-1-6"></a>
</span><span id="__span-1-7"><a id="__codelineno-1-7" name="__codelineno-1-7" href="#__codelineno-1-7"></a><span class="n">Settings</span><span class="o">.</span><span class="n">embed_model</span> <span class="o">=</span> <span class="n">embed_model</span>
</span></code></pre></div>
<p>I think this could work alright in terms of speed for now.</p>
<h3 id="ollama"><a class="toclink" href="2025/07/10/llama-index-and-rag-starter-point/#ollama">Ollama</a></h3>
<p>I installed Ollama from their website
Added Ollama to Environment Variables</p>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-2-1"><a id="__codelineno-2-1" name="__codelineno-2-1" href="#__codelineno-2-1"></a>ollama<span class="w"> </span>pull<span class="w"> </span>gemma3
</span><span id="__span-2-2"><a id="__codelineno-2-2" name="__codelineno-2-2" href="#__codelineno-2-2"></a>ollama<span class="w"> </span>pull<span class="w"> </span>gemma3:4b
</span></code></pre></div>
<p>I've been using them in the llama_index_starter.py to avoid using any API.
but with my cpu only computer (32gb ram) everything was really slow.
gemma3 in the terminal was super slow (~30s) , gemma3:4b much faster (~2s) but when integrating into llama index with the retrieval, it was slow too</p>
<p>I feel like there is no usage for local LLMs in my current computer. Maybe if I use a server or collab this could work.</p>
<h3 id="groq"><a class="toclink" href="2025/07/10/llama-index-and-rag-starter-point/#groq">Groq</a></h3>
<p>I found that they have a generous free tier (500k tokens per day for some models) that should be enough to test things and do some minimum POC. I can top up later or use another provider, that's the magic of Llama-index, it should be easy to change the provider.</p>
<p>Also, Groq onboarding couldn't be easier. Log in, they give you API key, and that's it.</p>
<p><code>poetry add llama-index-llms-groq</code></p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-3-1"><a id="__codelineno-3-1" name="__codelineno-3-1" href="#__codelineno-3-1"></a><span class="kn">from</span> <span class="nn">llama_index.llms.groq</span> <span class="kn">import</span> <span class="n">Groq</span>
</span><span id="__span-3-2"><a id="__codelineno-3-2" name="__codelineno-3-2" href="#__codelineno-3-2"></a><span class="n">Settings</span><span class="o">.</span><span class="n">llm</span> <span class="o">=</span> <span class="n">Groq</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="s2">&quot;llama-3.1-8b-instant&quot;</span><span class="p">,</span>
</span><span id="__span-3-3"><a id="__codelineno-3-3" name="__codelineno-3-3" href="#__codelineno-3-3"></a>                <span class="n">api_key</span><span class="o">=</span><span class="n">GROQ_API_KEY</span><span class="p">,</span>
</span><span id="__span-3-4"><a id="__codelineno-3-4" name="__codelineno-3-4" href="#__codelineno-3-4"></a>                <span class="n">request_timeout</span><span class="o">=</span><span class="mf">360.0</span><span class="p">)</span>
</span></code></pre></div>
<p>That's it, I'm using Groq. In the <a href="https://console.groq.com/dashboard/metrics">Dashboard</a> we can see usage, logs, etc, super cool.</p>
    
  </div>
</article>
      
        <article class="md-post md-post--excerpt">
  <header class="md-post__header">
    
      <nav class="md-post__authors md-typeset">
        
          <span class="md-author">
            <img src="https://cdn.sportsjobs.online/personal_profile_pic.jpg" alt="Franco Betteo">
          </span>
        
      </nav>
    
    <div class="md-post__meta md-meta">
      <ul class="md-meta__list">
        <li class="md-meta__item">
          <time datetime="2025-07-10 00:00:00+00:00">2025-07-10</time></li>
        
          <li class="md-meta__item">
            in
            
              <a href="category/ai/" class="md-meta__link">AI</a>, 
              <a href="category/machine-learning/" class="md-meta__link">Machine Learning</a></li>
        
        
          
          <li class="md-meta__item">
            
              1 min read
            
          </li>
        
      </ul>
      
    </div>
  </header>
  <div class="md-post__content md-typeset">
    <h2 id="how-to-use-poetry-with-conda-environments"><a class="toclink" href="2025/07/10/how-to-use-poetry-with-conda-environments/">How to use Poetry with Conda environments</a></h2>
<p>Poetry uses by default the system installed python and creates a new environment using that one. I prefer creating a new env with conda, install whatever python version I want and work in there.</p>
<p>1) Create an environment with Conda and activate it</p>
<p>2) Have setup (once, globally) that Poetry uses the current environment python version
<div class="language-bash highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a>poetry<span class="w"> </span>config<span class="w"> </span>virtualenvs.create<span class="w"> </span><span class="nb">false</span>
</span></code></pre></div></p>
    
  </div>
</article>
      
        <article class="md-post md-post--excerpt">
  <header class="md-post__header">
    
      <nav class="md-post__authors md-typeset">
        
          <span class="md-author">
            <img src="https://cdn.sportsjobs.online/personal_profile_pic.jpg" alt="Franco Betteo">
          </span>
        
      </nav>
    
    <div class="md-post__meta md-meta">
      <ul class="md-meta__list">
        <li class="md-meta__item">
          <time datetime="2025-03-10 00:00:00+00:00">2025-03-10</time></li>
        
          <li class="md-meta__item">
            in
            
              <a href="category/ai/" class="md-meta__link">AI</a>, 
              <a href="category/machine-learning/" class="md-meta__link">Machine Learning</a></li>
        
        
          
          <li class="md-meta__item">
            
              12 min read
            
          </li>
        
      </ul>
      
    </div>
  </header>
  <div class="md-post__content md-typeset">
    <h2 id="deep-dive-into-llms-like-chatgpt-karpathy"><a class="toclink" href="2025/03/10/deep-dive-into-llms/">Deep Dive into LLMs Like ChatGPT - Karpathy</a></h2>
<p><a href="https://www.youtube.com/watch?v=7xTGNNLPyMI">Original video from Andrej Karpathy. Masterpiece.</a></p>
<hr />
<p><a href="https://huggingface.co/spaces/HuggingFaceFW/blogpost-fineweb-v1">Fineweb</a></p>
<p>Tokenization. From words to tokens. Tokens are not words and punctuation, they can be the root of words, they can be some sequence of letters without explicit meaning. This will change depending on the model. (<a href="https://tiktokenizer.vercel.app">tiktokenizer</a> para verlo en accion)</p>
<p>How it works? From words to bits with encoding could be the first step. From words to 1 and 0. But this becomes a super large representation because we only have two symbols.
We can group every 8 bits into 256 different bytes. [0 to 255]  The sequence is much shorter because we have more symbols.
We can use this, but in SOTA we go beyond that. We use Byte-pair encoding which looks for common pairs of bytes and we create a new symbols starting from 256, and we can do this many times. More symbols, shorter representation. Gpt4 ends up with +100k symbols.</p>
<h4 id="neural-networks"><a class="toclink" href="2025/03/10/deep-dive-into-llms/#neural-networks">Neural Networks</a></h4>
<p>We take windows of tokens of flexible  length up to some maximum (4, 8, 16k). Too much could be computationally expensive.</p>
<p>The idea is to predict the next token. The window used is the <em>context</em>.
We do this for every context and token of the training data. The process will adjust the probabilities of each next token. They are initialized at random and in the end they should match the statistical properties of the dataset.</p>
<p>Training is done via Neural Network, the mathematical expression is updated via weights. Input is the token sequence, output is the probability of each token as the next one. In the middle there is the NN architecture with transformers and etc. First parts includes the embedding into numerical representation.</p>
<h5 id="inference"><a class="toclink" href="2025/03/10/deep-dive-into-llms/#inference">Inference</a></h5>
<p>Put an initial token and sample from the output probability distribution, this is your next token. We do that again, but now the context is 2 tokens, and so on.</p>
<h4 id="gpt-2-train-and-inference"><a class="toclink" href="2025/03/10/deep-dive-into-llms/#gpt-2-train-and-inference">GPT-2 train and inference</a></h4>
<p>Useful because the technical parts are still relevant only that now are bigger and more complex.</p>
<p>Base model is the model that comes out after training. It's an inference machine, just token prediction but it's not useful for chat for example. Some companies release their base models but not all of them.
GPT2 was released. A base model release requires, the model architecture and the model weights.</p>
<p>Llama 3 is another one more recent. 2024, 405 billions parameters</p>
<p>Base model are somewhat good at memorization (regurgitation) which is not desirable. If you paste the first sentence of a wikipedia page it will probably output the exact rest of the article up until some point and then deviate.</p>
<p>Wikipedia also has more weight in the model because the source is truthful. I'm not sure if this is because the wikipedia extract appears more times in the corpus because of citations and so or because some sources have more importance than other from pretraining methodology. </p>
<p>Base model is still useful to some extent without being an assistant if you are clever with the prompt.</p>
<p><strong>Few shot prompt</strong>. 
The model has some <em>in-context</em> learning, which is that the model can understand a pattern in the prompt. In the video, AK prompts a list of english words with their korean translation and left the last one without translating to make inference from that point.</p>
<p>He also shows that you can generate some assistant type of inference via in-context learning by passing an example of human-assistant interaction and making it generate the answer to you actual question via inference.</p>
<h4 id="post-training"><a class="toclink" href="2025/03/10/deep-dive-into-llms/#post-training">Post training</a></h4>
<p>Pretraining is all that we saw before. Get data from the web, tokenize it and create a base model that predicts next token. It's not an assistant, it's like a internet text generator. That's all included in pretraining and it's the expensive part, the one that takes millions of dollars and a lot of time.</p>
<p><strong>Post training</strong><br />
Much less computation than pretraining and it's the step that moves us from a token generator to an assistant.</p>
<p>Because this is a neural network we can't explicitly program the assistant or give them a personality or make it refuse some kind of questions. We can only do that via neural networks training on datasets.</p>
<p>Programming by example.
And the examples requires human labelers.
We train the model on this responses and try to imitate that behaviour.</p>
<p>We substitute the training dataset of the model, we remove all the internet text and we start using the conversation dataset. We keep training the model but know with this dataset and the model will pick the statistics of this new dataset and how the conversations should happen. (Supervised Finetuning aka SFT)</p>
<p>Post training in SOTA can be in 3 hours for example vs 3 months of training in pre training and thousands of CPUs. This is because post training the dataset is human created and much smaller.</p>
<h5 id="how-do-we-go-from-conversations-in-the-new-dataset-to-tokens"><a class="toclink" href="2025/03/10/deep-dive-into-llms/#how-do-we-go-from-conversations-in-the-new-dataset-to-tokens">How do we go from conversations in the new dataset to tokens?</a></h5>
<p>We need to encode and decode in some specific way. Each model has a slightly different methodology, but gpt-4o has for example a few extra tokens that represent the beginning of the new character talking (user or assistant), then a token for the user or the assistant, then a token for the start of the actual message, then the message tokenized  and then a token for the end of the message. Then we go again, same token representing the beginning, then the other token of user/assistant, etc</p>
<p>So, when we go to chatgpt and ask a question it's sent to the backend encoded with the above format and they add the tokens for the start of a new message from the assistant and run inference there, they let the LLM complete all the next tokens.</p>
<p><a href="https://arxiv.org/abs/2203.02155">InstructGPT paper on SFT:</a>First paper to talk about post-training.
Mentions the heavy human labeler part from where the post training datasets with conversations emerged and some of the instructions the labelers received.
The dataset from OpenAI is not released, but OpenAssistant is an open source alternative with a similar format.</p>
<p>Currently LLMs are being used to help create this datasets of conversations. No need for that much human effort.
But in the end the root of all this conversations is the initial human labelers following OpenAI and other companies instructions.
In the end, chatgpt for example, is answering in the tone and guided by those examples, so it's kind of recreating how the labelers wrote. It's a labeler text generation machine. </p>
<blockquote>
<p>"What would a human labeler say in this conversation?"
 You are talking to a simulation of an average labeler (who is probably some skilled person but still)</p>
</blockquote>
<h4 id="hallucinations"><a class="toclink" href="2025/03/10/deep-dive-into-llms/#hallucinations">Hallucinations</a></h4>
<p>They exist because the model is sampling from the training dataset statistics trying to answer something even if it's not the truth. The problem has been improved over the years but it's still relevant.</p>
<p>How to fix it?</p>
<p>We need to include in the post training dataset some conversations where the answer is that it doesn't know.</p>
<h5 id="mitigation-1-model-interrogation"><a class="toclink" href="2025/03/10/deep-dive-into-llms/#mitigation-1-model-interrogation">Mitigation <a class="magiclink magiclink-github magiclink-issue" href="https://github.com/jxnl/instructor/issues/1" title="GitHub Issue: jxnl/instructor #1">#1</a>: model interrogation</a></h5>
<p>What Meta did for LLama is super clever
. We don't know what the model knows or not exactly so we need to let it decide in some way. They assume there is some internal representation of lack of knowledge, some neuron that gets activated when it doesn't "know" something.
So, what they did to include that pattern is to take random text (from wikipedia lets say) and they used an LLM to create a few questions with factual answers about that text.
They interrogate the model with those questions and compare the answer to the actual truth (also another LLM as judge, no need for human). They did it a few times per question. If the model answered correctly then the conversation output is fine and all good. But if the model hallucinates and answers wrongly (as judged by another LLM based on the actual truth) then the answer to that question in the conversation dataset becomes "Sorry, I don't know". If you add some amount of answers like this (because of course you can't just add all question that don't have a true answer) then the model will get that pattern, that when that unknown neuron related to lack of knowledge gets activated, then answering I don't know is what it should do.
This worked quite well to mitigate hallucinations!</p>
<h5 id="mitigation-2-search"><a class="toclink" href="2025/03/10/deep-dive-into-llms/#mitigation-2-search">Mitigation <a class="magiclink magiclink-github magiclink-issue" href="https://github.com/jxnl/instructor/issues/2" title="GitHub Issue: jxnl/instructor #2">#2</a>: Search</a></h5>
<p>Allow the model to search the internet. Allow the model to use Tools.
We do this by introducing new tokens, in this case special tokens for search_start and search_end with a query in the middle. The Assistant will look up that query in a browser and will copy paste the information it gets just after the special tokens, so the internet information is now in the context. It goes directly into the model, like refreshing our memory as humans.</p>
<p>To add this functionality we need again to teach the model by example, adding a bunch of examples in the dataset on how to use the search.</p>
<blockquote>
<p>Knowledge in the parameters == Vague recollection (e.g. of something you read 1 month ago)
Knowledge in the tokens of the context window == Working memory</p>
</blockquote>
<h3 id="models-need-tokens-to-think"><a class="toclink" href="2025/03/10/deep-dive-into-llms/#models-need-tokens-to-think">Models need tokens to think</a></h3>
<p>Given the neural network architecture, there is a finite amount of computation that can be given for each token. Given the context your forward/inference pass will predict the next token using the network capability but it's finite/limited. We should try to expand/distribute the computation, "the thinking" between many tokens to use the full neural network computation power for each token, so we end up using more computation in total for our answer.
In concrete, he shows a simple math problem. If we aim for the model to answer directly, we are forcing the neural network to use it's context and finite computation to answer in a single attempt. Everything that comes after that answer will be a post hoc justification. While if we aim for the model to elaborate and go step by step (disguised CoT?) it will use full computation for each step and by the time it outputs the answer, it will have a good detailed context to provide that final "calculation"</p>
<p><img alt="image" src="img/Pasted%20image%2020250307130533.png" /></p>
<p>This is the same reason why models are not good at counting. Too much expected from a single forward pass, finite computation.</p>
<p>"use code" it's a great way to make the model good at those tasks, because the model is good at copy pasting and code gives the right answer. So, you can just copy the string to code and then use python to actually count the number of letters or whatever. Same for calculation.
It's much more likely to have the right answer than relying on the "mental arithmetic" of the model.</p>
<p>It's also interesting to understand why a model might be good at solving complex phD level math problems but fail at simple tasks like:
"what is bigger 9.11 or 9.9?" 
which usually is answered wrongly or randomly.</p>
<p>One hypothesis he mentions is that some research team said that the bible has 9.11 &gt; 9.9 in terms of verses and this can create confusion to the neural network but it's a problem not fully understood.</p>
<h3 id="reinforcement-learning"><a class="toclink" href="2025/03/10/deep-dive-into-llms/#reinforcement-learning">Reinforcement Learning</a></h3>
<p>The last major stage, some times is included  as part of post training but it's really a next separate major step.</p>
<blockquote>
<p>It's like going to school.</p>
</blockquote>
<p>He compares the training of  a model to a textbook, general explanations are like the pretraining, then the examples given in the book is like the post training with examples of how things should be solved (how to answer like an assistant) and then there are exercises which the student doesn't have the solution and needs to try to solve. You might have the final answer but not the path towards it. Reinforcement learning is like this last step.</p>
<p>The motivation is that we as humans (labelers) don't know what's the best way for the LLM to solve a specific problem, such as a math problem. He shows a few options, like going straight to the answer, doing some arithmetic, talking in native english and giving the answer, putting the problem as a system of equations, etc. What's easier for us might not be easy for the LLM, so we need to try what approach gives best results.</p>
<p>So, the idea is to generate multiple (thousands) solutions for some problem which isn't trivial and store the stochastic solutions / inferences / token sequence that led to a right answer among all the tries. Some will get the right answer, some don't. And then, the model will be retrained based on the right solutions. So, it's not human labeled anymore, it's just trying solutions and re-train on the ones that were correct so the network learns to keep doing that for similar situations in the future.</p>
<p>Pre and post training are quite standard and used across all providers but the reinforcement learning step is in an earlier stage and not standardized, different providers are trying different approaches and how some details in the process are handled (which is a simple idea overall) has high impact and is not trivial, those details in how we select what is "the best answer" among the correct ones for example play a big role.</p>
<h4 id="deepseek-r1"><a class="toclink" href="2025/03/10/deep-dive-into-llms/#deepseek-r1">Deepseek R1</a></h4>
<p>The <a href="https://arxiv.org/abs/2501.12948">paper</a> was innovative and game changer in part because is  open and explicit about RL while openAI and other kept the details for themselves.</p>
<p>With RL, the model learns over time to give better answers to the questions and it's using more and more tokens to do it. It "discovers" that trying many paths and backtracking and trying again it's better to get a good answers. <em>Chain of thoughts</em> emerge without being hardcoded anywhere by researchers (would be impossible too, it's something the model needs to discover)</p>
<blockquote>
<p>A "thinking/reasoning" model is one that has been trained with Reinforcement Learning</p>
</blockquote>
<p>ChatGPT 4o is not a reasoning one, is SFT montly (learn by example, just finetuned, no RL. He says there is a bit of RL but we should think about them as SFT really). DeepSeek uses RL.  o1 and o3 are also RL ones.</p>
<h4 id="alphago"><a class="toclink" href="2025/03/10/deep-dive-into-llms/#alphago">AlphaGo</a></h4>
<p>RL made it possible for the model to beat top players ELO while supervised learning was not capable. RL is not restricted to human kind of plays and that's how move 37 happened, a play that was not expected by top level players but that actually was really powerful. This happened because the training wasn't guided by supervised learning but by RL (the AI playing against itself kind of)</p>
<h4 id="learning-in-unverifiable-domains-reinforcement-learning-from-humand-feedback"><a class="toclink" href="2025/03/10/deep-dive-into-llms/#learning-in-unverifiable-domains-reinforcement-learning-from-humand-feedback">Learning in Unverifiable domains (Reinforcement learning from Humand Feedback)</a></h4>
<p>The previous problems where easily verifiable, we could just compare in RL if the solution was correct by checking the final output of the LLM vs the right answer, maybe by direct comparison or using LLM as judge where we ask another LLM to check if the solution provided by the model is consistent with the actual solution (currently that approach is quite reliable) but this can't be done in <em>unverifiable domains</em> such as "write a joke about pelicans", "write a poem", etc</p>
<p>For the pelican jokes, in principle you could use humans to judge if the joke is funny and reward it but as you need to evaluate thousands of generations for thousands of prompts, this becomes unfeasible. We need another strategy. This <a href="https://arxiv.org/abs/1909.08593">paper</a>introduced the RL-HF subject</p>
<p><strong>RLHF approach</strong>
<strong>STEP 1</strong> :Take 1000 prompts, generate 5 options, order them from best to worst.
<strong>STEP 2</strong>: Train a neural net simulator of human preferences ("reward model")
<strong>STEP 3</strong>: Run RL as usual, but using the simulator instead of actual humans</p>
<p>The reward model is not a perfect human simulator but it's currently good enough to work meaningfully. </p>
<h5 id="upside"><a class="toclink" href="2025/03/10/deep-dive-into-llms/#upside">Upside</a></h5>
<blockquote>
<p>We can run RL in arbitrary domains (even unverifiable ones) and empirically it gives better results.</p>
</blockquote>
<p>He says that probably this improves the model due to <strong>discriminator - generator gap</strong>. It's easier for a human to discriminate than to generate. It's easier to say which jokes are good or bad than to create the good ones. The labeler doesn't need to create a good joke, it just leaves that hard task to the model and the labeler points out which are good and which are bad</p>
<h5 id="downsides"><a class="toclink" href="2025/03/10/deep-dive-into-llms/#downsides">Downsides</a></h5>
<p>RL is done with respect to a <em>lossy simulation</em> of humans. It might be misleading, we generate orders based on a model that might not reflect the actual human judgement.</p>
<blockquote>
<p>RL discovers ways to "game" the reward model.</p>
</blockquote>
<p>It happens that after a lot of updates, the jokes that are considered the top are non sensical. At first, we some initial updates the jokes might improve but after some point in time they become much worse, like a top joke could be "the the the the the" and somehow that gets a high score by the reward model. Those weird top answers are <em>adversarial examples</em>. Somehow the RL get some answers that go through little paths that somehow  fire good scores without making human sense. The reward model are massive neural nets and they have cracks.</p>
<p>You could get this non sensical answers and add them to your dataset with very low ranking to make it learn that this is not a good joke but this is an infinite process, there will always be more adversarial examples to be found by the neural net.</p>
<p>What to do?
Just train the RL for some time and crop the training, don't go too far so you avoid the adversarial example generation.</p>
<p><strong>This is true for RLHF, not RL</strong> .
Plain RL can be run indefinitely because you can't really game the answer, you are looking for a specific answer and the neural net will find ways, even non standard ways, to find that answer but it's totally verifiable. RLHF is different, and a reward function can be gamed, so RLHF can't be run forever while plain RL yes.</p>
    
  </div>
</article>
      
        <article class="md-post md-post--excerpt">
  <header class="md-post__header">
    
      <nav class="md-post__authors md-typeset">
        
          <span class="md-author">
            <img src="https://cdn.sportsjobs.online/personal_profile_pic.jpg" alt="Franco Betteo">
          </span>
        
      </nav>
    
    <div class="md-post__meta md-meta">
      <ul class="md-meta__list">
        <li class="md-meta__item">
          <time datetime="2025-02-21 00:00:00+00:00">2025-02-21</time></li>
        
          <li class="md-meta__item">
            in
            
              <a href="category/ai/" class="md-meta__link">AI</a>, 
              <a href="category/machine-learning/" class="md-meta__link">Machine Learning</a></li>
        
        
          
          <li class="md-meta__item">
            
              2 min read
            
          </li>
        
      </ul>
      
    </div>
  </header>
  <div class="md-post__content md-typeset">
    <h2 id="e-commerce-image-similarity-via-visual-embeddings"><a class="toclink" href="2025/02/21/image-similarity-ecommerce/">E-commerce Image Similarity via Visual Embeddings</a></h2>
<p>How I implemented an API to retrieve similar images from an E-commerce in 3 steps</p>
<p>In this post, we explore a system to identify similar articles solely based on e-commerce images. The approach is designed with two primary objectives in mind:</p>
<p>Do you want to see how it looks? Check <a href="https://huggingface.co/spaces/fbetteo/fashion_similarity">my portfolio example</a>!</p>
<h3 id="objectives"><a class="toclink" href="2025/02/21/image-similarity-ecommerce/#objectives">Objectives</a></h3>
<ol>
<li>
<p><strong>Catalog Similarity:</strong><br />
    Determine which items in the client's catalog resemble each other using only their photos.</p>
</li>
<li>
<p><strong>External Querying:</strong><br />
    Although not implemented in the current API, the plan is to eventually allow querying with external images. The envisioned workflow is to source images from suppliers, compare them with the client's catalog, and perform this embedding generation locally to keep the API lightweight.</p>
</li>
</ol>
<h3 id="proposed-solution"><a class="toclink" href="2025/02/21/image-similarity-ecommerce/#proposed-solution">Proposed Solution</a></h3>
<p>The core idea is to use a pretrained image model to extract embeddings from each photo. Once these embeddings are available, we can perform similarity searches to find items that are visually alike.</p>
<p>For our implementation, we experimented with both OpenAI's <strong>clip-ViT-B-32</strong> and <strong>ResNet</strong>. In general, both models produced comparable results, though we opted for CLIP in our main experiments.</p>
<h3 id="implementation-steps"><a class="toclink" href="2025/02/21/image-similarity-ecommerce/#implementation-steps">Implementation Steps</a></h3>
<h4 id="step-1-download-catalog-images"><a class="toclink" href="2025/02/21/image-similarity-ecommerce/#step-1-download-catalog-images">Step 1: Download Catalog Images</a></h4>
<ul>
<li><strong>Script:</strong> <code>embeddings/download_images/get_images.py</code></li>
<li><strong>Details:</strong><br />
    This script downloads all catalog images from the e-commerce using a <code>ThreadPool</code> to speed up the process.</li>
</ul>
<h4 id="step-2-generate-and-index-embeddings"><a class="toclink" href="2025/02/21/image-similarity-ecommerce/#step-2-generate-and-index-embeddings">Step 2: Generate and Index Embeddings</a></h4>
<ul>
<li><strong>Script:</strong> <code>embeddings/clip_faiss.py</code></li>
<li><strong>Details:</strong><br />
    The script generates embeddings for each photo and stores them in a Faiss index, which is saved under <code>embeddings/faiss_index/</code>.<br />
<strong>Note:</strong> Since the process is deterministic, a simple overwrite will not impact the results. Idempotent as they call it.</li>
</ul>
<p>Additional notebooks are available to illustrate the process, check results, and experiment with alternative models and tests.</p>
<h4 id="step-3-query-the-faiss-index"><a class="toclink" href="2025/02/21/image-similarity-ecommerce/#step-3-query-the-faiss-index">Step 3: Query the Faiss Index</a></h4>
<ul>
<li><strong>API Functionality:</strong><br />
    The Faiss index is already built. We expose an API endpoint where you can pass an <code>article_id</code> (used during the embedding generation) and retrieve the most similar items.<br />
<strong>Validation:</strong><br />
    As a sanity check, querying an article should return itself as the top match with a distance of 0.</li>
</ul>
<h3 id="conclusion"><a class="toclink" href="2025/02/21/image-similarity-ecommerce/#conclusion">Conclusion</a></h3>
<p>By leveraging pretrained image models and efficient similarity search with Faiss, this approach provides a scalable method for identifying visually similar items in an e-commerce catalog. This system not only improves internal catalog management but also sets the groundwork for integrating external image queries in the future.</p>
    
  </div>
</article>
      
        <article class="md-post md-post--excerpt">
  <header class="md-post__header">
    
      <nav class="md-post__authors md-typeset">
        
          <span class="md-author">
            <img src="https://cdn.sportsjobs.online/personal_profile_pic.jpg" alt="Franco Betteo">
          </span>
        
      </nav>
    
    <div class="md-post__meta md-meta">
      <ul class="md-meta__list">
        <li class="md-meta__item">
          <time datetime="2025-01-28 00:00:00+00:00">2025-01-28</time></li>
        
          <li class="md-meta__item">
            in
            
              <a href="category/ai/" class="md-meta__link">AI</a>, 
              <a href="category/machine-learning/" class="md-meta__link">Machine Learning</a></li>
        
        
          
          <li class="md-meta__item">
            
              2 min read
            
          </li>
        
      </ul>
      
    </div>
  </header>
  <div class="md-post__content md-typeset">
    <h2 id="kullback-leibler-divergence"><a class="toclink" href="2025/01/28/kullback-leibler-divergence/">Kullback-Leibler divergence</a></h2>
<p>To understand KL divergence we need to first understand <a href="https://fbetteo.github.io/blog/writing/2025/01/06/entropy/">Entropy</a>. The most important thing to have in mind though is that entropy can be thought as a measure of "information", but what I like the most, as a measure of <em>expected surprise</em> that one gets for every observed value of the distribution.</p>
<p>For a highly dense distribution, you will almost sure get a value from the dense region and the expected surprise will be really low (but you are highly surprised when you see a value off that region!)</p>
<h4 id="relative-entropy"><a class="toclink" href="2025/01/28/kullback-leibler-divergence/#relative-entropy">Relative entropy</a></h4>
<p>How this relates to KL? Well, Kullback-Leibler is a divergence but is also called <em>relative entropy</em>. This means, how that measure of entropy differs between two distributions. I find that easier to grasp.</p>
<p>Usually we have a true distribution <span class="arithmatex">\(p(x)\)</span> and an estimated distribution <span class="arithmatex">\(q(x)\)</span> that we use to approximate <span class="arithmatex">\(p(x)\)</span>. KL divergence can help us understand how good it does the  job.</p>
<p>If entropy is: </p>
<p><span class="arithmatex">\(H[x] = - \sum_x p(x) \ln p(x)\)</span><br />
(originally <span class="arithmatex">\(\log_2\)</span> but <span class="arithmatex">\(\ln\)</span> works too and it's used everywhere )</p>
<div class="arithmatex">\[KL(p||q) = - \int{p(x) \ln q(x)dx} - (-\int{p(x) \ln p(x)dx})\]</div>
<div class="arithmatex">\[ = - \int{p(x) \ln \frac{q(x)}{p(x)}dx}\]</div>
<p>The first row is clear, is just the difference in entropies. 
This is relative entropy between p(x) and q(x).</p>
<p><strong>Important</strong>: KL divergence is not symmetrical. <span class="arithmatex">\(KL(p||q) \neq KL(q||p)\)</span>
So, KL is not a metric of distance (but can be thought as if). It's actually a divergence.</p>
<h4 id="why-its-not-symmetrical"><a class="toclink" href="2025/01/28/kullback-leibler-divergence/#why-its-not-symmetrical">Why it's not symmetrical?</a></h4>
<p>I think about it this way. This is a dissimilarity between one distribution and how we approximate it. Think about two totally different distributions (awful approximations):</p>
<ul>
<li>one highly centered around one specific value </li>
<li>the other with a uniform-ish shape, highly dispersed.</li>
</ul>
<p>The difference in "surprise" you get from both ways approximation is not the same.</p>
<p>If you are approximating the highly dense distribution with the uniform one, you are approximating it with a distribution that surprises you  in general <span class="arithmatex">\(\ln q(x)\)</span>, let's say <em>moderately high</em> everywhere, even for the specific dense region.</p>
<p>But the other way, if you approximate the dispersed distribution with the dense one, you are using a distribution with high surprise in most of the region of the dispersed distribution and really low surprise in one specific value.</p>
<p>This term <span class="arithmatex">\(\int{p(x) \ln q(x)dx}\)</span> behaves differently in both scenarios and there is no guarantee or need that they should match.</p>
<h5 id="references"><a class="toclink" href="2025/01/28/kullback-leibler-divergence/#references">References</a></h5>
<p><a href="https://www.bishopbook.com/">Deep Learning, Bishop</a><br />
<a href="https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence">Wikipedia</a></p>
    
  </div>
</article>
      
        <article class="md-post md-post--excerpt">
  <header class="md-post__header">
    
      <nav class="md-post__authors md-typeset">
        
          <span class="md-author">
            <img src="https://cdn.sportsjobs.online/personal_profile_pic.jpg" alt="Franco Betteo">
          </span>
        
      </nav>
    
    <div class="md-post__meta md-meta">
      <ul class="md-meta__list">
        <li class="md-meta__item">
          <time datetime="2025-01-28 00:00:00+00:00">2025-01-28</time></li>
        
          <li class="md-meta__item">
            in
            
              <a href="category/ai/" class="md-meta__link">AI</a>, 
              <a href="category/machine-learning/" class="md-meta__link">Machine Learning</a></li>
        
        
          
          <li class="md-meta__item">
            
              1 min read
            
          </li>
        
      </ul>
      
    </div>
  </header>
  <div class="md-post__content md-typeset">
    <h2 id="mutual-information"><a class="toclink" href="2025/01/28/mutual-information/">Mutual Information</a></h2>
<blockquote>
<p>When two variables <span class="arithmatex">\(x\)</span> and <span class="arithmatex">\(y\)</span> are independent, their joint distribution will factorize into the product of their marginals <span class="arithmatex">\(p(x,y) = p(x)p(y)\)</span>. If the variables are not independent, we can gain some idea of whether they are "close" to being independent by considering the <a href="https://fbetteo.github.io/blog/writing/2025/01/28/kullback-leibler-divergence/">KL Divergence</a> between the joint distribution and the product of the marginals, given by:</p>
</blockquote>
<div class="arithmatex">\[I[x,y] = KL(p(x,y)||p(x)p(y))\]</div>
<div class="arithmatex">\[=  - \int \int p(x,y) \ln (\frac{p(x)p(y)}{p(x,y)}) \]</div>
<p>which is called the <em>mutual information</em> between <span class="arithmatex">\(x\)</span> and <span class="arithmatex">\(y\)</span>.</p>
<p>Thus, the mutual information represents the reduction in uncertainty about <span class="arithmatex">\(x\)</span> by virtue of being told the value of <span class="arithmatex">\(y\)</span> (or vice versa)</p>
<blockquote>
<p>From a Bayesian perspective, we can view <span class="arithmatex">\(p(x)\)</span> as the prior distribution for <span class="arithmatex">\(x\)</span> and <span class="arithmatex">\(p(x|y)\)</span> as the posterior distribution after we have observed new data <span class="arithmatex">\(y\)</span>. The mutual information therefore represents the reduction in uncertainty about <span class="arithmatex">\(x\)</span> as a consequence of the new observation <span class="arithmatex">\(y\)</span>.</p>
</blockquote>
    
  </div>
</article>
      
        <article class="md-post md-post--excerpt">
  <header class="md-post__header">
    
      <nav class="md-post__authors md-typeset">
        
          <span class="md-author">
            <img src="https://cdn.sportsjobs.online/personal_profile_pic.jpg" alt="Franco Betteo">
          </span>
        
      </nav>
    
    <div class="md-post__meta md-meta">
      <ul class="md-meta__list">
        <li class="md-meta__item">
          <time datetime="2025-01-26 00:00:00+00:00">2025-01-26</time></li>
        
          <li class="md-meta__item">
            in
            
              <a href="category/personal/" class="md-meta__link">Personal</a></li>
        
        
          
          <li class="md-meta__item">
            
              2 min read
            
          </li>
        
      </ul>
      
    </div>
  </header>
  <div class="md-post__content md-typeset">
    <h2 id="obisidan-workflow"><a class="toclink" href="2025/01/26/obsidian-workflow/">Obisidan Workflow</a></h2>
<p>This is my first personal order for <a href="https://obsidian.md/">Obsidian</a> with some actual rules and not improvising everything.</p>
<p>I've read <a href="https://stephango.com/vault">Kepano's way</a> and <a href="https://www.youtube.com/watch?v=hSTy_BInQs8.">this other guy</a> I think both are useful in some way but I' sticking closer to Kepano. Not copying as he has a lots of templates with structured information in the YAML as he seems to create a lot of lists and rankings. Currently I'm using Obsidian a lot for technical notes, daily notes, paper annotation but also some listing as books I've read, movies, etc. It's a mix and I'm not sure I know what info to put for everything that is not a book, or game. Like, notes from some technical topic I can put the area or the author but there is no ranking.</p>
<p>Also, I like folders and he hates them.
I'll do the following.</p>
<ul>
<li>Have folders by general topic to order the notes (book, movies,  companies I work for, projects). Notes will be written where they belong the most. For general technical topics (such as Xgboost, I might create a data science or technical folder with all there. I'll put reasonable tags, many notes in different folders might share tags)</li>
<li>Notes across folders might share useful information. Maybe I have some deployment technical note on a company that could apply for another project, or even I'll want to find it without remembering where I applied it, so, I'll also add <strong>tags</strong> so I can see everything together using <a href="https://blacksmithgu.github.io/obsidian-dataview/">dataview</a></li>
<li>I'll try to add relevant information usable by dataview in some cases, such as Author for books, or technical notes.</li>
<li>I'll have a [[tags]] folder with relevant tags with queries from dataview so I can have stuff organized.</li>
<li>I'll keep tags in english for technical stuff but for books, series, etc where is more natural to remember in spanish (I'm from Argentina) and won't be shared probably I'll ues them in spanish (such as "policial", "novela", etc which are words that I never use in english). </li>
</ul>
    
  </div>
</article>
      
        <article class="md-post md-post--excerpt">
  <header class="md-post__header">
    
      <nav class="md-post__authors md-typeset">
        
          <span class="md-author">
            <img src="https://cdn.sportsjobs.online/personal_profile_pic.jpg" alt="Franco Betteo">
          </span>
        
      </nav>
    
    <div class="md-post__meta md-meta">
      <ul class="md-meta__list">
        <li class="md-meta__item">
          <time datetime="2025-01-06 00:00:00+00:00">2025-01-06</time></li>
        
          <li class="md-meta__item">
            in
            
              <a href="category/ai/" class="md-meta__link">AI</a>, 
              <a href="category/machine-learning/" class="md-meta__link">Machine Learning</a></li>
        
        
          
          <li class="md-meta__item">
            
              2 min read
            
          </li>
        
      </ul>
      
    </div>
  </header>
  <div class="md-post__content md-typeset">
    <h2 id="entropy-and-information"><a class="toclink" href="2025/01/06/entropy/">Entropy and information</a></h2>
<p>Term that comes from information theory.
The most intuitive way to think about <em>information</em> of a variable is to relate to the <strong>degree of surprise</strong> on learning the value of the variable X.<br />
This definition was mentioned both in <a href="https://www.bishopbook.com/">Deep Learning, Bishop</a> and in <a href="https://worrydream.com/refs/Hamming_1997_-_The_Art_of_Doing_Science_and_Engineering.pdf">Hamming</a>, and the former is the text I was just reading before starting this note.</p>
<p>So, having a variable X with <code>p(x)</code>, what's <code>h(x)</code> , the information of observing X? This quantity <code>h(x)</code> should be a monotonic function of <code>p(x)</code>. Remember, information is tied to the surprise, observing an almost sure event, high p(x), reveals less information than an unexpected event,low p(x). In the extreme, observing a known value, gives 0 information.</p>
<p>How to define the information mathematically comes (in some way intuitively) by the definition that, observing two independent variables <code>x</code> and <code>y</code> should provide an amount of information equal to the sum of the individual informations.</p>
<div class="arithmatex">\[h(x,y) = h(x) + h(y)\]</div>
<p>We know that for independent events <span class="arithmatex">\(p(x, y) = p(x)*p(y)\)</span>  </p>
<p>It can be derived then that  </p>
<div class="arithmatex">\[h(x) = - \log_2 p(x)\]</div>
<p>The log provides the summation part coming from a multiplication. The negative ensure 0 or positive values. Remember that we are taking the log of a value between 0 and 1.</p>
<p>Now, there is another important term, <strong>entropy</strong>.
It summarizes the average amount of information that is transmitted <em>if a sender wishes to transmit the value of a random variable to a receiver</em>. 
The entropy is the expectation of the information, with respect to the distribution p(x).  </p>
<div class="arithmatex">\[H[x] = - \sum_x p(x) \log_2 p(x)\]</div>
<p>For p(x) = 0, where the log would bring problem, we consider <span class="arithmatex">\(p(x) \log p(x)\)</span>=0</p>
<p>Classical information theory uses <span class="arithmatex">\(\log_2\)</span> because it relates to bits and the amount of bits required to send a message but the book changes to <span class="arithmatex">\(\ln\)</span> because is much more used in ML and it's just a different unit to measure entropy. </p>
    
  </div>
</article>
      
      
        
          



<nav class="md-pagination">
  <span class="md-pagination__current">1</span> <a class="md-pagination__link" href="page/2/">2</a> <a class="md-pagination__link" href="page/3/">3</a> <span class="md-pagination__dots">..</span> <a class="md-pagination__link" href="page/5/">5</a>
</nav>
        
      
    </div>
  </div>

          
  <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var labels=set.querySelector(".tabbed-labels");for(var tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script>

<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
    
      
      <nav class="md-footer__inner md-grid" aria-label="Footer" >
        
          
          <a href="../services/" class="md-footer__link md-footer__link--prev" aria-label="Previous: Services">
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
            </div>
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Previous
              </span>
              <div class="md-ellipsis">
                Services
              </div>
            </div>
          </a>
        
        
          
          <a href="category/ai/" class="md-footer__link md-footer__link--next" aria-label="Next: AI">
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Next
              </span>
              <div class="md-ellipsis">
                AI
              </div>
            </div>
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11z"/></svg>
            </div>
          </a>
        
      </nav>
    
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      Copyright &copy; 2025 Franco Betteo
    </div>
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
        <div class="md-social">
  
    
    
    
    
      
      
    
    <a href="https://x.com/franbetteo" target="_blank" rel="noopener" title="x.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.7.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253"/></svg>
    </a>
  
    
    
    
    
      
      
    
    <a href="https://github.com/fbetteo" target="_blank" rel="noopener" title="github.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.7.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
      <div class="md-progress" data-md-component="progress" role="progressbar"></div>
    
    
    <script id="__config" type="application/json">{"base": "..", "features": ["announce.dismiss", "content.action.edit", "content.action.view", "content.code.annotate", "content.code.copy", "content.code.select", "content.tabs.link", "content.tooltips", "header.autohide", "navigation.expand", "navigation.footer", "navigation.indexes", "navigation.instant", "navigation.instant.prefetch", "navigation.instant.progress", "navigation.prune", "navigation.sections", "navigation.tabs", "navigation.tabs.sticky", "navigation.top", "navigation.tracking", "search.highlight", "search.share", "search.suggest", "toc.follow"], "search": "../assets/javascripts/workers/search.6ce7567c.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../assets/javascripts/bundle.88dd0f4e.min.js"></script>
      
        <script src="../javascripts/mathjax.js"></script>
      
        <script src="https://unpkg.com/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>