
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
        <link rel="prev" href="../../../interests/">
      
      
        <link rel="next" href="../../category/personal/">
      
      
      <link rel="icon" href="../../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.5.46">
    
    
      
        <title>My words, sometimes technical, sometimes not - Franco Betteo</title>
      
    
    
      <link rel="stylesheet" href="../../../assets/stylesheets/main.6f8fc17f.min.css">
      
        
        <link rel="stylesheet" href="../../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CFira+Code:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Fira Code"}</style>
      
    
    
      <link rel="stylesheet" href="../../../stylesheets/extra.css">
    
    <script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="youtube" data-md-color-primary="indigo" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#my-words-sometimes-technical-sometimes-not" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow md-header--lifted" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../.." title="Franco Betteo" class="md-header__button md-logo" aria-label="Franco Betteo" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Franco Betteo
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              My words, sometimes technical, sometimes not
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="youtube" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-hidden="true"  type="radio" name="__palette" id="__palette_0">
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
    
  </nav>
  
    
      
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../.." class="md-tabs__link">
          
  
    
  
  Home

        </a>
      </li>
    
  

      
        
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="../../" class="md-tabs__link">
          
  
    
  
  Writing

        </a>
      </li>
    
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="https://sportsjobs.online" class="md-tabs__link">
        
  
    
  
  Job Board

      </a>
    </li>
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../nba_salaries/" class="md-tabs__link">
          
  
    
  
  NBA salaries legacy model

        </a>
      </li>
    
  

      
    </ul>
  </div>
</nav>
    
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../.." title="Franco Betteo" class="md-nav__button md-logo" aria-label="Franco Betteo" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    Franco Betteo
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
    
    
      
      
        
      
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../.." class="md-nav__link">
      
  
  <span class="md-ellipsis">
    Home
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
      
        
          
        
      
        
      
        
      
    
    
      
        
        
      
      
        
      
    
    
      
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" checked>
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    Writing
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_2" id="__nav_2_label" tabindex="">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            Writing
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
      
        
          
          
        
      
    
    
      
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2_2" >
        
          
          <label class="md-nav__link" for="__nav_2_2" id="__nav_2_2_label" tabindex="">
            
  
  <span class="md-ellipsis">
    Archive
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_2">
            <span class="md-nav__icon md-icon"></span>
            Archive
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../archive/2024/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    2024
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../archive/2022/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    2022
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../archive/2021/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    2021
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../archive/2020/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    2020
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../archive/2019/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    2019
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../archive/2018/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    2018
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
      
        
          
          
        
      
    
    
      
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2_3" >
        
          
          <label class="md-nav__link" for="__nav_2_3" id="__nav_2_3_label" tabindex="">
            
  
  <span class="md-ellipsis">
    Categories
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_3">
            <span class="md-nav__icon md-icon"></span>
            Categories
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../category/personal/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Personal
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../category/python/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Python
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../category/r/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    R
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../category/algebra/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    algebra
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../category/blog/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    blog
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../category/estadistica/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    estadistica
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../category/machine-learning/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    machine learning
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../category/matematica/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    matematica
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../category/statistics/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    statistics
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="https://sportsjobs.online" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Job Board
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
          
        
      
    
    
      
      
        
      
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../../nba_salaries/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    NBA salaries legacy model
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#non-negative-matrix-factorization" class="md-nav__link">
    <span class="md-ellipsis">
      Non Negative Matrix Factorization
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#distribucion-dirichlet-como-prior-de-multinomial" class="md-nav__link">
    <span class="md-ellipsis">
      Distribucion Dirichlet como prior de Multinomial
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#de-r-a-python-1" class="md-nav__link">
    <span class="md-ellipsis">
      De R a Python 1
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#anova" class="md-nav__link">
    <span class="md-ellipsis">
      ANOVA
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#distribucion-gamma" class="md-nav__link">
    <span class="md-ellipsis">
      Distribucion Gamma
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#proceso-poisson-y-distribucion-exponencial" class="md-nav__link">
    <span class="md-ellipsis">
      Proceso Poisson y distribucion exponencial
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#distintas-distancias" class="md-nav__link">
    <span class="md-ellipsis">
      Distintas Distancias
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#maxima-verosimilitud-y-estimacion-bayesiana" class="md-nav__link">
    <span class="md-ellipsis">
      Maxima Verosimilitud y estimacion bayesiana
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#teorema-central-del-limite" class="md-nav__link">
    <span class="md-ellipsis">
      Teorema Central del Limite
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#metodos-de-resampleo-islr-capitulo-5" class="md-nav__link">
    <span class="md-ellipsis">
      Metodos de Resampleo - ISLR Capitulo 5
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
  <div class="md-content" data-md-component="content">
    <div class="md-content__inner">
      <header class="md-typeset">
        <h1 id="my-words-sometimes-technical-sometimes-not">My words, sometimes technical, sometimes not<a class="headerlink" href="#my-words-sometimes-technical-sometimes-not" title="Permanent link">&para;</a></h1>
      </header>
      
        <article class="md-post md-post--excerpt">
  <header class="md-post__header">
    
      <nav class="md-post__authors md-typeset">
        
          <span class="md-author">
            <img src="https://media.licdn.com/dms/image/v2/D4D03AQGGiT9NDiLy7Q/profile-displayphoto-shrink_200_200/profile-displayphoto-shrink_200_200/0/1681511830071?e=1738195200&v=beta&t=Nd1WNLQTxHfCe7dT9BBaQYgaYtEHFCOPpntpImC4Lz8" alt="Franco Betteo">
          </span>
        
      </nav>
    
    <div class="md-post__meta md-meta">
      <ul class="md-meta__list">
        <li class="md-meta__item">
          <time datetime="2020-10-06 00:00:00+00:00">2020-10-06</time></li>
        
          <li class="md-meta__item">
            in
            
              <a href="../../category/estadistica/" class="md-meta__link">estadistica</a>, 
              <a href="../../category/r/" class="md-meta__link">R</a></li>
        
        
          
          <li class="md-meta__item">
            
              1 min read
            
          </li>
        
      </ul>
      
    </div>
  </header>
  <div class="md-post__content md-typeset">
    <h2 id="non-negative-matrix-factorization"><a class="toclink" href="../../2020/10/06/non-negative-matrix-factorization.en-us/">Non Negative Matrix Factorization</a></h2>
<p>Please follow this <a href="/flexdashboard/nnmf_nba.html">link</a><br />
It was made with Flexboard (a package to do dashboards in R) so I think it's only visualized correctly in laptops/pc because of the layout.</p>
    
  </div>
</article>
      
        <article class="md-post md-post--excerpt">
  <header class="md-post__header">
    
      <nav class="md-post__authors md-typeset">
        
          <span class="md-author">
            <img src="https://media.licdn.com/dms/image/v2/D4D03AQGGiT9NDiLy7Q/profile-displayphoto-shrink_200_200/profile-displayphoto-shrink_200_200/0/1681511830071?e=1738195200&v=beta&t=Nd1WNLQTxHfCe7dT9BBaQYgaYtEHFCOPpntpImC4Lz8" alt="Franco Betteo">
          </span>
        
      </nav>
    
    <div class="md-post__meta md-meta">
      <ul class="md-meta__list">
        <li class="md-meta__item">
          <time datetime="2020-07-18 00:00:00+00:00">2020-07-18</time></li>
        
          <li class="md-meta__item">
            in
            
              <a href="../../category/estadistica/" class="md-meta__link">estadistica</a>, 
              <a href="../../category/r/" class="md-meta__link">R</a></li>
        
        
          
          <li class="md-meta__item">
            
              4 min read
            
          </li>
        
      </ul>
      
    </div>
  </header>
  <div class="md-post__content md-typeset">
    <h2 id="distribucion-dirichlet-como-prior-de-multinomial"><a class="toclink" href="../../2020/07/18/disitrbucion-dirichlet-como-prior-de-mulitnomial/">Distribucion Dirichlet como prior de Multinomial</a></h2>
<p>Basado en:<br />
<a href="http://www.mas.ncl.ac.uk/~nmf16/teaching/mas3301/week6.pdf">http://www.mas.ncl.ac.uk/~nmf16/teaching/mas3301/week6.pdf</a><br />
<a href="http://www.inf.ed.ac.uk/teaching/courses/mlpr/assignments/multinomial.pdf">http://www.inf.ed.ac.uk/teaching/courses/mlpr/assignments/multinomial.pdf</a></p>
<p>La distribución Dirichlet es una distribución multivariada para un conjunto de cantidades <span class="arithmatex">\(\theta_i,...,\theta_m\)</span> donde <span class="arithmatex">\(\theta_i &gt;= 0\)</span> y <span class="arithmatex">\(\sum_{i=1}^m \theta_i = 1\)</span>. Esto la hace una candidata útil para modelar un conjunto de probabilidades de una partición (un un conjunto de eventos mutuamente excluyentes). Es decir, un grupo de probabilides de eventos excluyentes, que sumen 1.<br />
Podemos remplazar los <span class="arithmatex">\(\theta\)</span> por <span class="arithmatex">\(p\)</span> si es más claro que hablamos de probabilidades luego.</p>
<p>La PDF es:</p>
<div class="arithmatex">\[f(\theta_i,...,\theta_m; \alpha_i.., \alpha_m) =   \frac{\Gamma(\sum_i{\alpha_i})}{\prod_{i=1}^m \Gamma(\alpha_i)}\prod_{i = 1}^m \theta_i^{(\alpha_1-1)}\]</div>
<p>Donde la función <span class="arithmatex">\(\Gamma\)</span> es <span class="arithmatex">\(\Gamma(\alpha) = (\alpha -1)!\)</span>. Para más detalles ver <a href="https://en.wikipedia.org/wiki/Gamma_function">acá</a>.<br />
Los <span class="arithmatex">\(\alpha_i\)</span> son parámetros de la distribución y deben ser mayores a 0.<br />
Cuando m = 2, obtenemos una función <span class="arithmatex">\(beta(\alpha_1, \alpha_2)\)</span> como caso particular de la Dirichlet.</p>
<h4 id="dirichtlet-en-inferencia-bayesiana"><a class="toclink" href="../../2020/07/18/disitrbucion-dirichlet-como-prior-de-mulitnomial/#dirichtlet-en-inferencia-bayesiana">Dirichtlet en Inferencia Bayesiana.</a></h4>
<p>De la misma manera que la distribución Beta suele usarse como prior de la Distribución Binomial ya que es una distribución conjugada para ese caso, la distribución Dirichlet suele usarse para distribuciones <strong>Multinomiales</strong>, es decir donde hay más de 2 categorías posibles (más de 2 <span class="arithmatex">\(p_i\)</span>). También es distribución conjugada. Es simplemente la versión multinomial de la beta.  </p>
<p>La distribución multinomial es la siguiente:</p>
<div class="arithmatex">\[\frac{n!}{\prod_{i = 1}^m x_i!}\prod_{i=1}^m p_i^{x_i}\]</div>
<p>Cuando m = 2, es la distribución binomial.</p>
<p>Si tuvieramos un experimento que se puede modelar como una multinomial y queremos estimar los <span class="arithmatex">\(p_i\)</span> podemos utilizar los estimadores de máxima verosimilitud (frecuentista) o ir por el camino de bayesiano donde comenzamos con un prior para cada p, que modelaremos con la Dirichlet. El prior de cada <span class="arithmatex">\(p_i\)</span> va a ser definido con la elección de los <span class="arithmatex">\(\alpha\)</span>.</p>
<p>Yendo por el camino bayesiano vamos a tener nuestra distribución posterior:
$$ P(p | x) \propto P(x|p) * P(p)$$
donde <span class="arithmatex">\(P(x|p)\)</span> no es otra cosa que la distribución multinomial y <span class="arithmatex">\(P(p)\)</span> es nuestro prior de <span class="arithmatex">\(p\)</span> dado por la Dirichlet. Omitimos el denominador que es normalizador ya que es una constante.</p>
<p>Multiplicamos entonces la PDF multinomial por la Dirichlet y obtenemos:</p>
<p><em>Importante notar que efectivamente cambiamos <span class="arithmatex">\(\theta\)</span> por <span class="arithmatex">\(p\)</span> en la Dirichlet para que sea consistente con la multinomial.</em></p>
<div class="arithmatex">\[\frac{n!}{\prod_{i = 1}^m x_i!}\prod_{i=1}^m p_i^{x_i} * \frac{\Gamma(\sum_i{\alpha_i})}{\prod_{i=1}^m \Gamma(\alpha_i)}\prod_{i = 1}^m p_i^{(\alpha_1-1)} \\ \propto \prod_i p_i^{\alpha_i + x_i -1}\]</div>
<p>Para la proporcionalidad, quitamos todo lo que es factorial (y <span class="arithmatex">\(\Gamma\)</span>) ya que es constante y combinamos los exponentes de base <span class="arithmatex">\(p_i\)</span>.</p>
<p>Vemos entonces que nuestra distribución posterior es propocional a ese término, que si vemos, es una Dirichlet para la cual nos falta el término constante! Por eso se dice que es una prior conjugada, ya que la posterior es de la misma familia que la prior (con otros valores claro.)<br />
Es entonces una Dirichlet con parámetros <span class="arithmatex">\(\alpha_i + x_i\)</span> y podemos completar el término faltante obteniendo: 
$$ \frac{\Gamma(\sum_i{\alpha_i + x_i})}{\prod_{i=1}^m \Gamma(\alpha_i + x_i)}\prod_{i=1}^m p_i^{(\alpha_i + x_i-1)}$$</p>
<p>He ahí nuestra distribución posterior para los valores de <span class="arithmatex">\(p\)</span> de la multinomial.</p>
<p>Para calcular rápidamente la esperanza de cada <span class="arithmatex">\(p_i\)</span> hacemos simplemente:
<span class="arithmatex">\(<span class="arithmatex">\(E(p_i) = \frac{\alpha_i + x_i}{\sum (\alpha_i +  x_i)}\)</span>\)</span></p>
<p>Si obtenemos nueva información podemos repetir el proceso, pero nuestra nueva prior debería ser la posterior previamente calculada. Y así vamos agregando información a medida que se recolecta y actualizando nuestra inferencia acerca de <span class="arithmatex">\(p_i\)</span></p>
<p><strong>Aclaración</strong>: La proporción de cada <span class="arithmatex">\(\alpha_i\)</span> iniciales en la Dirichlet prior sobre la suma de todos los <span class="arithmatex">\(\alpha_i\)</span> es nuestro prior de <span class="arithmatex">\(p_i\)</span>. A mayores valores absolutos, mayor peso al prior respecto a los datos, ya que nuestro nuevo <span class="arithmatex">\(p_i\)</span> es función del <span class="arithmatex">\(\alpha_i\)</span> y <span class="arithmatex">\(x_i\)</span>. Revisar bien como ajustar los <span class="arithmatex">\(alpha\)</span> según la magnitud de <span class="arithmatex">\(x\)</span>, si es que hay que hacerlo.</p>
<h4 id="ejemplo"><a class="toclink" href="../../2020/07/18/disitrbucion-dirichlet-como-prior-de-mulitnomial/#ejemplo">Ejemplo</a></h4>
<p>Queremos modelar la compra de remeras de basquet en una tienda. Entra un cliente al azar y tiene determinadas probabilidades de comprar una remera de los Lakers, una de los Celtics, una de San Antonio o cualquier otro equipo.  </p>
<p>En un primer momento no sabemos las proporciones y empezamos con unos priors <span class="arithmatex">\(\alpha_1 : \alpha_4 = [8,6,4,2]\)</span> que corresponde a 40%, 30%, 20% y 10% respectivamente.</p>
<p>Recolectamos los datos de 100 clientes y vemos que las ventas fueron las siguientes:<br />
Lakers : 45<br />
Celtics: 22<br />
Spurs: 27<br />
Otros: 6  </p>
<p>Calculando rapidamente con la fórmula de la Esperanza las probabildades que se derivan de nuestra posterior obtenemos:</p>
<p>Lakers = 0.442<br />
Celtic = 0.233<br />
Spurs  = 0.258<br />
Otro   = 0.067  </p>
<p>Para ser más prolijos habría que agregar la varianza de cada <span class="arithmatex">\(p\)</span>. A agregar en un futuro..</p>
<p>Si hubieramos calculado los p  de máxima verosimilitud no sería más que la proporción de cada equipo en los datos, sin tener en cuenta nuestro prior. Vemos que acá están obviamente cercanos a la proporción en los datos pero se inclinan hacia el prior. Recordar que el peso de los priors va a verse afectar por los <span class="arithmatex">\(\alpha\)</span> elegidos y por la cantidad de datos recolectados.</p>
<p>En ML es bastante útil para el caso donde una nueva categoría aparece en el test set. Si no fue vista en el training le va a dar probabilidad 0 mientras que con un prior podemos salvar ese problema.<br />
En NLP es bastante habitual usar la distribución Dirichlet como prior. Investigar por ese lado.</p>
    
  </div>
</article>
      
        <article class="md-post md-post--excerpt">
  <header class="md-post__header">
    
      <nav class="md-post__authors md-typeset">
        
          <span class="md-author">
            <img src="https://media.licdn.com/dms/image/v2/D4D03AQGGiT9NDiLy7Q/profile-displayphoto-shrink_200_200/profile-displayphoto-shrink_200_200/0/1681511830071?e=1738195200&v=beta&t=Nd1WNLQTxHfCe7dT9BBaQYgaYtEHFCOPpntpImC4Lz8" alt="Franco Betteo">
          </span>
        
      </nav>
    
    <div class="md-post__meta md-meta">
      <ul class="md-meta__list">
        <li class="md-meta__item">
          <time datetime="2020-07-11 00:00:00+00:00">2020-07-11</time></li>
        
          <li class="md-meta__item">
            in
            
              <a href="../../category/r/" class="md-meta__link">R</a>, 
              <a href="../../category/python/" class="md-meta__link">Python</a></li>
        
        
          
          <li class="md-meta__item">
            
              3 min read
            
          </li>
        
      </ul>
      
    </div>
  </header>
  <div class="md-post__content md-typeset">
    <h2 id="de-r-a-python-1"><a class="toclink" href="../../2020/07/11/de-r-a-python-1/">De R a Python 1</a></h2>
<p>Serie que documenta cuestiones prácticas que voy descubriendo a medida que empiezo a incursionar en Python un poco más enserio.
Son más que nada recordatorios para el futuro de mecánicas que hoy entiendo, pero me voy a olvidar.</p>
<p>Muchos de los objetos no van a tener relación entre sí o no se puede correr el código directo 
ya que son copy/paste random de scripts.</p>
<h4 id="usar-objetos-de-otros-scripts"><a class="toclink" href="../../2020/07/11/de-r-a-python-1/#usar-objetos-de-otros-scripts">Usar objetos de otros scripts</a></h4>
<p>Si uno genera modelos, dataframes, etc en otro script por prolijidad y quiere utilizarlos en 
el principal (o cualquiera en realidad) lo aconsejable es exportarlo como objeto pickle (algo 
asi como los RDS en R.)</p>
<div class="language-r highlight"><pre><span></span><code><span id="__span-60-1"><a id="__codelineno-60-1" name="__codelineno-60-1" href="#__codelineno-60-1"></a><span class="nf">library</span><span class="p">(</span><span class="n">reticulate</span><span class="p">)</span>
</span></code></pre></div>
<div class="language-python highlight"><pre><span></span><code><span id="__span-61-1"><a id="__codelineno-61-1" name="__codelineno-61-1" href="#__codelineno-61-1"></a><span class="kn">import</span> <span class="nn">pickle</span>
</span><span id="__span-61-2"><a id="__codelineno-61-2" name="__codelineno-61-2" href="#__codelineno-61-2"></a><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
</span><span id="__span-61-3"><a id="__codelineno-61-3" name="__codelineno-61-3" href="#__codelineno-61-3"></a>
</span><span id="__span-61-4"><a id="__codelineno-61-4" name="__codelineno-61-4" href="#__codelineno-61-4"></a><span class="c1"># exportar. Objeto, archivo, permisos</span>
</span><span id="__span-61-5"><a id="__codelineno-61-5" name="__codelineno-61-5" href="#__codelineno-61-5"></a><span class="n">pickle</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">OBJETO</span><span class="p">,</span> <span class="nb">open</span><span class="p">(</span><span class="s2">&quot;working/qualifying.p&quot;</span><span class="p">,</span> <span class="s2">&quot;wb&quot;</span><span class="p">))</span>
</span><span id="__span-61-6"><a id="__codelineno-61-6" name="__codelineno-61-6" href="#__codelineno-61-6"></a>
</span><span id="__span-61-7"><a id="__codelineno-61-7" name="__codelineno-61-7" href="#__codelineno-61-7"></a><span class="c1"># importar</span>
</span><span id="__span-61-8"><a id="__codelineno-61-8" name="__codelineno-61-8" href="#__codelineno-61-8"></a><span class="n">leer</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_pickle</span><span class="p">(</span><span class="s1">&#39;archivo.p&#39;</span><span class="p">)</span>
</span></code></pre></div>
<h4 id="seleccionar-columas-de-dataframe-por-patron-en-el-nombre"><a class="toclink" href="../../2020/07/11/de-r-a-python-1/#seleccionar-columas-de-dataframe-por-patron-en-el-nombre">Seleccionar columas de dataframe por patrón en el nombre</a></h4>
<p>Para seleccionar columnas basados en si contiene determinado string en su nombre y no solo por nombre
completo o por índice. </p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-62-1"><a id="__codelineno-62-1" name="__codelineno-62-1" href="#__codelineno-62-1"></a><span class="c1"># Recordemos que iloc selecciona por índice</span>
</span><span id="__span-62-2"><a id="__codelineno-62-2" name="__codelineno-62-2" href="#__codelineno-62-2"></a><span class="c1"># Función Lambda  que convierte el indice de columna en strings y devuelve mascara (True/false)</span>
</span><span id="__span-62-3"><a id="__codelineno-62-3" name="__codelineno-62-3" href="#__codelineno-62-3"></a><span class="c1"># si contiene determinado patrón. Creo que puede ponerse cualquier Regex</span>
</span><span id="__span-62-4"><a id="__codelineno-62-4" name="__codelineno-62-4" href="#__codelineno-62-4"></a><span class="n">df2</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="k">lambda</span> <span class="n">df</span><span class="p">:</span><span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">contains</span><span class="p">(</span><span class="s1">&#39;_points&#39;</span><span class="p">)]</span> <span class="c1"># select column based on name</span>
</span></code></pre></div>
<p>Si queremos combinar esto con otras columnas con otro patrón no encontré manera más sencilla por
el momento que combinar por separado. Quizás es muy tedioso si son muchas.</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-63-1"><a id="__codelineno-63-1" name="__codelineno-63-1" href="#__codelineno-63-1"></a><span class="c1"># Notar que en point_vars le pasamos la máscara al listado de columnas nuevamente</span>
</span><span id="__span-63-2"><a id="__codelineno-63-2" name="__codelineno-63-2" href="#__codelineno-63-2"></a><span class="c1"># para quedarnos con el nombre real y poder sumarlo a las otras listas</span>
</span><span id="__span-63-3"><a id="__codelineno-63-3" name="__codelineno-63-3" href="#__codelineno-63-3"></a><span class="c1"># luego lo convertimos en lista porque el objeto es de tipo índice si no.</span>
</span><span id="__span-63-4"><a id="__codelineno-63-4" name="__codelineno-63-4" href="#__codelineno-63-4"></a><span class="n">target</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;position&#39;</span><span class="p">]</span>
</span><span id="__span-63-5"><a id="__codelineno-63-5" name="__codelineno-63-5" href="#__codelineno-63-5"></a><span class="n">qualy_vars</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;grid&#39;</span><span class="p">,</span> <span class="s1">&#39;dif_to_min_perc&#39;</span><span class="p">]</span>
</span><span id="__span-63-6"><a id="__codelineno-63-6" name="__codelineno-63-6" href="#__codelineno-63-6"></a><span class="n">point_vars</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">results</span><span class="o">.</span><span class="n">columns</span><span class="p">[</span><span class="n">results</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">contains</span><span class="p">(</span><span class="s1">&#39;_points&#39;</span><span class="p">)])</span>
</span><span id="__span-63-7"><a id="__codelineno-63-7" name="__codelineno-63-7" href="#__codelineno-63-7"></a>
</span><span id="__span-63-8"><a id="__codelineno-63-8" name="__codelineno-63-8" href="#__codelineno-63-8"></a><span class="n">vars_keep</span> <span class="o">=</span> <span class="n">target</span> <span class="o">+</span> <span class="n">qualy_vars</span> <span class="o">+</span> <span class="n">point_vars</span>
</span></code></pre></div>
<h4 id="juntar-dataframes-por-indice"><a class="toclink" href="../../2020/07/11/de-r-a-python-1/#juntar-dataframes-por-indice">Juntar dataframes por indice</a></h4>
<p>Los DF vienen por default con un índice. Si uno trabaja con una copia del DF original para generar nuevas columnas el índice se mantiene (si no lo reseteamos claro). También útil si se tienen varias tablas con mismo índice.</p>
<p>Esto permite juntar tablas sin tener que hacer un merge explicito por determinadas columnas si no
tenemos esos keys.</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-64-1"><a id="__codelineno-64-1" name="__codelineno-64-1" href="#__codelineno-64-1"></a><span class="n">results</span> <span class="o">=</span> <span class="n">results</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">driver_points_merge</span><span class="p">)</span> <span class="c1"># join by index (no need to merge with column)</span>
</span></code></pre></div>
<h4 id="ifelse"><a class="toclink" href="../../2020/07/11/de-r-a-python-1/#ifelse">Ifelse</a></h4>
<p>El equivalente de IFELSE en R para rapidamente crear una columna basado en otras, fila por fila.</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-65-1"><a id="__codelineno-65-1" name="__codelineno-65-1" href="#__codelineno-65-1"></a><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
</span><span id="__span-65-2"><a id="__codelineno-65-2" name="__codelineno-65-2" href="#__codelineno-65-2"></a><span class="c1">#               = condicion, valor si True, valor si False</span>
</span><span id="__span-65-3"><a id="__codelineno-65-3" name="__codelineno-65-3" href="#__codelineno-65-3"></a><span class="n">df</span><span class="p">[</span><span class="s1">&#39;position&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;position&#39;</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</span></code></pre></div>
<h4 id="dropear-columna-de-df"><a class="toclink" href="../../2020/07/11/de-r-a-python-1/#dropear-columna-de-df">Dropear columna de DF</a></h4>
<p>Útil para asegurar que sacan el target de las X...</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-66-1"><a id="__codelineno-66-1" name="__codelineno-66-1" href="#__codelineno-66-1"></a><span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="s2">&quot;position&quot;</span><span class="p">)</span>
</span></code></pre></div>
<h4 id="remplazar-determinado-valor-por-nan-u-otro"><a class="toclink" href="../../2020/07/11/de-r-a-python-1/#remplazar-determinado-valor-por-nan-u-otro">Remplazar determinado valor por NaN (u otro)</a></h4>
<p>df.replace</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-67-1"><a id="__codelineno-67-1" name="__codelineno-67-1" href="#__codelineno-67-1"></a><span class="n">qualifying</span> <span class="o">=</span> <span class="n">qualifying</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\\</span><span class="s1">N&#39;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">)</span>
</span></code></pre></div>
<h4 id="apply-aplicar-funciones-a-cada-fila-o-columna"><a class="toclink" href="../../2020/07/11/de-r-a-python-1/#apply-aplicar-funciones-a-cada-fila-o-columna">APPLY. Aplicar funciones a cada fila o columna</a></h4>
<p>Permite aplicar una función por fila o columna.La funcion se aplica sobre la serie (la fila o columna)
La serie mantiene los indices. Si usamos apply con axis = 1 que cada serie es una fila entera, 
podemos llamar a la celda correspondiente usando ['columna']</p>
<p>Apply es como las distintas versiones de apply de R y/o MAP del tidyverse cuando se aplica a un DF.</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-68-1"><a id="__codelineno-68-1" name="__codelineno-68-1" href="#__codelineno-68-1"></a><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
</span><span id="__span-68-2"><a id="__codelineno-68-2" name="__codelineno-68-2" href="#__codelineno-68-2"></a><span class="n">rectangles</span> <span class="o">=</span> <span class="p">[</span>
</span><span id="__span-68-3"><a id="__codelineno-68-3" name="__codelineno-68-3" href="#__codelineno-68-3"></a>    <span class="p">{</span> <span class="s1">&#39;height&#39;</span><span class="p">:</span> <span class="mi">40</span><span class="p">,</span> <span class="s1">&#39;width&#39;</span><span class="p">:</span> <span class="mi">10</span> <span class="p">},</span>
</span><span id="__span-68-4"><a id="__codelineno-68-4" name="__codelineno-68-4" href="#__codelineno-68-4"></a>    <span class="p">{</span> <span class="s1">&#39;height&#39;</span><span class="p">:</span> <span class="mi">20</span><span class="p">,</span> <span class="s1">&#39;width&#39;</span><span class="p">:</span> <span class="mi">9</span> <span class="p">},</span>
</span><span id="__span-68-5"><a id="__codelineno-68-5" name="__codelineno-68-5" href="#__codelineno-68-5"></a>    <span class="p">{</span> <span class="s1">&#39;height&#39;</span><span class="p">:</span> <span class="mf">3.4</span><span class="p">,</span> <span class="s1">&#39;width&#39;</span><span class="p">:</span> <span class="mi">4</span> <span class="p">}</span>
</span><span id="__span-68-6"><a id="__codelineno-68-6" name="__codelineno-68-6" href="#__codelineno-68-6"></a><span class="p">]</span>
</span><span id="__span-68-7"><a id="__codelineno-68-7" name="__codelineno-68-7" href="#__codelineno-68-7"></a>
</span><span id="__span-68-8"><a id="__codelineno-68-8" name="__codelineno-68-8" href="#__codelineno-68-8"></a><span class="n">rectangles_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">rectangles</span><span class="p">)</span>
</span><span id="__span-68-9"><a id="__codelineno-68-9" name="__codelineno-68-9" href="#__codelineno-68-9"></a><span class="n">rectangles_df</span>
</span><span id="__span-68-10"><a id="__codelineno-68-10" name="__codelineno-68-10" href="#__codelineno-68-10"></a>
</span><span id="__span-68-11"><a id="__codelineno-68-11" name="__codelineno-68-11" href="#__codelineno-68-11"></a>
</span><span id="__span-68-12"><a id="__codelineno-68-12" name="__codelineno-68-12" href="#__codelineno-68-12"></a><span class="c1"># Suma de todas las celdas (&quot;filas&quot;) por columna</span>
</span></code></pre></div>
<div class="language-text highlight"><pre><span></span><code><span id="__span-69-1"><a id="__codelineno-69-1" name="__codelineno-69-1" href="#__codelineno-69-1"></a>##    height  width
</span><span id="__span-69-2"><a id="__codelineno-69-2" name="__codelineno-69-2" href="#__codelineno-69-2"></a>## 0    40.0     10
</span><span id="__span-69-3"><a id="__codelineno-69-3" name="__codelineno-69-3" href="#__codelineno-69-3"></a>## 1    20.0      9
</span><span id="__span-69-4"><a id="__codelineno-69-4" name="__codelineno-69-4" href="#__codelineno-69-4"></a>## 2     3.4      4
</span></code></pre></div>
<div class="language-python highlight"><pre><span></span><code><span id="__span-70-1"><a id="__codelineno-70-1" name="__codelineno-70-1" href="#__codelineno-70-1"></a><span class="n">suma_por_columna</span> <span class="o">=</span> <span class="n">rectangles_df</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="nb">sum</span><span class="p">)</span>
</span><span id="__span-70-2"><a id="__codelineno-70-2" name="__codelineno-70-2" href="#__codelineno-70-2"></a><span class="nb">print</span><span class="p">(</span><span class="n">suma_por_columna</span><span class="p">)</span>
</span><span id="__span-70-3"><a id="__codelineno-70-3" name="__codelineno-70-3" href="#__codelineno-70-3"></a>
</span><span id="__span-70-4"><a id="__codelineno-70-4" name="__codelineno-70-4" href="#__codelineno-70-4"></a><span class="c1"># Suma de todas las celdas (&quot;columnas&quot;) por filas</span>
</span></code></pre></div>
<div class="language-text highlight"><pre><span></span><code><span id="__span-71-1"><a id="__codelineno-71-1" name="__codelineno-71-1" href="#__codelineno-71-1"></a>## height    63.4
</span><span id="__span-71-2"><a id="__codelineno-71-2" name="__codelineno-71-2" href="#__codelineno-71-2"></a>## width     23.0
</span><span id="__span-71-3"><a id="__codelineno-71-3" name="__codelineno-71-3" href="#__codelineno-71-3"></a>## dtype: float64
</span></code></pre></div>
<div class="language-python highlight"><pre><span></span><code><span id="__span-72-1"><a id="__codelineno-72-1" name="__codelineno-72-1" href="#__codelineno-72-1"></a><span class="n">suma_por_fila</span> <span class="o">=</span> <span class="n">rectangles_df</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="nb">sum</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
</span><span id="__span-72-2"><a id="__codelineno-72-2" name="__codelineno-72-2" href="#__codelineno-72-2"></a><span class="nb">print</span><span class="p">(</span><span class="n">suma_por_fila</span><span class="p">)</span>
</span></code></pre></div>
<div class="language-text highlight"><pre><span></span><code><span id="__span-73-1"><a id="__codelineno-73-1" name="__codelineno-73-1" href="#__codelineno-73-1"></a>## 0    50.0
</span><span id="__span-73-2"><a id="__codelineno-73-2" name="__codelineno-73-2" href="#__codelineno-73-2"></a>## 1    29.0
</span><span id="__span-73-3"><a id="__codelineno-73-3" name="__codelineno-73-3" href="#__codelineno-73-3"></a>## 2     7.4
</span><span id="__span-73-4"><a id="__codelineno-73-4" name="__codelineno-73-4" href="#__codelineno-73-4"></a>## dtype: float64
</span></code></pre></div>
<h4 id="apply-lambda-para-pasar-funciones-custom-en-el-momento"><a class="toclink" href="../../2020/07/11/de-r-a-python-1/#apply-lambda-para-pasar-funciones-custom-en-el-momento">Apply Lambda para pasar funciones custom en el momento</a></h4>
<div class="language-python highlight"><pre><span></span><code><span id="__span-74-1"><a id="__codelineno-74-1" name="__codelineno-74-1" href="#__codelineno-74-1"></a><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
</span><span id="__span-74-2"><a id="__codelineno-74-2" name="__codelineno-74-2" href="#__codelineno-74-2"></a><span class="n">rectangles</span> <span class="o">=</span> <span class="p">[</span>
</span><span id="__span-74-3"><a id="__codelineno-74-3" name="__codelineno-74-3" href="#__codelineno-74-3"></a>    <span class="p">{</span> <span class="s1">&#39;height&#39;</span><span class="p">:</span> <span class="mi">40</span><span class="p">,</span> <span class="s1">&#39;width&#39;</span><span class="p">:</span> <span class="mi">10</span> <span class="p">},</span>
</span><span id="__span-74-4"><a id="__codelineno-74-4" name="__codelineno-74-4" href="#__codelineno-74-4"></a>    <span class="p">{</span> <span class="s1">&#39;height&#39;</span><span class="p">:</span> <span class="mi">20</span><span class="p">,</span> <span class="s1">&#39;width&#39;</span><span class="p">:</span> <span class="mi">9</span> <span class="p">},</span>
</span><span id="__span-74-5"><a id="__codelineno-74-5" name="__codelineno-74-5" href="#__codelineno-74-5"></a>    <span class="p">{</span> <span class="s1">&#39;height&#39;</span><span class="p">:</span> <span class="mf">3.4</span><span class="p">,</span> <span class="s1">&#39;width&#39;</span><span class="p">:</span> <span class="mi">4</span> <span class="p">}</span>
</span><span id="__span-74-6"><a id="__codelineno-74-6" name="__codelineno-74-6" href="#__codelineno-74-6"></a><span class="p">]</span>
</span><span id="__span-74-7"><a id="__codelineno-74-7" name="__codelineno-74-7" href="#__codelineno-74-7"></a>
</span><span id="__span-74-8"><a id="__codelineno-74-8" name="__codelineno-74-8" href="#__codelineno-74-8"></a><span class="n">rectangles_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">rectangles</span><span class="p">)</span>
</span><span id="__span-74-9"><a id="__codelineno-74-9" name="__codelineno-74-9" href="#__codelineno-74-9"></a>
</span><span id="__span-74-10"><a id="__codelineno-74-10" name="__codelineno-74-10" href="#__codelineno-74-10"></a><span class="k">def</span> <span class="nf">multiplicar_2</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
</span><span id="__span-74-11"><a id="__codelineno-74-11" name="__codelineno-74-11" href="#__codelineno-74-11"></a>   <span class="k">return</span> <span class="n">x</span><span class="o">*</span><span class="mi">2</span>
</span><span id="__span-74-12"><a id="__codelineno-74-12" name="__codelineno-74-12" href="#__codelineno-74-12"></a>
</span><span id="__span-74-13"><a id="__codelineno-74-13" name="__codelineno-74-13" href="#__codelineno-74-13"></a><span class="c1"># Caso donde paso una funcion propia predefinida</span>
</span><span id="__span-74-14"><a id="__codelineno-74-14" name="__codelineno-74-14" href="#__codelineno-74-14"></a><span class="n">rectangles_df</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">multiplicar_2</span><span class="p">)</span>
</span><span id="__span-74-15"><a id="__codelineno-74-15" name="__codelineno-74-15" href="#__codelineno-74-15"></a>
</span><span id="__span-74-16"><a id="__codelineno-74-16" name="__codelineno-74-16" href="#__codelineno-74-16"></a>
</span><span id="__span-74-17"><a id="__codelineno-74-17" name="__codelineno-74-17" href="#__codelineno-74-17"></a><span class="c1"># Lo mismo pero definido en el momento</span>
</span></code></pre></div>
<div class="language-text highlight"><pre><span></span><code><span id="__span-75-1"><a id="__codelineno-75-1" name="__codelineno-75-1" href="#__codelineno-75-1"></a>##    height  width
</span><span id="__span-75-2"><a id="__codelineno-75-2" name="__codelineno-75-2" href="#__codelineno-75-2"></a>## 0    80.0     20
</span><span id="__span-75-3"><a id="__codelineno-75-3" name="__codelineno-75-3" href="#__codelineno-75-3"></a>## 1    40.0     18
</span><span id="__span-75-4"><a id="__codelineno-75-4" name="__codelineno-75-4" href="#__codelineno-75-4"></a>## 2     6.8      8
</span></code></pre></div>
<div class="language-python highlight"><pre><span></span><code><span id="__span-76-1"><a id="__codelineno-76-1" name="__codelineno-76-1" href="#__codelineno-76-1"></a><span class="n">rectangles_df</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">*</span><span class="mi">2</span><span class="p">)</span>
</span></code></pre></div>
<div class="language-text highlight"><pre><span></span><code><span id="__span-77-1"><a id="__codelineno-77-1" name="__codelineno-77-1" href="#__codelineno-77-1"></a>##    height  width
</span><span id="__span-77-2"><a id="__codelineno-77-2" name="__codelineno-77-2" href="#__codelineno-77-2"></a>## 0    80.0     20
</span><span id="__span-77-3"><a id="__codelineno-77-3" name="__codelineno-77-3" href="#__codelineno-77-3"></a>## 1    40.0     18
</span><span id="__span-77-4"><a id="__codelineno-77-4" name="__codelineno-77-4" href="#__codelineno-77-4"></a>## 2     6.8      8
</span></code></pre></div>
<h4 id="calculos-by-group"><a class="toclink" href="../../2020/07/11/de-r-a-python-1/#calculos-by-group">Calculos by group</a></h4>
<p>Como el bygroup de tidyverse.</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-78-1"><a id="__codelineno-78-1" name="__codelineno-78-1" href="#__codelineno-78-1"></a><span class="c1"># Equivalente a  groupby(raceid) %&gt;% summarise(newcol = min(best_qualy_ms))</span>
</span><span id="__span-78-2"><a id="__codelineno-78-2" name="__codelineno-78-2" href="#__codelineno-78-2"></a><span class="n">min_qualy_by_race</span> <span class="o">=</span> <span class="n">qualifying</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;raceId&#39;</span><span class="p">)[</span><span class="s1">&#39;best_qualy_ms&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">()</span>
</span></code></pre></div>
<h4 id="by-group-mas-complejo-con-calculo-acumulado-en-determinada-ventana-de-obs-por-cada-fila"><a class="toclink" href="../../2020/07/11/de-r-a-python-1/#by-group-mas-complejo-con-calculo-acumulado-en-determinada-ventana-de-obs-por-cada-fila">By Group más complejo, con calculo acumulado en determinada ventana de obs. por cada fila</a></h4>
<div class="language-python highlight"><pre><span></span><code><span id="__span-79-1"><a id="__codelineno-79-1" name="__codelineno-79-1" href="#__codelineno-79-1"></a><span class="c1"># suma acumulada de los ultimos 4 periodos (rolling)</span>
</span><span id="__span-79-2"><a id="__codelineno-79-2" name="__codelineno-79-2" href="#__codelineno-79-2"></a><span class="c1"># luego el gorupby(level = 0).shift() es para lagearlo por grupo</span>
</span><span id="__span-79-3"><a id="__codelineno-79-3" name="__codelineno-79-3" href="#__codelineno-79-3"></a><span class="c1"># el ultimo reset_index es para quitar el indice de este ultimo agrupado</span>
</span><span id="__span-79-4"><a id="__codelineno-79-4" name="__codelineno-79-4" href="#__codelineno-79-4"></a><span class="n">driver_points</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;driverId&#39;</span><span class="p">)[</span><span class="s1">&#39;points&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">rolling</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="n">min_periods</span> <span class="o">=</span> <span class="mi">4</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="n">level</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">shift</span><span class="p">()</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">level</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)[</span><span class="s1">&#39;points&#39;</span><span class="p">]</span>
</span></code></pre></div>
    
  </div>
</article>
      
        <article class="md-post md-post--excerpt">
  <header class="md-post__header">
    
      <nav class="md-post__authors md-typeset">
        
          <span class="md-author">
            <img src="https://media.licdn.com/dms/image/v2/D4D03AQGGiT9NDiLy7Q/profile-displayphoto-shrink_200_200/profile-displayphoto-shrink_200_200/0/1681511830071?e=1738195200&v=beta&t=Nd1WNLQTxHfCe7dT9BBaQYgaYtEHFCOPpntpImC4Lz8" alt="Franco Betteo">
          </span>
        
      </nav>
    
    <div class="md-post__meta md-meta">
      <ul class="md-meta__list">
        <li class="md-meta__item">
          <time datetime="2020-05-03 00:00:00+00:00">2020-05-03</time></li>
        
          <li class="md-meta__item">
            in
            
              <a href="../../category/estadistica/" class="md-meta__link">estadistica</a></li>
        
        
          
          <li class="md-meta__item">
            
              6 min read
            
          </li>
        
      </ul>
      
    </div>
  </header>
  <div class="md-post__content md-typeset">
    <h2 id="anova"><a class="toclink" href="../../2020/05/03/anova/">ANOVA</a></h2>
<div class="language-r highlight"><pre><span></span><code><span id="__span-8-1"><a id="__codelineno-8-1" name="__codelineno-8-1" href="#__codelineno-8-1"></a><span class="nf">library</span><span class="p">(</span><span class="n">tidyverse</span><span class="p">)</span>
</span><span id="__span-8-2"><a id="__codelineno-8-2" name="__codelineno-8-2" href="#__codelineno-8-2"></a><span class="nf">library</span><span class="p">(</span><span class="n">patchwork</span><span class="p">)</span>
</span></code></pre></div>
<p>ANOVA refiere a "Analysis of Variance" en inglés y corresponde a una serie de procedimientos estadísiticos que permiten estudiar diferencias de medias poblacionales, basado en muestras. <br />
Es una técnica muy difundida para comparar medias de 2 o más grupos. Específicamente queremos ver
si todos los grupos comparten media o al menos uno difiere. En el caso más simple, de comparar dos medias, el resultado es equivalente al <em>test t de comparación de medias</em>  por lo que ANOVA se considera una generalización de este.</p>
<p>El test de hipótesis sería:
<span class="arithmatex">\(<span class="arithmatex">\(H_0: \mu_1 = ... = \mu_k\)</span>\)</span>
<span class="arithmatex">\(<span class="arithmatex">\(H_1: \text{las medias no son iguales}\)</span>\)</span>
ANOVA tiene también una serie de supuestos que hay que tener en cuenta.  </p>
<ul>
<li>Independencia de las observaciones.</li>
<li>Normalidad en los residuos. Podemos pensarlo como normalidad dentro de cada grupo, siendo el residuo la parte no explicada por la media del grupo. En muestras chicas puede ser problemático si no se cumple (reduce la potencia del test). Con muestras grandes debería cumplirse por Teorema Central del Límite.</li>
<li>Homocedasticidad. Se supone que cada grupo tiene misma varianza. Si la muestra no es muy chica ANOVA es bastante robusto con este supuesto, si no, hay alternativas no parámetricas por ejemplo.</li>
</ul>
<h4 id="un-ejemplo-simulado"><a class="toclink" href="../../2020/05/03/anova/#un-ejemplo-simulado">Un ejemplo simulado</a></h4>
<p>Generamos primero un set de datos donde la media de 3 grupos es distinta y vamos paso a paso con los cálculos.</p>
<div class="language-r highlight"><pre><span></span><code><span id="__span-9-1"><a id="__codelineno-9-1" name="__codelineno-9-1" href="#__codelineno-9-1"></a><span class="nf">set.seed</span><span class="p">(</span><span class="m">24</span><span class="p">)</span>
</span><span id="__span-9-2"><a id="__codelineno-9-2" name="__codelineno-9-2" href="#__codelineno-9-2"></a><span class="n">df</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">data.frame</span><span class="p">(</span><span class="n">grupo1</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">rnorm</span><span class="p">(</span><span class="n">n</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">35</span><span class="p">,</span><span class="w"> </span><span class="n">mean</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">3</span><span class="p">,</span><span class="w"> </span><span class="n">sd</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1</span><span class="p">),</span>
</span><span id="__span-9-3"><a id="__codelineno-9-3" name="__codelineno-9-3" href="#__codelineno-9-3"></a><span class="w">                </span><span class="n">grupo2</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">rnorm</span><span class="p">(</span><span class="n">n</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">35</span><span class="p">,</span><span class="w"> </span><span class="n">mean</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">6</span><span class="p">,</span><span class="w"> </span><span class="n">sd</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1</span><span class="p">),</span>
</span><span id="__span-9-4"><a id="__codelineno-9-4" name="__codelineno-9-4" href="#__codelineno-9-4"></a><span class="w">                </span><span class="n">grupo3</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">rnorm</span><span class="p">(</span><span class="n">n</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">35</span><span class="p">,</span><span class="w"> </span><span class="n">mean</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">9</span><span class="p">,</span><span class="w"> </span><span class="n">sd</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1</span><span class="p">))</span>
</span></code></pre></div>
<p>Tenemos 3 grupos de 35 observaciones, cada uno proveniente de poblaciones con medias notoriamente distintas.<br />
Veamos como resultaron las medias muestrales.</p>
<div class="language-r highlight"><pre><span></span><code><span id="__span-10-1"><a id="__codelineno-10-1" name="__codelineno-10-1" href="#__codelineno-10-1"></a><span class="nf">sapply</span><span class="p">(</span><span class="n">df</span><span class="p">,</span><span class="w"> </span><span class="n">FUN</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">mean</span><span class="p">)</span>
</span></code></pre></div>
<div class="language-text highlight"><pre><span></span><code><span id="__span-11-1"><a id="__codelineno-11-1" name="__codelineno-11-1" href="#__codelineno-11-1"></a>##   grupo1   grupo2   grupo3 
</span><span id="__span-11-2"><a id="__codelineno-11-2" name="__codelineno-11-2" href="#__codelineno-11-2"></a>## 2.916989 5.910171 8.904245
</span></code></pre></div>
<p>Viédolo gráficamente vemos que son muy dispares y ANOVA debería captar estas diferencias.<br />
En el segundo gráfico, la linea vertical represnta la media general del dataset</p>
<p><img alt="Image" src="../../img/2020-05-03-anova-unnamed-chunk-5-1.png" />
Veamos como resulta analizar esto con ANOVA.  </p>
<h4 id="calculos"><a class="toclink" href="../../2020/05/03/anova/#calculos">Cálculos.</a></h4>
<p>Obviamente existen paquetes estadísticos para realizar este análisis rapidamente pero iremos paso por paso.<br />
La lógica es comparar la media de las poblaciones y para ello nos basamos en la varianza. Más precisamente en la descomposición de la varianza.</p>
<p><span class="arithmatex">\(<span class="arithmatex">\(SC_{Total} = SC_{Entre} +  SC_{Dentro}\)</span>\)</span>
La suma de errores cuadrados de TODO el dataset se puede descomponer entre el desvío cuadrado de cada grupo frente a la media general (Entre) más el desvío cuadrado de cada observación respecto a su media grupal.</p>
<p>Siendo más intuitivos. Los suma de los desvíos cuadrados de cada observación respecto a la media general 5.91 pueden ser vistos como la diferencia entre medias grupales (qué tan lejos está cada pico del gráfico de la media grupal) más qué tan dispersos están los datos dentro de cada grupo.  </p>
<p>Cuanto más grande sea la brecha entre la variabilidad entre grupos y la variabilidad al interior de los grupos, más probable es que las medias poblacionales sean distintas. Es decir, si la variabilidad total se explica más por la diferencia entre medias grupales que por la diferencia entre desviós al interior, entonces más evidencia en favor de distintas medias grupales. Si el ratio no es tan grande, entonces tenemos menos fuerza para afirmar tal cosa.</p>
<p>Para poder comparar correctamente, no se mira directamente <span class="arithmatex">\(SC_{Entre}\)</span> vs <span class="arithmatex">\(SC_{Dentro}\)</span> ya que estos dependen del tamaño de la muestra, sino que se los normaliza primero.  <span class="arithmatex">\(SC_{Entre}\)</span> se normaliza por sus grados de libertad siendo <em>k-1</em> (cantidad de grupos menos 1) y  <span class="arithmatex">\(SC_{Dentro}\)</span> se normaliza con <em>N-K</em> (observaciones totales menos cantidad de grupos).</p>
<blockquote>
<h5 id="detalle-tecnico"><a class="toclink" href="../../2020/05/03/anova/#detalle-tecnico">Detalle técnico</a></h5>
<p>Como asumimos que los residuos son normales, entonces elevarlos al cuadrado nos devuelve una distribución <em>Chi-Cuadrado</em>. Las sumas de residuos al cuadrado son entones Chi-Cuadrado con los grados de libertad que mencionamos.
Si dividimos dos distribuciones Chi-Cuadrado, normalizadas por sus grados de libertad, obtenemos una distribución F con grados de libertad equivalentes a los de ambas Chi-Cuadrado.</p>
</blockquote>
<p>Ese estadístico F, que sigue la distribución recién mencionada sera nuestro estádistico para testear la Hipótesis.</p>
<div class="arithmatex">\[F = \frac{\frac{SC_{Entre}}{K-1}}{\frac{SC_{Dentro}}{N-K}}\]</div>
<p>Donde:
<span class="arithmatex">\(<span class="arithmatex">\(SC_{Entre} = \sum_{i=1}^k{n_i (\bar{x}_i} - \bar{x})^2\)</span>\)</span>
<span class="arithmatex">\(<span class="arithmatex">\(SC_{Dentro} = \sum_{i=1}^K\sum_{j=1}^{n_k}{(x_j - \bar{x}_i)^2}\)</span>\)</span>
Luego como en cualquier test de hipótesis, comparamos el estadístico F con la distribución teórica si la hipótesis nula fuera cierto y según el valor de alfa que hayamos elegido, rechazamos o no la hipótesis nula.<br />
Para ilustrar, la dsitribución F tiene la siguiente forma con los grados de libertad de nuestro ejemplo.</p>
<p><img alt="Image" src="../../img/2020-05-03-anova-unnamed-chunk-6-1.png" /></p>
<p>Donde la región en rojo es el area de la curva posterior al 95% de la distribución. Si nuestro estadístico cae en la zona rojo podemos rechazar la hipótesis nula con alfa =0.05</p>
<p>Obtengamos los números con la función aov.</p>
<div class="language-r highlight"><pre><span></span><code><span id="__span-12-1"><a id="__codelineno-12-1" name="__codelineno-12-1" href="#__codelineno-12-1"></a><span class="n">res</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">aov</span><span class="p">(</span><span class="n">valor</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">grupo</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">df_long</span><span class="p">)</span>
</span><span id="__span-12-2"><a id="__codelineno-12-2" name="__codelineno-12-2" href="#__codelineno-12-2"></a><span class="nf">summary</span><span class="p">(</span><span class="n">res</span><span class="p">)</span>
</span></code></pre></div>
<div class="language-text highlight"><pre><span></span><code><span id="__span-13-1"><a id="__codelineno-13-1" name="__codelineno-13-1" href="#__codelineno-13-1"></a>##              Df Sum Sq Mean Sq F value Pr(&gt;F)    
</span><span id="__span-13-2"><a id="__codelineno-13-2" name="__codelineno-13-2" href="#__codelineno-13-2"></a>## grupo         2  627.3  313.66     326 &lt;2e-16 ***
</span><span id="__span-13-3"><a id="__codelineno-13-3" name="__codelineno-13-3" href="#__codelineno-13-3"></a>## Residuals   102   98.1    0.96                   
</span><span id="__span-13-4"><a id="__codelineno-13-4" name="__codelineno-13-4" href="#__codelineno-13-4"></a>## ---
</span><span id="__span-13-5"><a id="__codelineno-13-5" name="__codelineno-13-5" href="#__codelineno-13-5"></a>## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
</span></code></pre></div>
<p>La tabla que devuelve la función es justamente todo lo que fuimos viendo.<br />
Sum Sq es la suma de desvíos cuadrados. La fila de grupo corresponde a <em>Entre</em> y Residuals corresponde a <em>Dentro</em>.<br />
DF son los grados de libertad (K-1) y (N-K).<br />
Mean Sq es la división de Sum Sq por sus grados de libertad. Serían el numerador y denominador del estadístico F.<br />
F value es simplemente la división de los Mean Sq. Obtenemos un estadístico de 326(!). A partir de 3 aprox ya podíamos rechazar la hipótesis nula. El p-value (la última columna) es virtualmente 0.</p>
<p>Dado este resultado, podemos rechazar la hipótesis nula y asegurar con el 95% de confianza que las medias poblacionales no son iguales.<br />
Era un caso medio extremo pero sirve de ejemplo.</p>
<p>Lo que no nos dice ANOVA es si todas son distintas o cuál es diferente al resto. Para ello hay que hacer estudios posteriores pero no entramos en detalles acá.</p>
<h4 id="un-caso-de-medias-iguales"><a class="toclink" href="../../2020/05/03/anova/#un-caso-de-medias-iguales">Un caso de medias iguales</a></h4>
<p><img alt="Image" src="../../img/2020-05-03-anova-unnamed-chunk-10-1.png" /></p>
<div class="language-r highlight"><pre><span></span><code><span id="__span-14-1"><a id="__codelineno-14-1" name="__codelineno-14-1" href="#__codelineno-14-1"></a><span class="n">res2</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">aov</span><span class="p">(</span><span class="n">valor</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">grupo</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">df2_long</span><span class="p">)</span>
</span><span id="__span-14-2"><a id="__codelineno-14-2" name="__codelineno-14-2" href="#__codelineno-14-2"></a>
</span><span id="__span-14-3"><a id="__codelineno-14-3" name="__codelineno-14-3" href="#__codelineno-14-3"></a><span class="nf">summary</span><span class="p">(</span><span class="n">res2</span><span class="p">)</span>
</span></code></pre></div>
<div class="language-text highlight"><pre><span></span><code><span id="__span-15-1"><a id="__codelineno-15-1" name="__codelineno-15-1" href="#__codelineno-15-1"></a>##              Df Sum Sq Mean Sq F value Pr(&gt;F)
</span><span id="__span-15-2"><a id="__codelineno-15-2" name="__codelineno-15-2" href="#__codelineno-15-2"></a>## grupo         2   0.00  0.0014   0.001  0.999
</span><span id="__span-15-3"><a id="__codelineno-15-3" name="__codelineno-15-3" href="#__codelineno-15-3"></a>## Residuals   102  98.14  0.9621
</span></code></pre></div>
<p>Aquí es el otro extremo. El valor del estadístico F es casi 0, por lo tanto el p-value es casi 1. No hay evidencia para rechazar la hipótesis nula.</p>
<h4 id="conclusiones"><a class="toclink" href="../../2020/05/03/anova/#conclusiones">Conclusiones</a></h4>
<p>ANOVA cómo método para comparar medias poblacionales es muy sencillo de aplicar y bastante robusto frente a inconsistencias en los supuestos. Permite dar una medida objetiva de si es posible o no rechazar la hipótesis nula, más allá de que uno pueda tener una primera impresión visual.</p>
<p>Para ir un paso más allá, ANOVA se puede relacionar directamnte con las regresiones lineales. Anova tal como lo presentamos es equivalente a correr una regresión donde la variable independiente es el grupo al que pertenece la observación. Las generalizaciones como ANCOVA, MANOVA, etc, también tienen su correlato en regresión. Esto sucede porque según el campo de estudio se eligieron caminos y convenciones distintos de análisis, llevando a distintas ramas que al final hacen lo mismo, pero genera confusión al intentar entender la estadística como un todo.</p>
    
  </div>
</article>
      
        <article class="md-post md-post--excerpt">
  <header class="md-post__header">
    
      <nav class="md-post__authors md-typeset">
        
          <span class="md-author">
            <img src="https://media.licdn.com/dms/image/v2/D4D03AQGGiT9NDiLy7Q/profile-displayphoto-shrink_200_200/profile-displayphoto-shrink_200_200/0/1681511830071?e=1738195200&v=beta&t=Nd1WNLQTxHfCe7dT9BBaQYgaYtEHFCOPpntpImC4Lz8" alt="Franco Betteo">
          </span>
        
      </nav>
    
    <div class="md-post__meta md-meta">
      <ul class="md-meta__list">
        <li class="md-meta__item">
          <time datetime="2020-04-25 00:00:00+00:00">2020-04-25</time></li>
        
          <li class="md-meta__item">
            in
            
              <a href="../../category/estadistica/" class="md-meta__link">estadistica</a>, 
              <a href="../../category/r/" class="md-meta__link">R</a></li>
        
        
          
          <li class="md-meta__item">
            
              5 min read
            
          </li>
        
      </ul>
      
    </div>
  </header>
  <div class="md-post__content md-typeset">
    <h2 id="distribucion-gamma"><a class="toclink" href="../../2020/04/25/distribucion-gamma/">Distribucion Gamma</a></h2>
<h4 id="origen-y-uso-habitual"><a class="toclink" href="../../2020/04/25/distribucion-gamma/#origen-y-uso-habitual">Origen y uso habitual</a></h4>
<p>La distribución Gamma es continua y siempre positiva. Se parametriza con dos parámetros que deben ser positivos.</p>
<p>Lamentablemente no hay un consenso sobre cómo llamar a los parámetros y prevalecen dos formas, bastante similares pero con distinto origen.</p>
<ul>
<li>La primera es con los parámetros shape <span class="arithmatex">\(k\)</span> y scale <span class="arithmatex">\(\theta\)</span>.</li>
<li>La segunda es con los parámetros shape <span class="arithmatex">\(\alpha\)</span> y rate <span class="arithmatex">\(\beta\)</span>.</li>
</ul>
<p>La relación entre ambas es <span class="arithmatex">\(k = \alpha\)</span> y <span class="arithmatex">\(\theta = 1/\beta\)</span>.<br />
Obviamente cualquiera que se use va a resultar en los mismos resultados, pero hay que estar atento para lograr la parametrización adecuada.</p>
<p>Yo prefiero la segunda opción, donde el rate <span class="arithmatex">\(\beta\)</span> puede relacionarse al rate <span class="arithmatex">\(\lambda\)</span> de una <a href="https://fbetteo.netlify.app/2020/04/proceso-poisson-y-distribucion-exponencial">poisson</a>.</p>
<h4 id="por-que-nos-interesa-relacionarla-con-la-poisson"><a class="toclink" href="../../2020/04/25/distribucion-gamma/#por-que-nos-interesa-relacionarla-con-la-poisson">Por qué nos interesa relacionarla con la Poisson?</a></h4>
<p>Uno de los usos habituales y que resulta fácil de entender es que si nos encontramos en un <em>Proceso de Poisson</em> (si no se recuerda ver <a href="https://fbetteo.netlify.app/2020/04/proceso-poisson-y-distribucion-exponencial">ACA</a>), suceden <span class="arithmatex">\(\lambda\)</span> eventos por período en promedio (la distribución poisson nos ayuda con eso), el tiempo (medido en períodos) entre un evento y otro se puede modelar con una exponencial con parámetro rate = <span class="arithmatex">\(\lambda\)</span> (el mismo de la poisson), y ahora adicionamos que el tiempo medido en períodos hasta que suceda el k-ésimo evento, se puede modelar con la distribución gamma, parametrizada con shape = <span class="arithmatex">\(k\)</span> (cantidad de eventos) y rate = <span class="arithmatex">\(\lambda\)</span> (el mismo de la poisson nuevamente.)</p>
<p>Por ejemplo:</p>
<p>Si podemos modelar la cantidad de veces que vamos por semana a comprar cerveza como una poisson con <span class="arithmatex">\(\lambda\)</span> = 2, es decir en promedio dos veces por semana, tendremos la siguiente distribución.</p>
<div class="language-r highlight"><pre><span></span><code><span id="__span-8-1"><a id="__codelineno-8-1" name="__codelineno-8-1" href="#__codelineno-8-1"></a><span class="nf">set.seed</span><span class="p">(</span><span class="m">1</span><span class="p">)</span>
</span><span id="__span-8-2"><a id="__codelineno-8-2" name="__codelineno-8-2" href="#__codelineno-8-2"></a><span class="nf">ggplot</span><span class="p">()</span><span class="w"> </span><span class="o">+</span>
</span><span id="__span-8-3"><a id="__codelineno-8-3" name="__codelineno-8-3" href="#__codelineno-8-3"></a><span class="w">  </span><span class="nf">geom_bar</span><span class="p">(</span><span class="nf">aes</span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">rpois</span><span class="p">(</span><span class="m">10000</span><span class="p">,</span><span class="m">2</span><span class="p">)),</span><span class="w"> </span><span class="n">fill</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;lightgreen&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">color</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;black&quot;</span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
</span><span id="__span-8-4"><a id="__codelineno-8-4" name="__codelineno-8-4" href="#__codelineno-8-4"></a><span class="w">  </span><span class="nf">xlab</span><span class="p">(</span><span class="s">&quot;&quot;</span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
</span><span id="__span-8-5"><a id="__codelineno-8-5" name="__codelineno-8-5" href="#__codelineno-8-5"></a><span class="w">  </span><span class="nf">ylab</span><span class="p">(</span><span class="s">&quot;&quot;</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span>
</span><span id="__span-8-6"><a id="__codelineno-8-6" name="__codelineno-8-6" href="#__codelineno-8-6"></a><span class="w">  </span><span class="nf">ggtitle</span><span class="p">(</span><span class="s">&quot;Simulación de 10000 variables Poisson con rate = 2&quot;</span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
</span><span id="__span-8-7"><a id="__codelineno-8-7" name="__codelineno-8-7" href="#__codelineno-8-7"></a><span class="w">  </span><span class="nf">scale_x_continuous</span><span class="p">(</span><span class="n">breaks</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">seq</span><span class="p">(</span><span class="m">0</span><span class="p">,</span><span class="m">9</span><span class="p">))</span><span class="w"> </span><span class="o">+</span><span class="w"> </span>
</span><span id="__span-8-8"><a id="__codelineno-8-8" name="__codelineno-8-8" href="#__codelineno-8-8"></a><span class="w">  </span><span class="nf">theme_minimal</span><span class="p">()</span>
</span></code></pre></div>
<p><img alt="Image" src="../../img/2020-04-25-distribucion-gamma-unnamed-chunk-2-1.png" />
Donde la mayoría de las semanas vamos alrededor de  2 veces.</p>
<p>Podemos a su vez, modelar el tiempo entre cada evento con una exponencial. Se lo puede pensar como ¿cuánto tiempo falta para que vaya de nuevo a comprar cerveza a partir del momento en que estoy parado?</p>
<p>Usaremos una exponencial, pero para verlo en días, que sería lo apropiado, cambiamos <span class="arithmatex">\(\lambda = 2\)</span> por <span class="arithmatex">\(\lambda = 2/7\)</span>, que sería el rate por día.</p>
<div class="language-r highlight"><pre><span></span><code><span id="__span-9-1"><a id="__codelineno-9-1" name="__codelineno-9-1" href="#__codelineno-9-1"></a><span class="nf">set.seed</span><span class="p">(</span><span class="m">2</span><span class="p">)</span>
</span><span id="__span-9-2"><a id="__codelineno-9-2" name="__codelineno-9-2" href="#__codelineno-9-2"></a><span class="nf">ggplot</span><span class="p">()</span><span class="w"> </span><span class="o">+</span>
</span><span id="__span-9-3"><a id="__codelineno-9-3" name="__codelineno-9-3" href="#__codelineno-9-3"></a><span class="w">  </span><span class="nf">geom_histogram</span><span class="p">(</span><span class="nf">aes</span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">rexp</span><span class="p">(</span><span class="m">10000</span><span class="p">,</span><span class="w"> </span><span class="m">2</span><span class="o">/</span><span class="m">7</span><span class="p">)),</span><span class="n">bins</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">100</span><span class="p">,</span><span class="w"> </span><span class="n">fill</span><span class="w"> </span><span class="o">=</span><span class="s">&quot;darkgreen&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">color</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;black&quot;</span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
</span><span id="__span-9-4"><a id="__codelineno-9-4" name="__codelineno-9-4" href="#__codelineno-9-4"></a><span class="w">  </span><span class="nf">xlab</span><span class="p">(</span><span class="s">&quot;&quot;</span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
</span><span id="__span-9-5"><a id="__codelineno-9-5" name="__codelineno-9-5" href="#__codelineno-9-5"></a><span class="w">  </span><span class="nf">ylab</span><span class="p">(</span><span class="s">&quot;&quot;</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span>
</span><span id="__span-9-6"><a id="__codelineno-9-6" name="__codelineno-9-6" href="#__codelineno-9-6"></a><span class="w">  </span><span class="nf">ggtitle</span><span class="p">(</span><span class="s">&quot;Simulación de 10000 variables Exponenciales con rate = 2/7&quot;</span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
</span><span id="__span-9-7"><a id="__codelineno-9-7" name="__codelineno-9-7" href="#__codelineno-9-7"></a><span class="w">  </span><span class="nf">scale_x_continuous</span><span class="p">(</span><span class="n">breaks</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="nf">seq</span><span class="p">(</span><span class="m">0</span><span class="p">,</span><span class="m">10</span><span class="p">),</span><span class="m">15</span><span class="p">,</span><span class="m">20</span><span class="p">,</span><span class="m">25</span><span class="p">,</span><span class="m">30</span><span class="p">,</span><span class="m">35</span><span class="p">,</span><span class="m">40</span><span class="p">))</span><span class="w"> </span><span class="o">+</span><span class="w"> </span>
</span><span id="__span-9-8"><a id="__codelineno-9-8" name="__codelineno-9-8" href="#__codelineno-9-8"></a><span class="w">  </span><span class="nf">theme_minimal</span><span class="p">()</span>
</span></code></pre></div>
<p><img alt="Image" src="../../img/2020-04-25-distribucion-gamma-unnamed-chunk-3-1.png" />
Vemos que en general faltan 1 o 2 días para que tengamos que ir de nuevo, aunque si tomamos el promedio veremos que es 3.5 dias, lo cuales lógico porque venimos de una poisson con rate de 2 veces por semana.</p>
<p>Si ahora queremos ver en cuantos días habremos ido 5 veces, podemos usar la distribución gamma, con <span class="arithmatex">\(shape = 5\)</span> (porque queremos ver el 5 evento), y <span class="arithmatex">\(rate = 2/7\)</span> porque es el rate diario.</p>
<div class="language-r highlight"><pre><span></span><code><span id="__span-10-1"><a id="__codelineno-10-1" name="__codelineno-10-1" href="#__codelineno-10-1"></a><span class="nf">set.seed</span><span class="p">(</span><span class="m">3</span><span class="p">)</span>
</span><span id="__span-10-2"><a id="__codelineno-10-2" name="__codelineno-10-2" href="#__codelineno-10-2"></a><span class="nf">ggplot</span><span class="p">()</span><span class="w"> </span><span class="o">+</span>
</span><span id="__span-10-3"><a id="__codelineno-10-3" name="__codelineno-10-3" href="#__codelineno-10-3"></a><span class="w">  </span><span class="nf">geom_histogram</span><span class="p">(</span><span class="nf">aes</span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">rgamma</span><span class="p">(</span><span class="m">10000</span><span class="p">,</span><span class="w"> </span><span class="n">shape</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">5</span><span class="p">,</span><span class="w"> </span><span class="n">rate</span><span class="w"> </span><span class="o">=</span><span class="w">  </span><span class="m">2</span><span class="o">/</span><span class="m">7</span><span class="p">)),</span><span class="n">bins</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">100</span><span class="p">,</span><span class="w"> </span><span class="n">fill</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;darkred&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">color</span><span class="w"> </span><span class="o">=</span><span class="s">&quot;black&quot;</span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
</span><span id="__span-10-4"><a id="__codelineno-10-4" name="__codelineno-10-4" href="#__codelineno-10-4"></a><span class="w">  </span><span class="nf">xlab</span><span class="p">(</span><span class="s">&quot;&quot;</span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
</span><span id="__span-10-5"><a id="__codelineno-10-5" name="__codelineno-10-5" href="#__codelineno-10-5"></a><span class="w">  </span><span class="nf">ylab</span><span class="p">(</span><span class="s">&quot;&quot;</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span>
</span><span id="__span-10-6"><a id="__codelineno-10-6" name="__codelineno-10-6" href="#__codelineno-10-6"></a><span class="w">  </span><span class="nf">ggtitle</span><span class="p">(</span><span class="s">&quot;Simulación de 10000 variables Gamma con shape = 5  y rate = 2/7&quot;</span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
</span><span id="__span-10-7"><a id="__codelineno-10-7" name="__codelineno-10-7" href="#__codelineno-10-7"></a><span class="w">  </span><span class="nf">scale_x_continuous</span><span class="p">(</span><span class="n">breaks</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">seq</span><span class="p">(</span><span class="m">0</span><span class="p">,</span><span class="m">60</span><span class="p">,</span><span class="w"> </span><span class="n">by</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">5</span><span class="p">))</span><span class="w"> </span><span class="o">+</span><span class="w"> </span>
</span><span id="__span-10-8"><a id="__codelineno-10-8" name="__codelineno-10-8" href="#__codelineno-10-8"></a><span class="w">  </span><span class="nf">theme_minimal</span><span class="p">()</span>
</span></code></pre></div>
<p><img alt="Image" src="../../img/2020-04-25-distribucion-gamma-unnamed-chunk-4-1.png" /></p>
<p>Podemos ver que la distribución gamma es asimétrica en este caso y en general faltan unos 12-16 días. Si tomamos el promedio vemos que es de 17.5 días, lo cual tiene sentido ya que es 5 veces el tiempo promedio de espera, que era 3.5 días.</p>
<p>La media de una gamma puede calcularse rápidamente como <span class="arithmatex">\(media = \frac{shape}{rate} = \frac{5}{2/7} = 17.5\)</span></p>
<p>Hay una clara relación entre la distribución Exponencial y la Gamma.<br />
Primero, como ya vimos, la exponencial modela el tiempo hasta el próximo evento en un proceso Poisson y la Gamma hasta el k-ésimo evento.<br />
Podemos pensar a la distribución Gamma como la suma de K distribuciones Exponenciales con un mismo rate!</p>
<p>Yendo más allá, en realidad, la distribución Gamma es una familia de distribuciones, y la Exponencial no es más que un caso particular de la Gamma con k = 1.<br />
Si Gamma nos permite saber el tiempo hasta el k-esimo evento, y la Exponencial es hasta el primer evento, entonces la Exponencial como caso particular de la Gamma parece obvio.</p>
<h4 id="un-poco-de-formulas"><a class="toclink" href="../../2020/04/25/distribucion-gamma/#un-poco-de-formulas">Un poco de formulas</a></h4>
<p>La función de densidad de la distribución Gamma, utilizando <span class="arithmatex">\(\alpha\)</span> y <span class="arithmatex">\(\beta\)</span> es:
<span class="arithmatex">\(<span class="arithmatex">\(\frac{\beta^{\alpha}}{\Gamma (\alpha)}x^{\alpha - 1}e^{-\beta x}\)</span>\)</span></p>
<p>donde <span class="arithmatex">\(\Gamma (\alpha)\)</span> = <span class="arithmatex">\((\alpha - 1)!\)</span>  </p>
<p>Cuidado con las distintas maneras de nombrar a los parámetros. En la literatura posiblemente vean <span class="arithmatex">\(\alpha\)</span> y <span class="arithmatex">\(\beta\)</span> cuando usen shape y rate. Aquí para el ejemplo de las cervezas reemplazamos <span class="arithmatex">\(\alpha\)</span> por <span class="arithmatex">\(k\)</span> y <span class="arithmatex">\(\beta\)</span> por <span class="arithmatex">\(\lambda\)</span> para relacionarlo con la distribución Poisson.</p>
<p>El equivalente con esa notación sería:
<span class="arithmatex">\(<span class="arithmatex">\(\frac{\lambda^{k}}{\Gamma (k)}x^{k - 1}e^{-\lambda x}\)</span>\)</span></p>
<p>Como dijimos si reemplazamos k por 1, obtenemos la función de densidad de la Exponencial.</p>
<p>Otras distribuciones que son casos particulares de la Gamma son la Erlang (es Gamma pero con valores discretos de K, la exponencial también es un caso particular de Erlang con k= 1) y la Chi-Cuadrado</p>
<h4 id="desestimar-el-significado-de-shape-y-scale"><a class="toclink" href="../../2020/04/25/distribucion-gamma/#desestimar-el-significado-de-shape-y-scale">Desestimar el significado de Shape y Scale</a></h4>
<p>Ya sea que prefiramos shape y scale o shape y rate como parametrización, sus nombres en inglés llevan a pensar que la dsitribución varía su forma con shape y su escala con scale. Eso no es tan así y puede llevar más a confusiones que otra cosa. Ambos parámetros pueden afectar tanto la forma y escala, por eso me parece más sencillo pensarlo con <span class="arithmatex">\(k\)</span> Y <span class="arithmatex">\(\lambda\)</span>, al menos en el ámbito de los procesos Poisson.<br />
Igualmente, no olvidar que la distribcuión Gamma se puede usar para otros campos que no son situaciones de un Proceso de Poisson y esa interpretación de los parámetros puede ser poco apropiada.</p>
<div class="language-r highlight"><pre><span></span><code><span id="__span-11-1"><a id="__codelineno-11-1" name="__codelineno-11-1" href="#__codelineno-11-1"></a><span class="n">k</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">2</span><span class="p">,</span><span class="m">9</span><span class="p">)</span>
</span><span id="__span-11-2"><a id="__codelineno-11-2" name="__codelineno-11-2" href="#__codelineno-11-2"></a><span class="n">rate</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">1</span><span class="p">,</span><span class="m">2</span><span class="p">)</span>
</span><span id="__span-11-3"><a id="__codelineno-11-3" name="__codelineno-11-3" href="#__codelineno-11-3"></a><span class="n">x</span><span class="o">=</span><span class="w"> </span><span class="nf">seq</span><span class="p">(</span><span class="m">0</span><span class="p">,</span><span class="m">10</span><span class="p">,</span><span class="w"> </span><span class="n">by</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.1</span><span class="p">)</span>
</span><span id="__span-11-4"><a id="__codelineno-11-4" name="__codelineno-11-4" href="#__codelineno-11-4"></a>
</span><span id="__span-11-5"><a id="__codelineno-11-5" name="__codelineno-11-5" href="#__codelineno-11-5"></a><span class="n">df</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">expand.grid</span><span class="p">(</span><span class="n">lambda</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">as.factor</span><span class="p">(</span><span class="n">rate</span><span class="p">),</span><span class="w"> </span><span class="n">k</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">k</span><span class="p">,</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">x</span><span class="p">)</span><span class="w"> </span><span class="o">%&gt;%</span>
</span><span id="__span-11-6"><a id="__codelineno-11-6" name="__codelineno-11-6" href="#__codelineno-11-6"></a><span class="w">  </span><span class="nf">mutate</span><span class="p">(</span><span class="n">gamma</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">dgamma</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">k</span><span class="p">,</span><span class="w"> </span><span class="nf">as.numeric</span><span class="p">(</span><span class="nf">as.character</span><span class="p">(</span><span class="n">lambda</span><span class="p">))),</span>
</span><span id="__span-11-7"><a id="__codelineno-11-7" name="__codelineno-11-7" href="#__codelineno-11-7"></a><span class="w">         </span><span class="n">combination</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">as.factor</span><span class="p">(</span><span class="nf">paste0</span><span class="p">(</span><span class="s">&quot;k = &quot;</span><span class="p">,</span><span class="n">k</span><span class="p">,</span><span class="s">&quot;, lambda = &quot;</span><span class="p">,</span><span class="n">lambda</span><span class="p">)))</span>
</span><span id="__span-11-8"><a id="__codelineno-11-8" name="__codelineno-11-8" href="#__codelineno-11-8"></a>
</span><span id="__span-11-9"><a id="__codelineno-11-9" name="__codelineno-11-9" href="#__codelineno-11-9"></a><span class="nf">ggplot</span><span class="p">(</span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">df</span><span class="p">,</span><span class="w"> </span><span class="nf">aes</span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="n">gamma</span><span class="p">,</span><span class="w"> </span><span class="n">color</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">combination</span><span class="p">))</span><span class="w"> </span><span class="o">+</span><span class="w"> </span>
</span><span id="__span-11-10"><a id="__codelineno-11-10" name="__codelineno-11-10" href="#__codelineno-11-10"></a><span class="w">  </span><span class="nf">geom_line</span><span class="p">()</span><span class="w"> </span><span class="o">+</span><span class="w"> </span>
</span><span id="__span-11-11"><a id="__codelineno-11-11" name="__codelineno-11-11" href="#__codelineno-11-11"></a><span class="w">  </span><span class="c1">#geom_point() + </span>
</span><span id="__span-11-12"><a id="__codelineno-11-12" name="__codelineno-11-12" href="#__codelineno-11-12"></a><span class="w">  </span><span class="nf">ggtitle</span><span class="p">(</span><span class="s">&quot;Función de Densidad para distintos parámetros de una Distribución Gamma&quot;</span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
</span><span id="__span-11-13"><a id="__codelineno-11-13" name="__codelineno-11-13" href="#__codelineno-11-13"></a><span class="w">  </span><span class="nf">xlab</span><span class="p">(</span><span class="s">&quot;Períodos&quot;</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span>
</span><span id="__span-11-14"><a id="__codelineno-11-14" name="__codelineno-11-14" href="#__codelineno-11-14"></a><span class="w">  </span><span class="nf">ylab</span><span class="p">(</span><span class="s">&quot;&quot;</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span>
</span><span id="__span-11-15"><a id="__codelineno-11-15" name="__codelineno-11-15" href="#__codelineno-11-15"></a><span class="w">  </span><span class="nf">scale_color_brewer</span><span class="p">(</span><span class="n">palette</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;Set1&quot;</span><span class="p">)</span>
</span></code></pre></div>
<p><img alt="Image" src="../../img/2020-04-25-distribucion-gamma-unnamed-chunk-5-1.png" /></p>
    
  </div>
</article>
      
        <article class="md-post md-post--excerpt">
  <header class="md-post__header">
    
      <nav class="md-post__authors md-typeset">
        
          <span class="md-author">
            <img src="https://media.licdn.com/dms/image/v2/D4D03AQGGiT9NDiLy7Q/profile-displayphoto-shrink_200_200/profile-displayphoto-shrink_200_200/0/1681511830071?e=1738195200&v=beta&t=Nd1WNLQTxHfCe7dT9BBaQYgaYtEHFCOPpntpImC4Lz8" alt="Franco Betteo">
          </span>
        
      </nav>
    
    <div class="md-post__meta md-meta">
      <ul class="md-meta__list">
        <li class="md-meta__item">
          <time datetime="2020-04-18 00:00:00+00:00">2020-04-18</time></li>
        
          <li class="md-meta__item">
            in
            
              <a href="../../category/estadistica/" class="md-meta__link">estadistica</a></li>
        
        
          
          <li class="md-meta__item">
            
              5 min read
            
          </li>
        
      </ul>
      
    </div>
  </header>
  <div class="md-post__content md-typeset">
    <h2 id="proceso-poisson-y-distribucion-exponencial"><a class="toclink" href="../../2020/04/18/proceso-poisson-y-distribucion-exponencial/">Proceso Poisson y distribucion exponencial</a></h2>
<p>Basado en:<br />
<a href="https://stats.stackexchange.com/questions/2092/relationship-between-poisson-and-exponential-distribution">https://stats.stackexchange.com/questions/2092/relationship-between-poisson-and-exponential-distribution</a><br />
<a href="https://towardsdatascience.com/the-poisson-distribution-and-poisson-process-explained-4e2cb17d459">https://towardsdatascience.com/the-poisson-distribution-and-poisson-process-explained-4e2cb17d459</a></p>
<p>Un proceso que sigue un <em>proceso de Poisson</em> es aquel que tiene un cantidad de eventos promedio cada determinada unidad de medida (generalmente tiempo). Estos sucesos deben ser independientes y aleatorios pero la cantidad debe estar centrada alrededor del promedio ya mencionado. Una última condición es que dos sucesos no pueden suceder en simultáneo.</p>
<p>Para ejemplificar, podemos suponer que la cantidad de pacientes que llegan a la guardia de un hospital sigue un proceso de Poisson. </p>
<p>Un proceso Poisson se puede "descomponer" en 2 conceptos.  </p>
<ul>
<li>Una disitribución <strong>Poisson (no proceso!)</strong> que provee la función de densidad de la cantidad de pacientes que ingresan al hospital. (Discreta)</li>
<li>Una distribución <strong>exponencial</strong> que modela el tiempo que transcurre entre cada paciente. (Continua)</li>
</ul>
<h4 id="distribucion-poisson"><a class="toclink" href="../../2020/04/18/proceso-poisson-y-distribucion-exponencial/#distribucion-poisson">Distribución Poisson</a></h4>
<p>Esta distribución sirve para modelar la cantidad de pacientes. Digamos que ingresan en promedio <span class="arithmatex">\(\lambda\)</span> pacientes por <em>hora</em>.</p>
<p>La función de probabilidad (probability mass function en inglés ya que es discreta) es: 
<span class="arithmatex">\(<span class="arithmatex">\(P(K) = e^{-\lambda}\frac{\lambda^k}{k!}\)</span>\)</span></p>
<p>Donde K es la cantidad de pacientes en una hora y <span class="arithmatex">\(\lambda\)</span> es como dijimos,  la cantidad promedio que ingresa por hora.
La función nos dice qué probabilidad hay de recibir K pacientes en una hora si en general llegan <span class="arithmatex">\(\lambda\)</span>.</p>
<p>Distintos <span class="arithmatex">\(\lambda\)</span> devuelven obviamente distintas probabilidades para cada valor de K. Vemos que a medida que crece <span class="arithmatex">\(\lambda\)</span> la densidad se parece cada vez más a una normal.</p>
<div class="language-r highlight"><pre><span></span><code><span id="__span-4-1"><a id="__codelineno-4-1" name="__codelineno-4-1" href="#__codelineno-4-1"></a><span class="n">lambda</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">1</span><span class="p">,</span><span class="m">2</span><span class="p">,</span><span class="m">4</span><span class="p">,</span><span class="m">6</span><span class="p">,</span><span class="m">10</span><span class="p">)</span>
</span><span id="__span-4-2"><a id="__codelineno-4-2" name="__codelineno-4-2" href="#__codelineno-4-2"></a><span class="n">k</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">seq</span><span class="p">(</span><span class="m">0</span><span class="p">,</span><span class="nf">max</span><span class="p">(</span><span class="n">lambda</span><span class="p">)</span><span class="o">*</span><span class="m">1.5</span><span class="p">)</span>
</span><span id="__span-4-3"><a id="__codelineno-4-3" name="__codelineno-4-3" href="#__codelineno-4-3"></a><span class="n">df</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">expand.grid</span><span class="p">(</span><span class="n">lambda</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">as.factor</span><span class="p">(</span><span class="n">lambda</span><span class="p">),</span><span class="w"> </span><span class="n">k</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">k</span><span class="p">)</span><span class="w"> </span><span class="o">%&gt;%</span>
</span><span id="__span-4-4"><a id="__codelineno-4-4" name="__codelineno-4-4" href="#__codelineno-4-4"></a><span class="w">  </span><span class="nf">mutate</span><span class="p">(</span><span class="n">poisson</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">dpois</span><span class="p">(</span><span class="n">k</span><span class="p">,</span><span class="w"> </span><span class="nf">as.numeric</span><span class="p">(</span><span class="nf">as.character</span><span class="p">(</span><span class="n">lambda</span><span class="p">))))</span>
</span><span id="__span-4-5"><a id="__codelineno-4-5" name="__codelineno-4-5" href="#__codelineno-4-5"></a>
</span><span id="__span-4-6"><a id="__codelineno-4-6" name="__codelineno-4-6" href="#__codelineno-4-6"></a><span class="nf">ggplot</span><span class="p">(</span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">df</span><span class="p">,</span><span class="w"> </span><span class="nf">aes</span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">k</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="n">poisson</span><span class="p">,</span><span class="w"> </span><span class="n">colour</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">lambda</span><span class="p">))</span><span class="w"> </span><span class="o">+</span><span class="w"> </span>
</span><span id="__span-4-7"><a id="__codelineno-4-7" name="__codelineno-4-7" href="#__codelineno-4-7"></a><span class="w">  </span><span class="nf">geom_line</span><span class="p">()</span><span class="w"> </span><span class="o">+</span><span class="w"> </span>
</span><span id="__span-4-8"><a id="__codelineno-4-8" name="__codelineno-4-8" href="#__codelineno-4-8"></a><span class="w">  </span><span class="nf">geom_point</span><span class="p">()</span><span class="w"> </span><span class="o">+</span><span class="w"> </span>
</span><span id="__span-4-9"><a id="__codelineno-4-9" name="__codelineno-4-9" href="#__codelineno-4-9"></a><span class="w">  </span><span class="nf">ggtitle</span><span class="p">(</span><span class="s">&quot;Probabilidad por intervalo (1 hora)&quot;</span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
</span><span id="__span-4-10"><a id="__codelineno-4-10" name="__codelineno-4-10" href="#__codelineno-4-10"></a><span class="w">  </span><span class="nf">xlab</span><span class="p">(</span><span class="s">&quot;Cantidad K de pacientes&quot;</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span>
</span><span id="__span-4-11"><a id="__codelineno-4-11" name="__codelineno-4-11" href="#__codelineno-4-11"></a><span class="w">  </span><span class="nf">ylab</span><span class="p">(</span><span class="s">&quot;&quot;</span><span class="p">)</span>
</span></code></pre></div>
<p><img alt="Image" src="../../img/2020-04-18-proceso-poisson-y-distribucion-exponencial-unnamed-chunk-2-1.png" /></p>
<p><span class="arithmatex">\(\lambda\)</span> determina la forma de la dsitribución y como es de esperar, esta se centra alrededor del parámetro ya que es la cantidad promedio en el intervalo. Una propiedad interesante es que la varianza de la disitribución también es <span class="arithmatex">\(\lambda\)</span>.<br />
Los pacientes que llegan al hospital siguen una distribución <span class="arithmatex">\(\sim  P(\lambda)\)</span>.</p>
<p>Otra caracterísica es que uno puede escalar la distribución para cualquier intervalo. Es decir que si nuestro modelo era para cantidad de pacientes por hora, uno puede multiplicar <span class="arithmatex">\(\lambda\)</span> por 3 si quiere la distribución cada 3 horas, o dividir por 6 si la quiere cada 10 minutos por ejemplo. Esto es asi porque en realidad en la función de probabilidad de la distribución Poisson, <span class="arithmatex">\(\lambda\)</span> está multiplicado por el intervalo <em>t</em>,pero se simplifica y se lo asume 1. Luego uno puede derivar para el lapso que desee multiplicando.</p>
<h4 id="distribucion-exponencial"><a class="toclink" href="../../2020/04/18/proceso-poisson-y-distribucion-exponencial/#distribucion-exponencial">Distribución Exponencial</a></h4>
<p>Sabemos que llegan <span class="arithmatex">\(\lambda\)</span> pacientes por hora. Nos gustaría ahora saber la distribución para el tiempo de espera hasta que llegue el próximo paciente. Es decir, parados en el momento <em>t</em>, qué probabilidad hay de tener que esperar un minuto, 2, 10 hasta el próximo paciente?</p>
<p>El concepto es el siguiente. Si queremos saber la probabilidad de que haya que esperar al menos X minutos, es lo mismo que calcular la probabilidad de que la cantidad de pacientes en el momento t+x sea igual a la cantidad de momento t. Es decir, que no haya llegado nadie.<br />
<span class="arithmatex">\(N_{t+x} = N_{t}\)</span>.  </p>
<p>Podemos calcular eso con la distribución Poisson. Es simplemente la probabilidad de 0 pacientes en un intervalo x.</p>
<p>$$P(N_{t+x} - N_t = 0) = e^{-\lambda x}\frac{\lambda x^0}{0!} = e^{-\lambda x} $$
La probabilidad de obtener un nuevo paciente en el intervalo x es 1 menos la probabilidad de no obtener ninguno,  por lo tanto:
$$ P(X_t \leq x) = 1 -  P(N_{t+x} - N_t = 0) = 1 - e^{-\lambda x}$$
Este último resultado es la <strong>función de probabilidad acumulada de la exponencial</strong>. La probabilidad de tener que esperar X o menos minutos depende de <span class="arithmatex">\(\lambda\)</span> y x.</p>
<p>Con la derivada obtenemos la <strong>Función de distribución de la exponencial</strong>.
<span class="arithmatex">\(<span class="arithmatex">\(f(x, \lambda) = \lambda e^{-\lambda x}\)</span>\)</span></p>
<p>Si al hospital llegaran 10 personas por hora a la guardia, tendríamos la siguiente función de densidad de la exponencial.
Tener en cuenta que <span class="arithmatex">\(\lambda\)</span> = 10 en la poisson (10 casos por unidad de tiempo (hora)), sin embargo, en la exponencial queremos medirlo en minutos, por lo que usamos un <span class="arithmatex">\(\lambda\)</span> de 10/60.</p>
<div class="language-r highlight"><pre><span></span><code><span id="__span-5-1"><a id="__codelineno-5-1" name="__codelineno-5-1" href="#__codelineno-5-1"></a><span class="n">lambda</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">10</span><span class="p">)</span>
</span><span id="__span-5-2"><a id="__codelineno-5-2" name="__codelineno-5-2" href="#__codelineno-5-2"></a><span class="n">t</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">seq</span><span class="p">(</span><span class="m">0</span><span class="p">,</span><span class="m">30</span><span class="p">,</span><span class="w"> </span><span class="n">by</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1</span><span class="p">)</span>
</span><span id="__span-5-3"><a id="__codelineno-5-3" name="__codelineno-5-3" href="#__codelineno-5-3"></a><span class="n">df2</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">expand.grid</span><span class="p">(</span><span class="n">lambda</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">as.factor</span><span class="p">(</span><span class="n">lambda</span><span class="p">),</span><span class="w"> </span><span class="n">t</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">t</span><span class="p">)</span><span class="w"> </span><span class="o">%&gt;%</span>
</span><span id="__span-5-4"><a id="__codelineno-5-4" name="__codelineno-5-4" href="#__codelineno-5-4"></a><span class="w">  </span><span class="nf">mutate</span><span class="p">(</span><span class="n">exponencial</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">dexp</span><span class="p">(</span><span class="n">t</span><span class="p">,</span><span class="w"> </span><span class="nf">as.numeric</span><span class="p">(</span><span class="nf">as.character</span><span class="p">(</span><span class="n">lambda</span><span class="p">))</span><span class="o">/</span><span class="m">60</span><span class="p">))</span>
</span><span id="__span-5-5"><a id="__codelineno-5-5" name="__codelineno-5-5" href="#__codelineno-5-5"></a>
</span><span id="__span-5-6"><a id="__codelineno-5-6" name="__codelineno-5-6" href="#__codelineno-5-6"></a><span class="nf">ggplot</span><span class="p">(</span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">df2</span><span class="p">,</span><span class="w"> </span><span class="nf">aes</span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">t</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="n">exponencial</span><span class="p">))</span><span class="w"> </span><span class="o">+</span><span class="w"> </span>
</span><span id="__span-5-7"><a id="__codelineno-5-7" name="__codelineno-5-7" href="#__codelineno-5-7"></a><span class="w">  </span><span class="nf">geom_line</span><span class="p">(</span><span class="n">colour</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;red&quot;</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span>
</span><span id="__span-5-8"><a id="__codelineno-5-8" name="__codelineno-5-8" href="#__codelineno-5-8"></a><span class="w">  </span><span class="nf">geom_point</span><span class="p">(</span><span class="n">colour</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;red&quot;</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span>
</span><span id="__span-5-9"><a id="__codelineno-5-9" name="__codelineno-5-9" href="#__codelineno-5-9"></a><span class="w">  </span><span class="nf">ggtitle</span><span class="p">(</span><span class="s">&quot;Función de densidad de distribución exponencial: lambda = 10/60&quot;</span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
</span><span id="__span-5-10"><a id="__codelineno-5-10" name="__codelineno-5-10" href="#__codelineno-5-10"></a><span class="w">  </span><span class="nf">xlab</span><span class="p">(</span><span class="s">&quot;Minutos&quot;</span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
</span><span id="__span-5-11"><a id="__codelineno-5-11" name="__codelineno-5-11" href="#__codelineno-5-11"></a><span class="w">  </span><span class="nf">ylab</span><span class="p">(</span><span class="s">&quot;Densidad&quot;</span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
</span><span id="__span-5-12"><a id="__codelineno-5-12" name="__codelineno-5-12" href="#__codelineno-5-12"></a><span class="w">  </span><span class="nf">scale_x_continuous</span><span class="p">(</span><span class="n">breaks</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">seq</span><span class="p">(</span><span class="m">0</span><span class="p">,</span><span class="m">30</span><span class="p">,</span><span class="w"> </span><span class="n">by</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">5</span><span class="p">))</span>
</span></code></pre></div>
<p><img alt="Image" src="../../img/2020-04-18-proceso-poisson-y-distribucion-exponencial-unnamed-chunk-3-1.png" /></p>
<p>Por otro lado podemos ver la probabilidad acumulada hasta determinado minuto. Siguiendo el mismo ejemplo de 10 pacientes por hora (Poisson con <span class="arithmatex">\(\lambda = 10\)</span>), la acumulada de la distribución exponencial tiene la siguiente forma.</p>
<p><em>Hay alrededor de 80% de chances que un paciente llegue en los próximos 10 minutos.</em></p>
<div class="language-r highlight"><pre><span></span><code><span id="__span-6-1"><a id="__codelineno-6-1" name="__codelineno-6-1" href="#__codelineno-6-1"></a><span class="n">lambda</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">10</span><span class="p">)</span>
</span><span id="__span-6-2"><a id="__codelineno-6-2" name="__codelineno-6-2" href="#__codelineno-6-2"></a><span class="n">t</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">seq</span><span class="p">(</span><span class="m">0</span><span class="p">,</span><span class="nf">max</span><span class="p">(</span><span class="n">lambda</span><span class="p">)</span><span class="o">*</span><span class="m">3</span><span class="p">,</span><span class="w"> </span><span class="n">by</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1</span><span class="p">)</span>
</span><span id="__span-6-3"><a id="__codelineno-6-3" name="__codelineno-6-3" href="#__codelineno-6-3"></a><span class="n">df2</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">expand.grid</span><span class="p">(</span><span class="n">lambda</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">as.factor</span><span class="p">(</span><span class="n">lambda</span><span class="p">),</span><span class="w"> </span><span class="n">t</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">t</span><span class="p">)</span><span class="w"> </span><span class="o">%&gt;%</span>
</span><span id="__span-6-4"><a id="__codelineno-6-4" name="__codelineno-6-4" href="#__codelineno-6-4"></a><span class="w">  </span><span class="nf">mutate</span><span class="p">(</span><span class="n">exponencial</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">pexp</span><span class="p">(</span><span class="n">t</span><span class="p">,</span><span class="w"> </span><span class="nf">as.numeric</span><span class="p">(</span><span class="nf">as.character</span><span class="p">(</span><span class="n">lambda</span><span class="p">))</span><span class="o">/</span><span class="m">60</span><span class="p">))</span>
</span><span id="__span-6-5"><a id="__codelineno-6-5" name="__codelineno-6-5" href="#__codelineno-6-5"></a>
</span><span id="__span-6-6"><a id="__codelineno-6-6" name="__codelineno-6-6" href="#__codelineno-6-6"></a><span class="nf">ggplot</span><span class="p">(</span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">df2</span><span class="p">,</span><span class="w"> </span><span class="nf">aes</span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">t</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="n">exponencial</span><span class="p">))</span><span class="w"> </span><span class="o">+</span><span class="w"> </span>
</span><span id="__span-6-7"><a id="__codelineno-6-7" name="__codelineno-6-7" href="#__codelineno-6-7"></a><span class="w">  </span><span class="nf">geom_line</span><span class="p">(</span><span class="n">colour</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;blue&quot;</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span>
</span><span id="__span-6-8"><a id="__codelineno-6-8" name="__codelineno-6-8" href="#__codelineno-6-8"></a><span class="w">  </span><span class="nf">geom_point</span><span class="p">()</span><span class="w"> </span><span class="o">+</span><span class="w"> </span>
</span><span id="__span-6-9"><a id="__codelineno-6-9" name="__codelineno-6-9" href="#__codelineno-6-9"></a><span class="w">  </span><span class="nf">ggtitle</span><span class="p">(</span><span class="s">&quot;Probabilidad de tener que esperar X minutos o menos&quot;</span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
</span><span id="__span-6-10"><a id="__codelineno-6-10" name="__codelineno-6-10" href="#__codelineno-6-10"></a><span class="w">  </span><span class="nf">xlab</span><span class="p">(</span><span class="s">&quot;Minutos&quot;</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span>
</span><span id="__span-6-11"><a id="__codelineno-6-11" name="__codelineno-6-11" href="#__codelineno-6-11"></a><span class="w">  </span><span class="nf">ylab</span><span class="p">(</span><span class="s">&quot;&quot;</span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
</span><span id="__span-6-12"><a id="__codelineno-6-12" name="__codelineno-6-12" href="#__codelineno-6-12"></a><span class="w">  </span><span class="nf">scale_x_continuous</span><span class="p">(</span><span class="n">breaks</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">seq</span><span class="p">(</span><span class="m">0</span><span class="p">,</span><span class="m">30</span><span class="p">,</span><span class="w"> </span><span class="n">by</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">5</span><span class="p">))</span>
</span></code></pre></div>
<p><img alt="Image" src="../../img/2020-04-18-proceso-poisson-y-distribucion-exponencial-unnamed-chunk-4-1.png" /></p>
<p>Por último, si lo quieren ver al revés. Podemos ver la probabilidad de tener que esperar al menos X minutos para que llegue el próximo.</p>
<p><em>Hay alrededor de 5% de chances de tener que esperar 20 minutos hasta el próximo paciente</em></p>
<div class="language-r highlight"><pre><span></span><code><span id="__span-7-1"><a id="__codelineno-7-1" name="__codelineno-7-1" href="#__codelineno-7-1"></a><span class="n">lambda</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">10</span><span class="p">)</span>
</span><span id="__span-7-2"><a id="__codelineno-7-2" name="__codelineno-7-2" href="#__codelineno-7-2"></a><span class="n">t</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">seq</span><span class="p">(</span><span class="m">0</span><span class="p">,</span><span class="nf">max</span><span class="p">(</span><span class="n">lambda</span><span class="p">)</span><span class="o">*</span><span class="m">3</span><span class="p">,</span><span class="w"> </span><span class="n">by</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1</span><span class="p">)</span>
</span><span id="__span-7-3"><a id="__codelineno-7-3" name="__codelineno-7-3" href="#__codelineno-7-3"></a><span class="n">df2</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">expand.grid</span><span class="p">(</span><span class="n">lambda</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">as.factor</span><span class="p">(</span><span class="n">lambda</span><span class="p">),</span><span class="w"> </span><span class="n">t</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">t</span><span class="p">)</span><span class="w"> </span><span class="o">%&gt;%</span>
</span><span id="__span-7-4"><a id="__codelineno-7-4" name="__codelineno-7-4" href="#__codelineno-7-4"></a><span class="w">  </span><span class="nf">mutate</span><span class="p">(</span><span class="n">exponencial</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">pexp</span><span class="p">(</span><span class="n">t</span><span class="p">,</span><span class="w"> </span><span class="nf">as.numeric</span><span class="p">(</span><span class="nf">as.character</span><span class="p">(</span><span class="n">lambda</span><span class="p">))</span><span class="o">/</span><span class="m">60</span><span class="p">,</span><span class="w"> </span><span class="n">lower.tail</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">FALSE</span><span class="p">))</span>
</span><span id="__span-7-5"><a id="__codelineno-7-5" name="__codelineno-7-5" href="#__codelineno-7-5"></a>
</span><span id="__span-7-6"><a id="__codelineno-7-6" name="__codelineno-7-6" href="#__codelineno-7-6"></a><span class="nf">ggplot</span><span class="p">(</span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">df2</span><span class="p">,</span><span class="w"> </span><span class="nf">aes</span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">t</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="n">exponencial</span><span class="p">))</span><span class="w"> </span><span class="o">+</span><span class="w"> </span>
</span><span id="__span-7-7"><a id="__codelineno-7-7" name="__codelineno-7-7" href="#__codelineno-7-7"></a><span class="w">  </span><span class="nf">geom_line</span><span class="p">(</span><span class="n">colour</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;darkgreen&quot;</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span>
</span><span id="__span-7-8"><a id="__codelineno-7-8" name="__codelineno-7-8" href="#__codelineno-7-8"></a><span class="w">  </span><span class="nf">geom_point</span><span class="p">()</span><span class="w"> </span><span class="o">+</span><span class="w"> </span>
</span><span id="__span-7-9"><a id="__codelineno-7-9" name="__codelineno-7-9" href="#__codelineno-7-9"></a><span class="w">  </span><span class="nf">ggtitle</span><span class="p">(</span><span class="s">&quot;Probabilidad de tener que esperar al menos X minutos&quot;</span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
</span><span id="__span-7-10"><a id="__codelineno-7-10" name="__codelineno-7-10" href="#__codelineno-7-10"></a><span class="w">  </span><span class="nf">xlab</span><span class="p">(</span><span class="s">&quot;Minutos&quot;</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span>
</span><span id="__span-7-11"><a id="__codelineno-7-11" name="__codelineno-7-11" href="#__codelineno-7-11"></a><span class="w">  </span><span class="nf">ylab</span><span class="p">(</span><span class="s">&quot;&quot;</span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
</span><span id="__span-7-12"><a id="__codelineno-7-12" name="__codelineno-7-12" href="#__codelineno-7-12"></a><span class="w">  </span><span class="nf">scale_x_continuous</span><span class="p">(</span><span class="n">breaks</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">seq</span><span class="p">(</span><span class="m">0</span><span class="p">,</span><span class="m">30</span><span class="p">,</span><span class="w"> </span><span class="n">by</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">5</span><span class="p">))</span><span class="w"> </span><span class="o">+</span><span class="w"> </span>
</span><span id="__span-7-13"><a id="__codelineno-7-13" name="__codelineno-7-13" href="#__codelineno-7-13"></a><span class="w">  </span><span class="nf">scale_y_continuous</span><span class="p">(</span><span class="n">breaks</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">seq</span><span class="p">(</span><span class="m">0</span><span class="p">,</span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="n">by</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.1</span><span class="p">))</span>
</span></code></pre></div>
<p><img alt="Image" src="../../img/2020-04-18-proceso-poisson-y-distribucion-exponencial-unnamed-chunk-5-1.png" /></p>
    
  </div>
</article>
      
        <article class="md-post md-post--excerpt">
  <header class="md-post__header">
    
      <nav class="md-post__authors md-typeset">
        
          <span class="md-author">
            <img src="https://media.licdn.com/dms/image/v2/D4D03AQGGiT9NDiLy7Q/profile-displayphoto-shrink_200_200/profile-displayphoto-shrink_200_200/0/1681511830071?e=1738195200&v=beta&t=Nd1WNLQTxHfCe7dT9BBaQYgaYtEHFCOPpntpImC4Lz8" alt="Franco Betteo">
          </span>
        
      </nav>
    
    <div class="md-post__meta md-meta">
      <ul class="md-meta__list">
        <li class="md-meta__item">
          <time datetime="2019-11-11 00:00:00+00:00">2019-11-11</time></li>
        
          <li class="md-meta__item">
            in
            
              <a href="../../category/algebra/" class="md-meta__link">algebra</a>, 
              <a href="../../category/estadistica/" class="md-meta__link">estadistica</a>, 
              <a href="../../category/matematica/" class="md-meta__link">matematica</a></li>
        
        
          
          <li class="md-meta__item">
            
              7 min read
            
          </li>
        
      </ul>
      
    </div>
  </header>
  <div class="md-post__content md-typeset">
    <h2 id="distintas-distancias"><a class="toclink" href="../../2019/11/11/distintas-distancias/">Distintas Distancias</a></h2>
<div class="language-r highlight"><pre><span></span><code><span id="__span-51-1"><a id="__codelineno-51-1" name="__codelineno-51-1" href="#__codelineno-51-1"></a><span class="nf">library</span><span class="p">(</span><span class="n">tidyverse</span><span class="p">)</span>
</span></code></pre></div>
<p>Si tenemos un espacio euclideo, es decir, una linea, un plano o un hiperplano, que son los espacios
típicos de la geometría clásica, podemos calcular la distancia entre dos puntos que se hayen en él.</p>
<p>Es decir, cuál es la distancia entre los puntos A (1,1) y B (1,0) en un plano?
Empecemos pensando en los casos donde todos los valores del vector son numéricos.</p>
<div class="language-r highlight"><pre><span></span><code><span id="__span-52-1"><a id="__codelineno-52-1" name="__codelineno-52-1" href="#__codelineno-52-1"></a><span class="n">A</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">0</span><span class="p">,</span><span class="m">0</span><span class="p">,</span><span class="m">1</span><span class="p">,</span><span class="m">1</span><span class="p">)</span>
</span><span id="__span-52-2"><a id="__codelineno-52-2" name="__codelineno-52-2" href="#__codelineno-52-2"></a><span class="n">B</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">0</span><span class="p">,</span><span class="m">0</span><span class="p">,</span><span class="m">1</span><span class="p">,</span><span class="m">0</span><span class="p">)</span>
</span><span id="__span-52-3"><a id="__codelineno-52-3" name="__codelineno-52-3" href="#__codelineno-52-3"></a><span class="n">recta</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">1</span><span class="p">,</span><span class="m">1</span><span class="p">,</span><span class="m">1</span><span class="p">,</span><span class="m">0</span><span class="p">)</span>
</span><span id="__span-52-4"><a id="__codelineno-52-4" name="__codelineno-52-4" href="#__codelineno-52-4"></a><span class="n">df</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">as.data.frame</span><span class="p">(</span><span class="nf">matrix</span><span class="p">(</span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="n">A</span><span class="p">,</span><span class="n">B</span><span class="p">,</span><span class="w"> </span><span class="n">recta</span><span class="p">),</span>
</span><span id="__span-52-5"><a id="__codelineno-52-5" name="__codelineno-52-5" href="#__codelineno-52-5"></a><span class="w">                          </span><span class="n">nrow</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">4</span><span class="p">,</span><span class="w"> </span>
</span><span id="__span-52-6"><a id="__codelineno-52-6" name="__codelineno-52-6" href="#__codelineno-52-6"></a><span class="w">                          </span><span class="n">ncol</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">4</span><span class="p">,</span>
</span><span id="__span-52-7"><a id="__codelineno-52-7" name="__codelineno-52-7" href="#__codelineno-52-7"></a><span class="w">                          </span><span class="n">byrow</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="w"> </span><span class="p">))</span><span class="w"> </span><span class="o">%&gt;%</span>
</span><span id="__span-52-8"><a id="__codelineno-52-8" name="__codelineno-52-8" href="#__codelineno-52-8"></a><span class="w">  </span><span class="nf">rename</span><span class="p">(</span><span class="w"> </span><span class="n">x0</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">V1</span><span class="p">,</span>
</span><span id="__span-52-9"><a id="__codelineno-52-9" name="__codelineno-52-9" href="#__codelineno-52-9"></a><span class="w">          </span><span class="n">y0</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">V2</span><span class="p">,</span>
</span><span id="__span-52-10"><a id="__codelineno-52-10" name="__codelineno-52-10" href="#__codelineno-52-10"></a><span class="w">          </span><span class="n">x1</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">V3</span><span class="p">,</span>
</span><span id="__span-52-11"><a id="__codelineno-52-11" name="__codelineno-52-11" href="#__codelineno-52-11"></a><span class="w">          </span><span class="n">y1</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">V4</span><span class="p">)</span>
</span><span id="__span-52-12"><a id="__codelineno-52-12" name="__codelineno-52-12" href="#__codelineno-52-12"></a>
</span><span id="__span-52-13"><a id="__codelineno-52-13" name="__codelineno-52-13" href="#__codelineno-52-13"></a>
</span><span id="__span-52-14"><a id="__codelineno-52-14" name="__codelineno-52-14" href="#__codelineno-52-14"></a><span class="nf">ggplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">[</span><span class="m">1</span><span class="o">:</span><span class="m">2</span><span class="p">,],</span><span class="w"> </span><span class="nf">aes</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">x0</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="o">=</span><span class="n">y0</span><span class="p">))</span><span class="w"> </span><span class="o">+</span><span class="w"> </span>
</span><span id="__span-52-15"><a id="__codelineno-52-15" name="__codelineno-52-15" href="#__codelineno-52-15"></a><span class="w">  </span><span class="nf">geom_segment</span><span class="p">(</span><span class="nf">aes</span><span class="p">(</span><span class="n">xend</span><span class="o">=</span><span class="n">x1</span><span class="p">,</span><span class="w"> </span><span class="n">yend</span><span class="o">=</span><span class="n">y1</span><span class="p">),</span>
</span><span id="__span-52-16"><a id="__codelineno-52-16" name="__codelineno-52-16" href="#__codelineno-52-16"></a><span class="w">               </span><span class="n">arrow</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">arrow</span><span class="p">(</span><span class="n">length</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">unit</span><span class="p">(</span><span class="m">0.3</span><span class="p">,</span><span class="s">&quot;cm&quot;</span><span class="p">)))</span><span class="w"> </span><span class="o">+</span><span class="w"> </span>
</span><span id="__span-52-17"><a id="__codelineno-52-17" name="__codelineno-52-17" href="#__codelineno-52-17"></a><span class="w">  </span><span class="nf">geom_point</span><span class="p">(</span><span class="w"> </span><span class="nf">aes</span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">x1</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">y1</span><span class="p">),</span><span class="w"> </span>
</span><span id="__span-52-18"><a id="__codelineno-52-18" name="__codelineno-52-18" href="#__codelineno-52-18"></a><span class="w">              </span><span class="n">color</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;red&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">2</span><span class="p">)</span>
</span></code></pre></div>
<p><img alt="Image" src="../../img/2019-11-11-distintas-distancias-unnamed-chunk-2-1.png" /></p>
<h4 id="distancia-euclideana"><a class="toclink" href="../../2019/11/11/distintas-distancias/#distancia-euclideana">Distancia Euclideana</a></h4>
<p>La métrica más habitual que se utiliza es la distancia euclideana, que consiste en la recta que une ambos puntos. </p>
<div class="language-r highlight"><pre><span></span><code><span id="__span-53-1"><a id="__codelineno-53-1" name="__codelineno-53-1" href="#__codelineno-53-1"></a><span class="nf">ggplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">[</span><span class="m">1</span><span class="o">:</span><span class="m">2</span><span class="p">,],</span><span class="w"> </span><span class="nf">aes</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">x0</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="o">=</span><span class="n">y0</span><span class="p">))</span><span class="o">+</span>
</span><span id="__span-53-2"><a id="__codelineno-53-2" name="__codelineno-53-2" href="#__codelineno-53-2"></a><span class="w">  </span><span class="nf">geom_segment</span><span class="p">(</span><span class="nf">aes</span><span class="p">(</span><span class="n">xend</span><span class="o">=</span><span class="n">x1</span><span class="p">,</span><span class="w"> </span><span class="n">yend</span><span class="o">=</span><span class="n">y1</span><span class="p">),</span>
</span><span id="__span-53-3"><a id="__codelineno-53-3" name="__codelineno-53-3" href="#__codelineno-53-3"></a><span class="w">               </span><span class="n">arrow</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">arrow</span><span class="p">(</span><span class="n">length</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">unit</span><span class="p">(</span><span class="m">0.3</span><span class="p">,</span><span class="s">&quot;cm&quot;</span><span class="p">)))</span><span class="w"> </span><span class="o">+</span><span class="w"> </span>
</span><span id="__span-53-4"><a id="__codelineno-53-4" name="__codelineno-53-4" href="#__codelineno-53-4"></a><span class="w">  </span><span class="nf">geom_point</span><span class="p">(</span><span class="nf">aes</span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">x1</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">y1</span><span class="p">),</span><span class="w"> </span>
</span><span id="__span-53-5"><a id="__codelineno-53-5" name="__codelineno-53-5" href="#__codelineno-53-5"></a><span class="w">               </span><span class="n">color</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;red&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">2</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span>
</span><span id="__span-53-6"><a id="__codelineno-53-6" name="__codelineno-53-6" href="#__codelineno-53-6"></a><span class="w">  </span><span class="nf">geom_segment</span><span class="p">(</span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">df</span><span class="p">[</span><span class="m">3</span><span class="p">,],</span><span class="w"> </span>
</span><span id="__span-53-7"><a id="__codelineno-53-7" name="__codelineno-53-7" href="#__codelineno-53-7"></a><span class="w">               </span><span class="nf">aes</span><span class="p">(</span><span class="n">xend</span><span class="o">=</span><span class="n">x1</span><span class="p">,</span><span class="w"> </span><span class="n">yend</span><span class="o">=</span><span class="n">y1</span><span class="p">),</span>
</span><span id="__span-53-8"><a id="__codelineno-53-8" name="__codelineno-53-8" href="#__codelineno-53-8"></a><span class="w">               </span><span class="n">color</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;blue&quot;</span><span class="p">,</span><span class="w"> </span>
</span><span id="__span-53-9"><a id="__codelineno-53-9" name="__codelineno-53-9" href="#__codelineno-53-9"></a><span class="w">               </span><span class="n">arrow</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">arrow</span><span class="p">(</span><span class="n">length</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">unit</span><span class="p">(</span><span class="m">0.3</span><span class="p">,</span><span class="s">&quot;cm&quot;</span><span class="p">)))</span>
</span></code></pre></div>
<p><img alt="Image" src="../../img/2019-11-11-distintas-distancias-unnamed-chunk-3-1.png" /></p>
<p>Esta distancia se calcula con:<br />
<span class="arithmatex">\(<span class="arithmatex">\(d(A,B) = d(B,A) = \sqrt{(A_1 - B_1)^2 + (A_2 - B_2)^2 + ... + (A_n - B_n)^2}  
= \sqrt{\sum_{i=1}^n (A_i - B_i)^2}\)</span>\)</span></p>
<p>Como se ve en la imagen, los puntos A y B pueden verse como vectores que inician en el origen (0,0). La distancia euclidea es a su vez la distancia entre sus puntas, que a su vez puede pensarse como un vector de desplazamiento (de A a B por ejemplo).</p>
<p>En este caso la distancia euclidea es:
<span class="arithmatex">\(<span class="arithmatex">\(d(A,B) = \sqrt{ (1-1)^2 + (1 - 0)^2} = 1\)</span>\)</span>
Y que es algo visible en el gráfico.</p>
<p>De manera más general, podemos definir toda una familia de distancias en el espacio euclideo.
<em>Las distancias de Minkowsky.</em></p>
<p>La distancia Minkowsky de orden p es:
<span class="arithmatex">\(<span class="arithmatex">\(d(A,B) = d(B,A) = \Bigg({\sum_{i=1}^n |A_i - B_i|^p}\Bigg)^{1/p}\)</span>\)</span></p>
<p>Vemos que si p = 2, entonces la distancia de Minkowsky no es otra que la distancia euclideana.</p>
<h4 id="distancia-de-manhattan"><a class="toclink" href="../../2019/11/11/distintas-distancias/#distancia-de-manhattan">Distancia de Manhattan</a></h4>
<p>Otro valor que suele tomarse para p es p = 1, y eso corresponde a la <em>distancia de Manhattan</em>.</p>
<p>Esta distancia se calcula con:<br />
<span class="arithmatex">\(<span class="arithmatex">\(d(A,B) = d(B,A) =  |A_1 - B_1| + |A_2 - B_2| + ... + |A_n - B_n|  
=\sum_{i=1}^n |A_i - B_i|\)</span>\)</span></p>
<p>Es básicamente la suma de las diferencias absolutas entre las distintas dimensiones de los vectores.</p>
<p>Luce asi.</p>
<div class="language-r highlight"><pre><span></span><code><span id="__span-54-1"><a id="__codelineno-54-1" name="__codelineno-54-1" href="#__codelineno-54-1"></a><span class="n">A</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">0</span><span class="p">,</span><span class="m">0</span><span class="p">,</span><span class="m">3</span><span class="p">,</span><span class="m">3</span><span class="p">)</span>
</span><span id="__span-54-2"><a id="__codelineno-54-2" name="__codelineno-54-2" href="#__codelineno-54-2"></a><span class="n">B</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">0</span><span class="p">,</span><span class="m">0</span><span class="p">,</span><span class="m">2</span><span class="p">,</span><span class="m">1</span><span class="p">)</span>
</span><span id="__span-54-3"><a id="__codelineno-54-3" name="__codelineno-54-3" href="#__codelineno-54-3"></a><span class="n">recta</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">2</span><span class="p">,</span><span class="m">1</span><span class="p">,</span><span class="m">3</span><span class="p">,</span><span class="m">3</span><span class="p">)</span>
</span><span id="__span-54-4"><a id="__codelineno-54-4" name="__codelineno-54-4" href="#__codelineno-54-4"></a><span class="n">manhattan1</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">2</span><span class="p">,</span><span class="m">1</span><span class="p">,</span><span class="m">3</span><span class="p">,</span><span class="m">1</span><span class="p">)</span>
</span><span id="__span-54-5"><a id="__codelineno-54-5" name="__codelineno-54-5" href="#__codelineno-54-5"></a><span class="n">manhattan2</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">3</span><span class="p">,</span><span class="m">1</span><span class="p">,</span><span class="m">3</span><span class="p">,</span><span class="m">3</span><span class="p">)</span>
</span><span id="__span-54-6"><a id="__codelineno-54-6" name="__codelineno-54-6" href="#__codelineno-54-6"></a>
</span><span id="__span-54-7"><a id="__codelineno-54-7" name="__codelineno-54-7" href="#__codelineno-54-7"></a><span class="n">df</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">as.data.frame</span><span class="p">(</span><span class="nf">matrix</span><span class="p">(</span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="n">A</span><span class="p">,</span><span class="n">B</span><span class="p">,</span><span class="w"> </span><span class="n">recta</span><span class="p">,</span><span class="w"> </span><span class="n">manhattan1</span><span class="p">,</span><span class="w"> </span><span class="n">manhattan2</span><span class="p">),</span>
</span><span id="__span-54-8"><a id="__codelineno-54-8" name="__codelineno-54-8" href="#__codelineno-54-8"></a><span class="w">                          </span><span class="n">nrow</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">5</span><span class="p">,</span><span class="w"> </span>
</span><span id="__span-54-9"><a id="__codelineno-54-9" name="__codelineno-54-9" href="#__codelineno-54-9"></a><span class="w">                          </span><span class="n">ncol</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">4</span><span class="p">,</span>
</span><span id="__span-54-10"><a id="__codelineno-54-10" name="__codelineno-54-10" href="#__codelineno-54-10"></a><span class="w">                          </span><span class="n">byrow</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="w"> </span><span class="p">))</span><span class="w"> </span><span class="o">%&gt;%</span>
</span><span id="__span-54-11"><a id="__codelineno-54-11" name="__codelineno-54-11" href="#__codelineno-54-11"></a><span class="w">  </span><span class="nf">rename</span><span class="p">(</span><span class="w"> </span><span class="n">x0</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">V1</span><span class="p">,</span>
</span><span id="__span-54-12"><a id="__codelineno-54-12" name="__codelineno-54-12" href="#__codelineno-54-12"></a><span class="w">          </span><span class="n">y0</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">V2</span><span class="p">,</span>
</span><span id="__span-54-13"><a id="__codelineno-54-13" name="__codelineno-54-13" href="#__codelineno-54-13"></a><span class="w">          </span><span class="n">x1</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">V3</span><span class="p">,</span>
</span><span id="__span-54-14"><a id="__codelineno-54-14" name="__codelineno-54-14" href="#__codelineno-54-14"></a><span class="w">          </span><span class="n">y1</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">V4</span><span class="p">)</span>
</span><span id="__span-54-15"><a id="__codelineno-54-15" name="__codelineno-54-15" href="#__codelineno-54-15"></a>
</span><span id="__span-54-16"><a id="__codelineno-54-16" name="__codelineno-54-16" href="#__codelineno-54-16"></a>
</span><span id="__span-54-17"><a id="__codelineno-54-17" name="__codelineno-54-17" href="#__codelineno-54-17"></a><span class="nf">ggplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">[</span><span class="m">1</span><span class="o">:</span><span class="m">2</span><span class="p">,],</span><span class="w"> </span><span class="nf">aes</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">x0</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="o">=</span><span class="n">y0</span><span class="p">))</span><span class="w"> </span><span class="o">+</span><span class="w"> </span>
</span><span id="__span-54-18"><a id="__codelineno-54-18" name="__codelineno-54-18" href="#__codelineno-54-18"></a><span class="w">    </span><span class="nf">geom_point</span><span class="p">(</span><span class="w"> </span><span class="nf">aes</span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">x1</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">y1</span><span class="p">),</span><span class="w"> </span>
</span><span id="__span-54-19"><a id="__codelineno-54-19" name="__codelineno-54-19" href="#__codelineno-54-19"></a><span class="w">              </span><span class="n">color</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;red&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">2</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span>
</span><span id="__span-54-20"><a id="__codelineno-54-20" name="__codelineno-54-20" href="#__codelineno-54-20"></a><span class="w">      </span><span class="nf">geom_segment</span><span class="p">(</span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">df</span><span class="p">[</span><span class="m">3</span><span class="p">,],</span><span class="w"> </span>
</span><span id="__span-54-21"><a id="__codelineno-54-21" name="__codelineno-54-21" href="#__codelineno-54-21"></a><span class="w">               </span><span class="nf">aes</span><span class="p">(</span><span class="n">xend</span><span class="o">=</span><span class="n">x1</span><span class="p">,</span><span class="w"> </span><span class="n">yend</span><span class="o">=</span><span class="n">y1</span><span class="p">,</span><span class="w"> </span><span class="n">color</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;blue&quot;</span><span class="p">),</span>
</span><span id="__span-54-22"><a id="__codelineno-54-22" name="__codelineno-54-22" href="#__codelineno-54-22"></a><span class="w">               </span><span class="c1">#color = &quot;blue&quot;, </span>
</span><span id="__span-54-23"><a id="__codelineno-54-23" name="__codelineno-54-23" href="#__codelineno-54-23"></a><span class="w">               </span><span class="n">arrow</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">arrow</span><span class="p">(</span><span class="n">length</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">unit</span><span class="p">(</span><span class="m">0.3</span><span class="p">,</span><span class="s">&quot;cm&quot;</span><span class="p">)))</span><span class="w"> </span><span class="o">+</span>
</span><span id="__span-54-24"><a id="__codelineno-54-24" name="__codelineno-54-24" href="#__codelineno-54-24"></a><span class="w">      </span><span class="nf">geom_segment</span><span class="p">(</span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">df</span><span class="p">[</span><span class="m">4</span><span class="p">,],</span><span class="w"> </span>
</span><span id="__span-54-25"><a id="__codelineno-54-25" name="__codelineno-54-25" href="#__codelineno-54-25"></a><span class="w">               </span><span class="nf">aes</span><span class="p">(</span><span class="n">xend</span><span class="o">=</span><span class="n">x1</span><span class="p">,</span><span class="w"> </span><span class="n">yend</span><span class="o">=</span><span class="n">y1</span><span class="p">,</span><span class="w">  </span><span class="n">color</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;green&quot;</span><span class="p">,),</span>
</span><span id="__span-54-26"><a id="__codelineno-54-26" name="__codelineno-54-26" href="#__codelineno-54-26"></a><span class="w">               </span><span class="c1">#color = &quot;green&quot;, </span>
</span><span id="__span-54-27"><a id="__codelineno-54-27" name="__codelineno-54-27" href="#__codelineno-54-27"></a><span class="w">               </span><span class="n">arrow</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">arrow</span><span class="p">(</span><span class="n">length</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">unit</span><span class="p">(</span><span class="m">0.3</span><span class="p">,</span><span class="s">&quot;cm&quot;</span><span class="p">)))</span><span class="w"> </span><span class="o">+</span><span class="w"> </span>
</span><span id="__span-54-28"><a id="__codelineno-54-28" name="__codelineno-54-28" href="#__codelineno-54-28"></a><span class="w">      </span><span class="nf">geom_segment</span><span class="p">(</span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">df</span><span class="p">[</span><span class="m">5</span><span class="p">,],</span><span class="w"> </span>
</span><span id="__span-54-29"><a id="__codelineno-54-29" name="__codelineno-54-29" href="#__codelineno-54-29"></a><span class="w">               </span><span class="nf">aes</span><span class="p">(</span><span class="n">xend</span><span class="o">=</span><span class="n">x1</span><span class="p">,</span><span class="w"> </span><span class="n">yend</span><span class="o">=</span><span class="n">y1</span><span class="p">),</span>
</span><span id="__span-54-30"><a id="__codelineno-54-30" name="__codelineno-54-30" href="#__codelineno-54-30"></a><span class="w">               </span><span class="n">color</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;green&quot;</span><span class="p">,</span><span class="w"> </span>
</span><span id="__span-54-31"><a id="__codelineno-54-31" name="__codelineno-54-31" href="#__codelineno-54-31"></a><span class="w">               </span><span class="n">arrow</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">arrow</span><span class="p">(</span><span class="n">length</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">unit</span><span class="p">(</span><span class="m">0.3</span><span class="p">,</span><span class="s">&quot;cm&quot;</span><span class="p">)))</span><span class="w"> </span><span class="o">+</span>
</span><span id="__span-54-32"><a id="__codelineno-54-32" name="__codelineno-54-32" href="#__codelineno-54-32"></a><span class="w">      </span><span class="nf">scale_colour_manual</span><span class="p">(</span><span class="n">name</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&#39;the colour&#39;</span><span class="p">,</span><span class="w"> </span>
</span><span id="__span-54-33"><a id="__codelineno-54-33" name="__codelineno-54-33" href="#__codelineno-54-33"></a><span class="w">         </span><span class="n">values</span><span class="w"> </span><span class="o">=</span><span class="nf">c</span><span class="p">(</span><span class="s">&#39;blue&#39;</span><span class="o">=</span><span class="s">&#39;blue&#39;</span><span class="p">,</span><span class="s">&#39;green&#39;</span><span class="o">=</span><span class="s">&#39;green&#39;</span><span class="p">),</span>
</span><span id="__span-54-34"><a id="__codelineno-54-34" name="__codelineno-54-34" href="#__codelineno-54-34"></a><span class="w">         </span><span class="n">labels</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="s">&#39;Euclideana&#39;</span><span class="p">,</span><span class="s">&#39;Manhattan&#39;</span><span class="p">))</span>
</span></code></pre></div>
<p><img alt="Image" src="../../img/2019-11-11-distintas-distancias-unnamed-chunk-4-1.png" /></p>
<p>Vemos como el valor abosluto imposibilita ir en dirección diagonal. Lo que se logra es medir la distancia como si hubiera una grilla como la del gráfico. Su nombre proviene de su utilización para medir distancias al interior de una ciudad (uno no puede cruzar las manzanas por el medio!).</p>
<p>Para saber cual conviene utilizar hay que pensar en el problema en cuestión. </p>
<ul>
<li>Ya sea medir distancias en ciudades o donde haya restricciones de ese tipo puede que Manhattan sea más apropiado.  </li>
<li>Por otra parte al no elevar al cuadrado le da menos pesos a las grandes distancias o mismo outliers por lo que puede ser otro motivo válido.  </li>
<li>Por último, algunos trabajos argumentan que es más adecuada en problema de alta dimensionalidad (o mismo valores menores a 1 en el exponente de la formula de Minkowsky)</li>
</ul>
<h4 id="similaridad-coseno"><a class="toclink" href="../../2019/11/11/distintas-distancias/#similaridad-coseno">Similaridad coseno</a></h4>
<p>La similaridad coseno se utiliza cuando se quiere ver la similitud "angular" entre dos observaciones y no la distancia en el plano. Es decir, vemos la dirección pero no la magnitud</p>
<div class="language-r highlight"><pre><span></span><code><span id="__span-55-1"><a id="__codelineno-55-1" name="__codelineno-55-1" href="#__codelineno-55-1"></a><span class="n">A</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">0</span><span class="p">,</span><span class="m">0</span><span class="p">,</span><span class="m">1</span><span class="p">,</span><span class="m">1</span><span class="p">)</span>
</span><span id="__span-55-2"><a id="__codelineno-55-2" name="__codelineno-55-2" href="#__codelineno-55-2"></a><span class="n">B</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">0</span><span class="p">,</span><span class="m">0</span><span class="p">,</span><span class="m">2</span><span class="p">,</span><span class="m">2</span><span class="p">)</span>
</span><span id="__span-55-3"><a id="__codelineno-55-3" name="__codelineno-55-3" href="#__codelineno-55-3"></a><span class="n">C</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">0</span><span class="p">,</span><span class="m">0</span><span class="p">,</span><span class="m">5</span><span class="p">,</span><span class="m">0</span><span class="p">)</span>
</span><span id="__span-55-4"><a id="__codelineno-55-4" name="__codelineno-55-4" href="#__codelineno-55-4"></a>
</span><span id="__span-55-5"><a id="__codelineno-55-5" name="__codelineno-55-5" href="#__codelineno-55-5"></a><span class="n">df</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">as.data.frame</span><span class="p">(</span><span class="nf">matrix</span><span class="p">(</span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="n">A</span><span class="p">,</span><span class="n">B</span><span class="p">,</span><span class="n">C</span><span class="p">),</span>
</span><span id="__span-55-6"><a id="__codelineno-55-6" name="__codelineno-55-6" href="#__codelineno-55-6"></a><span class="w">                          </span><span class="n">nrow</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">3</span><span class="p">,</span><span class="w"> </span>
</span><span id="__span-55-7"><a id="__codelineno-55-7" name="__codelineno-55-7" href="#__codelineno-55-7"></a><span class="w">                          </span><span class="n">ncol</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">4</span><span class="p">,</span>
</span><span id="__span-55-8"><a id="__codelineno-55-8" name="__codelineno-55-8" href="#__codelineno-55-8"></a><span class="w">                          </span><span class="n">byrow</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="w"> </span><span class="p">))</span><span class="w"> </span><span class="o">%&gt;%</span>
</span><span id="__span-55-9"><a id="__codelineno-55-9" name="__codelineno-55-9" href="#__codelineno-55-9"></a><span class="w">  </span><span class="nf">rename</span><span class="p">(</span><span class="w"> </span><span class="n">x0</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">V1</span><span class="p">,</span>
</span><span id="__span-55-10"><a id="__codelineno-55-10" name="__codelineno-55-10" href="#__codelineno-55-10"></a><span class="w">          </span><span class="n">y0</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">V2</span><span class="p">,</span>
</span><span id="__span-55-11"><a id="__codelineno-55-11" name="__codelineno-55-11" href="#__codelineno-55-11"></a><span class="w">          </span><span class="n">x1</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">V3</span><span class="p">,</span>
</span><span id="__span-55-12"><a id="__codelineno-55-12" name="__codelineno-55-12" href="#__codelineno-55-12"></a><span class="w">          </span><span class="n">y1</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">V4</span><span class="p">)</span>
</span><span id="__span-55-13"><a id="__codelineno-55-13" name="__codelineno-55-13" href="#__codelineno-55-13"></a>
</span><span id="__span-55-14"><a id="__codelineno-55-14" name="__codelineno-55-14" href="#__codelineno-55-14"></a>
</span><span id="__span-55-15"><a id="__codelineno-55-15" name="__codelineno-55-15" href="#__codelineno-55-15"></a><span class="nf">ggplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">[</span><span class="m">1</span><span class="o">:</span><span class="m">3</span><span class="p">,],</span><span class="w"> </span><span class="nf">aes</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">x0</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="o">=</span><span class="n">y0</span><span class="w"> </span><span class="p">))</span><span class="w"> </span><span class="o">+</span><span class="w"> </span>
</span><span id="__span-55-16"><a id="__codelineno-55-16" name="__codelineno-55-16" href="#__codelineno-55-16"></a><span class="w">  </span><span class="nf">geom_segment</span><span class="p">(</span><span class="nf">aes</span><span class="p">(</span><span class="n">xend</span><span class="o">=</span><span class="n">x1</span><span class="p">,</span><span class="w"> </span><span class="n">yend</span><span class="o">=</span><span class="n">y1</span><span class="p">),</span>
</span><span id="__span-55-17"><a id="__codelineno-55-17" name="__codelineno-55-17" href="#__codelineno-55-17"></a><span class="w">               </span><span class="n">arrow</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">arrow</span><span class="p">(</span><span class="n">length</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">unit</span><span class="p">(</span><span class="m">0.3</span><span class="p">,</span><span class="s">&quot;cm&quot;</span><span class="p">)))</span><span class="w"> </span><span class="o">+</span><span class="w"> </span>
</span><span id="__span-55-18"><a id="__codelineno-55-18" name="__codelineno-55-18" href="#__codelineno-55-18"></a><span class="w">  </span><span class="nf">geom_point</span><span class="p">(</span><span class="w"> </span><span class="nf">aes</span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">x1</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">y1</span><span class="p">),</span><span class="w"> </span>
</span><span id="__span-55-19"><a id="__codelineno-55-19" name="__codelineno-55-19" href="#__codelineno-55-19"></a><span class="w">              </span><span class="n">color</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;red&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">2</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span>
</span><span id="__span-55-20"><a id="__codelineno-55-20" name="__codelineno-55-20" href="#__codelineno-55-20"></a><span class="w">  </span><span class="nf">geom_text</span><span class="p">(</span><span class="nf">aes</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">x1</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">y1</span><span class="p">,</span><span class="w"> </span><span class="n">label</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="s">&quot;A&quot;</span><span class="p">,</span><span class="s">&quot;B&quot;</span><span class="p">,</span><span class="s">&quot;C&quot;</span><span class="p">)),</span>
</span><span id="__span-55-21"><a id="__codelineno-55-21" name="__codelineno-55-21" href="#__codelineno-55-21"></a><span class="w">            </span><span class="n">vjust</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">-0.5</span><span class="p">)</span>
</span></code></pre></div>
<p><img alt="Image" src="../../img/2019-11-11-distintas-distancias-unnamed-chunk-5-1.png" /></p>
<p>Si hicieramos la distancia euclideando entre A y B obtendriamos el valor de la distancia en el plano, sin embargo podemos ver que se encuentran sobre la misma recta y por lo tanto su dirección es la misma. La similaridad coseno mide el ángulo entre dos puntos. En este caso el ángulo entre A y B es 0, y por ende su similaridad coseno es 1. Ambas tendrían la misma similaridad con cualquier otro punto de la misma recta, por más alejado que esté.
Respecto a C, tanto A y B tiene comparten el ángulo por lo tanto la similaridad coseno entre A y C será la misma que entre B y C.</p>
<div class="language-r highlight"><pre><span></span><code><span id="__span-56-1"><a id="__codelineno-56-1" name="__codelineno-56-1" href="#__codelineno-56-1"></a><span class="n">cosA</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">1</span><span class="p">,</span><span class="m">1</span><span class="p">)</span>
</span><span id="__span-56-2"><a id="__codelineno-56-2" name="__codelineno-56-2" href="#__codelineno-56-2"></a><span class="n">cosB</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">2</span><span class="p">,</span><span class="m">2</span><span class="p">)</span>
</span><span id="__span-56-3"><a id="__codelineno-56-3" name="__codelineno-56-3" href="#__codelineno-56-3"></a><span class="n">cosC</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">5</span><span class="p">,</span><span class="m">0</span><span class="p">)</span>
</span><span id="__span-56-4"><a id="__codelineno-56-4" name="__codelineno-56-4" href="#__codelineno-56-4"></a>
</span><span id="__span-56-5"><a id="__codelineno-56-5" name="__codelineno-56-5" href="#__codelineno-56-5"></a><span class="c1"># Similaridad coseno entre A y B</span>
</span><span id="__span-56-6"><a id="__codelineno-56-6" name="__codelineno-56-6" href="#__codelineno-56-6"></a><span class="n">lsa</span><span class="o">::</span><span class="nf">cosine</span><span class="p">(</span><span class="n">cosA</span><span class="p">,</span><span class="w"> </span><span class="n">cosB</span><span class="p">)[[</span><span class="m">1</span><span class="p">]]</span>
</span></code></pre></div>
<div class="language-text highlight"><pre><span></span><code><span id="__span-57-1"><a id="__codelineno-57-1" name="__codelineno-57-1" href="#__codelineno-57-1"></a>## [1] 1
</span></code></pre></div>
<div class="language-r highlight"><pre><span></span><code><span id="__span-58-1"><a id="__codelineno-58-1" name="__codelineno-58-1" href="#__codelineno-58-1"></a><span class="c1"># Similaridad coseno entre A y C</span>
</span><span id="__span-58-2"><a id="__codelineno-58-2" name="__codelineno-58-2" href="#__codelineno-58-2"></a><span class="n">lsa</span><span class="o">::</span><span class="nf">cosine</span><span class="p">(</span><span class="n">cosA</span><span class="p">,</span><span class="w"> </span><span class="n">cosC</span><span class="p">)[[</span><span class="m">1</span><span class="p">]]</span>
</span></code></pre></div>
<div class="language-text highlight"><pre><span></span><code><span id="__span-59-1"><a id="__codelineno-59-1" name="__codelineno-59-1" href="#__codelineno-59-1"></a>## [1] 0.7071068
</span></code></pre></div>
<div class="language-r highlight"><pre><span></span><code><span id="__span-60-1"><a id="__codelineno-60-1" name="__codelineno-60-1" href="#__codelineno-60-1"></a><span class="c1"># Similaridad coseno entre B y C</span>
</span><span id="__span-60-2"><a id="__codelineno-60-2" name="__codelineno-60-2" href="#__codelineno-60-2"></a><span class="n">lsa</span><span class="o">::</span><span class="nf">cosine</span><span class="p">(</span><span class="n">cosC</span><span class="p">,</span><span class="w"> </span><span class="n">cosB</span><span class="p">)[[</span><span class="m">1</span><span class="p">]]</span>
</span></code></pre></div>
<div class="language-text highlight"><pre><span></span><code><span id="__span-61-1"><a id="__codelineno-61-1" name="__codelineno-61-1" href="#__codelineno-61-1"></a>## [1] 0.7071068
</span></code></pre></div>
<p>Hay que tener en cuenta el contexto de nuestro problema para decidir qué medida de distancia usar. Por ejemplo la similaridad coseno se usa de manera estándar en análisis de texto (text mining).</p>
<h4 id="distancia-de-mahalanobis"><a class="toclink" href="../../2019/11/11/distintas-distancias/#distancia-de-mahalanobis">Distancia de Mahalanobis</a></h4>
<p>La distancia de Mahalanobis tiene la particularidad que mide la distancia entre un punto (P) y una distribución de datos (D). Si tenemos una nube de puntos correspondiente a una distribución D, cuanto más cerca esté P del centro de masa (o "promedio") más cerca se encuetran P y D. Intuitivamente sirve para pensar si P puede pertenecer a D o no.<br />
Dado que la nube de puntos no tiene por qué ser una esfera (donde cada dirección tiene la misma cantidad de puntos), hay que tener en cuenta cómo se dispersan los puntos alrededor del centro de masa.</p>
<p>No es lo mismo, </p>
<div class="language-r highlight"><pre><span></span><code><span id="__span-62-1"><a id="__codelineno-62-1" name="__codelineno-62-1" href="#__codelineno-62-1"></a><span class="n">esfera</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">as.data.frame</span><span class="p">(</span><span class="n">MASS</span><span class="o">::</span><span class="nf">mvrnorm</span><span class="p">(</span><span class="m">1000</span><span class="p">,</span><span class="w"> </span><span class="n">mu</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">3</span><span class="p">,</span><span class="m">3</span><span class="p">),</span><span class="w"> </span>
</span><span id="__span-62-2"><a id="__codelineno-62-2" name="__codelineno-62-2" href="#__codelineno-62-2"></a><span class="w">                                     </span><span class="n">Sigma</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">matrix</span><span class="p">(</span><span class="nf">c</span><span class="p">(</span><span class="m">1</span><span class="p">,</span><span class="m">0</span><span class="p">,</span><span class="m">0</span><span class="p">,</span><span class="m">1</span><span class="p">),</span>
</span><span id="__span-62-3"><a id="__codelineno-62-3" name="__codelineno-62-3" href="#__codelineno-62-3"></a><span class="w">                                                    </span><span class="n">nrow</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">2</span><span class="p">,</span>
</span><span id="__span-62-4"><a id="__codelineno-62-4" name="__codelineno-62-4" href="#__codelineno-62-4"></a><span class="w">                                                    </span><span class="n">ncol</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">2</span><span class="p">)))</span>
</span><span id="__span-62-5"><a id="__codelineno-62-5" name="__codelineno-62-5" href="#__codelineno-62-5"></a>
</span><span id="__span-62-6"><a id="__codelineno-62-6" name="__codelineno-62-6" href="#__codelineno-62-6"></a><span class="nf">ggplot</span><span class="p">(</span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">esfera</span><span class="p">,</span><span class="w"> </span><span class="nf">aes</span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">V1</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">V2</span><span class="p">))</span><span class="w"> </span><span class="o">+</span><span class="w"> </span>
</span><span id="__span-62-7"><a id="__codelineno-62-7" name="__codelineno-62-7" href="#__codelineno-62-7"></a><span class="w">  </span><span class="nf">geom_point</span><span class="p">()</span><span class="w"> </span><span class="o">+</span><span class="w"> </span>
</span><span id="__span-62-8"><a id="__codelineno-62-8" name="__codelineno-62-8" href="#__codelineno-62-8"></a><span class="w">  </span><span class="nf">geom_point</span><span class="p">(</span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">as.data.frame</span><span class="p">(</span><span class="nf">matrix</span><span class="p">(</span><span class="nf">c</span><span class="p">(</span><span class="m">6</span><span class="p">,</span><span class="m">2</span><span class="p">),</span><span class="n">ncol</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">2</span><span class="p">)),</span><span class="w"> </span>
</span><span id="__span-62-9"><a id="__codelineno-62-9" name="__codelineno-62-9" href="#__codelineno-62-9"></a><span class="w">             </span><span class="nf">aes</span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">V1</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">V2</span><span class="p">),</span><span class="w"> </span><span class="n">color</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;red&quot;</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span>
</span><span id="__span-62-10"><a id="__codelineno-62-10" name="__codelineno-62-10" href="#__codelineno-62-10"></a><span class="w">  </span><span class="nf">geom_text</span><span class="p">(</span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">as.data.frame</span><span class="p">(</span><span class="nf">matrix</span><span class="p">(</span><span class="nf">c</span><span class="p">(</span><span class="m">6</span><span class="p">,</span><span class="m">2</span><span class="p">),</span><span class="n">ncol</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">2</span><span class="p">)),</span>
</span><span id="__span-62-11"><a id="__codelineno-62-11" name="__codelineno-62-11" href="#__codelineno-62-11"></a><span class="w">            </span><span class="nf">aes</span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">V1</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">V2</span><span class="p">,</span><span class="n">label</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;P&quot;</span><span class="p">),</span>
</span><span id="__span-62-12"><a id="__codelineno-62-12" name="__codelineno-62-12" href="#__codelineno-62-12"></a><span class="w">            </span><span class="n">vjust</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1.5</span><span class="p">,</span><span class="w"> </span><span class="n">color</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;blue&quot;</span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
</span><span id="__span-62-13"><a id="__codelineno-62-13" name="__codelineno-62-13" href="#__codelineno-62-13"></a><span class="w">  </span><span class="nf">labs</span><span class="p">(</span><span class="n">title</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;Distribución esférica&quot;</span><span class="p">)</span>
</span></code></pre></div>
<p><img alt="Image" src="../../img/2019-11-11-distintas-distancias-unnamed-chunk-7-1.png" /></p>
<p>que,</p>
<div class="language-r highlight"><pre><span></span><code><span id="__span-63-1"><a id="__codelineno-63-1" name="__codelineno-63-1" href="#__codelineno-63-1"></a><span class="n">elipse</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">as.data.frame</span><span class="p">(</span><span class="n">MASS</span><span class="o">::</span><span class="nf">mvrnorm</span><span class="p">(</span><span class="m">1000</span><span class="p">,</span><span class="w"> </span><span class="n">mu</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">3</span><span class="p">,</span><span class="m">3</span><span class="p">),</span><span class="w"> </span>
</span><span id="__span-63-2"><a id="__codelineno-63-2" name="__codelineno-63-2" href="#__codelineno-63-2"></a><span class="w">                                     </span><span class="n">Sigma</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">matrix</span><span class="p">(</span><span class="nf">c</span><span class="p">(</span><span class="m">1</span><span class="p">,</span><span class="m">0.6</span><span class="p">,</span><span class="m">0.6</span><span class="p">,</span><span class="m">1</span><span class="p">),</span>
</span><span id="__span-63-3"><a id="__codelineno-63-3" name="__codelineno-63-3" href="#__codelineno-63-3"></a><span class="w">                                                    </span><span class="n">nrow</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">2</span><span class="p">,</span>
</span><span id="__span-63-4"><a id="__codelineno-63-4" name="__codelineno-63-4" href="#__codelineno-63-4"></a><span class="w">                                                    </span><span class="n">ncol</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">2</span><span class="p">)))</span>
</span><span id="__span-63-5"><a id="__codelineno-63-5" name="__codelineno-63-5" href="#__codelineno-63-5"></a>
</span><span id="__span-63-6"><a id="__codelineno-63-6" name="__codelineno-63-6" href="#__codelineno-63-6"></a>
</span><span id="__span-63-7"><a id="__codelineno-63-7" name="__codelineno-63-7" href="#__codelineno-63-7"></a>
</span><span id="__span-63-8"><a id="__codelineno-63-8" name="__codelineno-63-8" href="#__codelineno-63-8"></a><span class="nf">ggplot</span><span class="p">(</span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">elipse</span><span class="p">,</span><span class="w"> </span><span class="nf">aes</span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">V1</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">V2</span><span class="p">))</span><span class="w"> </span><span class="o">+</span><span class="w"> </span>
</span><span id="__span-63-9"><a id="__codelineno-63-9" name="__codelineno-63-9" href="#__codelineno-63-9"></a><span class="w">  </span><span class="nf">geom_point</span><span class="p">()</span><span class="w"> </span><span class="o">+</span><span class="w"> </span>
</span><span id="__span-63-10"><a id="__codelineno-63-10" name="__codelineno-63-10" href="#__codelineno-63-10"></a><span class="w">  </span><span class="nf">geom_point</span><span class="p">(</span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">as.data.frame</span><span class="p">(</span><span class="nf">matrix</span><span class="p">(</span><span class="nf">c</span><span class="p">(</span><span class="m">6</span><span class="p">,</span><span class="m">2</span><span class="p">),</span><span class="n">ncol</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">2</span><span class="p">)),</span><span class="w"> </span>
</span><span id="__span-63-11"><a id="__codelineno-63-11" name="__codelineno-63-11" href="#__codelineno-63-11"></a><span class="w">             </span><span class="nf">aes</span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">V1</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">V2</span><span class="p">),</span><span class="w"> </span><span class="n">color</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;red&quot;</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span>
</span><span id="__span-63-12"><a id="__codelineno-63-12" name="__codelineno-63-12" href="#__codelineno-63-12"></a><span class="w">  </span><span class="nf">geom_text</span><span class="p">(</span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">as.data.frame</span><span class="p">(</span><span class="nf">matrix</span><span class="p">(</span><span class="nf">c</span><span class="p">(</span><span class="m">6</span><span class="p">,</span><span class="m">2</span><span class="p">),</span><span class="n">ncol</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">2</span><span class="p">)),</span>
</span><span id="__span-63-13"><a id="__codelineno-63-13" name="__codelineno-63-13" href="#__codelineno-63-13"></a><span class="w">            </span><span class="nf">aes</span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">V1</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">V2</span><span class="p">,</span><span class="n">label</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;P&quot;</span><span class="p">),</span>
</span><span id="__span-63-14"><a id="__codelineno-63-14" name="__codelineno-63-14" href="#__codelineno-63-14"></a><span class="w">            </span><span class="n">vjust</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1.5</span><span class="p">,</span><span class="w"> </span><span class="n">color</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;blue&quot;</span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
</span><span id="__span-63-15"><a id="__codelineno-63-15" name="__codelineno-63-15" href="#__codelineno-63-15"></a><span class="w">  </span><span class="nf">labs</span><span class="p">(</span><span class="n">title</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;Distribución Elíptica&quot;</span><span class="p">)</span>
</span></code></pre></div>
<p><img alt="Image" src="../../img/2019-11-11-distintas-distancias-unnamed-chunk-8-1.png" /></p>
<p>Los centros de masa son los mismos y lo único que cambia es la matriz de variancias y covarianzas (o como se correlacionan las variables). La distancia de P al centro es la misma, pero está claro que en el caso esférico P se encuentra más cerca de la distribución que en el caso elíptico.</p>
<p>Mahalanobis tiene en cuenta este aspecto ya que involucra la matriz de varianzas y covarianzas.</p>
<p>La distancia entre el punto x y la distribución con vector de medias <span class="arithmatex">\(\vec{\mu}\)</span> y matriz de covarianzas S es:
$$ D_M(\vec{x}) = \sqrt{(\vec{x} - \vec{\mu})<sup -1="-1">TS</sup>)$$}(\vec{x} - \vec{\mu})</p>
<p>Tanto el vector <span class="arithmatex">\(\vec{x}\)</span> como la distribución pueden ser multivariadas (como se ve en los gráficos de arriba).</p>
<p>Tener en cuenta que si tenemos dos puntos provenientes de la misma distribución, podemos usar la distancia de Mahalanobis como una medida de disimilaridad:
$$ D_M(\vec{x},\vec{y}) = \sqrt{(\vec{x} - \vec{y})<sup -1="-1">TS</sup>)$$
Veamos por ejemplo como queda la distancia de P a las distribuciones esféricas y elípticas graficadas.}(\vec{x} - \vec{y})</p>
<div class="language-r highlight"><pre><span></span><code><span id="__span-64-1"><a id="__codelineno-64-1" name="__codelineno-64-1" href="#__codelineno-64-1"></a><span class="c1"># Caso Esférico</span>
</span><span id="__span-64-2"><a id="__codelineno-64-2" name="__codelineno-64-2" href="#__codelineno-64-2"></a>
</span><span id="__span-64-3"><a id="__codelineno-64-3" name="__codelineno-64-3" href="#__codelineno-64-3"></a><span class="nf">mahalanobis</span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">6</span><span class="p">,</span><span class="m">2</span><span class="p">),</span><span class="w"> </span>
</span><span id="__span-64-4"><a id="__codelineno-64-4" name="__codelineno-64-4" href="#__codelineno-64-4"></a><span class="w">            </span><span class="n">center</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">3</span><span class="p">,</span><span class="m">3</span><span class="p">),</span><span class="w"> </span>
</span><span id="__span-64-5"><a id="__codelineno-64-5" name="__codelineno-64-5" href="#__codelineno-64-5"></a><span class="w">            </span><span class="n">cov</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">matrix</span><span class="p">(</span><span class="nf">c</span><span class="p">(</span><span class="m">1</span><span class="p">,</span><span class="m">0</span><span class="p">,</span><span class="m">0</span><span class="p">,</span><span class="m">1</span><span class="p">),</span>
</span><span id="__span-64-6"><a id="__codelineno-64-6" name="__codelineno-64-6" href="#__codelineno-64-6"></a><span class="w">                         </span><span class="n">nrow</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">2</span><span class="p">,</span>
</span><span id="__span-64-7"><a id="__codelineno-64-7" name="__codelineno-64-7" href="#__codelineno-64-7"></a><span class="w">                         </span><span class="n">ncol</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">2</span><span class="p">))</span>
</span></code></pre></div>
<div class="language-text highlight"><pre><span></span><code><span id="__span-65-1"><a id="__codelineno-65-1" name="__codelineno-65-1" href="#__codelineno-65-1"></a>## [1] 10
</span></code></pre></div>
<div class="language-r highlight"><pre><span></span><code><span id="__span-66-1"><a id="__codelineno-66-1" name="__codelineno-66-1" href="#__codelineno-66-1"></a><span class="c1"># Caso Elíptico</span>
</span><span id="__span-66-2"><a id="__codelineno-66-2" name="__codelineno-66-2" href="#__codelineno-66-2"></a><span class="nf">mahalanobis</span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">6</span><span class="p">,</span><span class="m">2</span><span class="p">),</span><span class="w"> </span>
</span><span id="__span-66-3"><a id="__codelineno-66-3" name="__codelineno-66-3" href="#__codelineno-66-3"></a><span class="w">            </span><span class="n">center</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">3</span><span class="p">,</span><span class="m">3</span><span class="p">),</span><span class="w"> </span>
</span><span id="__span-66-4"><a id="__codelineno-66-4" name="__codelineno-66-4" href="#__codelineno-66-4"></a><span class="w">            </span><span class="n">cov</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">matrix</span><span class="p">(</span><span class="nf">c</span><span class="p">(</span><span class="m">1</span><span class="p">,</span><span class="m">0.6</span><span class="p">,</span><span class="m">0.6</span><span class="p">,</span><span class="m">1</span><span class="p">),</span>
</span><span id="__span-66-5"><a id="__codelineno-66-5" name="__codelineno-66-5" href="#__codelineno-66-5"></a><span class="w">                         </span><span class="n">nrow</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">2</span><span class="p">,</span>
</span><span id="__span-66-6"><a id="__codelineno-66-6" name="__codelineno-66-6" href="#__codelineno-66-6"></a><span class="w">                         </span><span class="n">ncol</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">2</span><span class="p">))</span>
</span></code></pre></div>
<div class="language-text highlight"><pre><span></span><code><span id="__span-67-1"><a id="__codelineno-67-1" name="__codelineno-67-1" href="#__codelineno-67-1"></a>## [1] 21.25
</span></code></pre></div>
<p>Queda claro que P es más cercano a la distribución esférica que a la elíptica.</p>
    
  </div>
</article>
      
        <article class="md-post md-post--excerpt">
  <header class="md-post__header">
    
      <nav class="md-post__authors md-typeset">
        
          <span class="md-author">
            <img src="https://media.licdn.com/dms/image/v2/D4D03AQGGiT9NDiLy7Q/profile-displayphoto-shrink_200_200/profile-displayphoto-shrink_200_200/0/1681511830071?e=1738195200&v=beta&t=Nd1WNLQTxHfCe7dT9BBaQYgaYtEHFCOPpntpImC4Lz8" alt="Franco Betteo">
          </span>
        
      </nav>
    
    <div class="md-post__meta md-meta">
      <ul class="md-meta__list">
        <li class="md-meta__item">
          <time datetime="2019-10-31 00:00:00+00:00">2019-10-31</time></li>
        
          <li class="md-meta__item">
            in
            
              <a href="../../category/estadistica/" class="md-meta__link">estadistica</a>, 
              <a href="../../category/r/" class="md-meta__link">R</a></li>
        
        
          
          <li class="md-meta__item">
            
              7 min read
            
          </li>
        
      </ul>
      
    </div>
  </header>
  <div class="md-post__content md-typeset">
    <h2 id="maxima-verosimilitud-y-estimacion-bayesiana"><a class="toclink" href="../../2019/10/31/maxima-verosimilitud-y-estimacion-bayesiana/">Maxima Verosimilitud y estimacion bayesiana</a></h2>
<h3 id="distribucion-prior"><a class="toclink" href="../../2019/10/31/maxima-verosimilitud-y-estimacion-bayesiana/#distribucion-prior">Distribucion prior</a></h3>
<p>A falta de una buena traducción usamos este término.</p>
<p>Supongamos que se toman muestras aleatorias de una distribucion con <a href="https://fbetteo.netlify.com/2019/04/funciones-de-probabilidad-y-distribucion/">pdf (funcion de densidad de probabilidad)</a> <span class="arithmatex">\(f(x|\theta)\)</span>. Por ejemplo podrían provenir de una normal con media = <span class="arithmatex">\(\mu\)</span> y varianza = 4.<br />
Nosotros no sabemos el valor de <span class="arithmatex">\(\mu\)</span> pero podemos tener una idea de qué valores puede tomar y tener en mente una distribución prior de este parámetro <span class="arithmatex">\(\epsilon(\theta)\)</span>. Para el ejemplo sería <span class="arithmatex">\(\epsilon(\mu)\)</span>. Podemos suponer que <span class="arithmatex">\(\mu\)</span> se distribuye como una uniforme (0,1) por decir algo.<br />
El concepto radica en tener una distribución prior para los parámetros de la distribución de la cual tomamos muestras aleatorias.</p>
<h3 id="distribucion-posterior"><a class="toclink" href="../../2019/10/31/maxima-verosimilitud-y-estimacion-bayesiana/#distribucion-posterior">Distribución Posterior</a></h3>
<p>Volviendo a nuestra muestra <span class="arithmatex">\(X_1...X_n\)</span> proveniente de <span class="arithmatex">\(f(x|\theta)\)</span>, podemos decir, debido a que son observaciones aleatorias e independientes que su distribución conjunta es <span class="arithmatex">\(f_n(x_1...X_n|\theta) = f(x_1|\theta)...f(x_n|\theta)\)</span>, que lo podemos escribir como <span class="arithmatex">\(f_n(x|\theta)\)</span>.<br />
Dado que suponemos que <span class="arithmatex">\(\theta\)</span> proviene de una distribución <span class="arithmatex">\(\epsilon(\theta)\)</span>, la pdf conjunta <span class="arithmatex">\(f_n(x|\theta)\)</span> tiene que ser vista como la pdf conjunta condicional de<span class="arithmatex">\(X_1...X_n\)</span> para un valor particular de <span class="arithmatex">\(\theta\)</span>.<br />
Multiplicando la pdf conjunta condicional por la pdf <span class="arithmatex">\(\epsilon(\theta)\)</span> obtenemos la (n+1) distribución conjunta de <span class="arithmatex">\(X_1...X_n\)</span> y <span class="arithmatex">\(\theta\)</span> bajo la forma <span class="arithmatex">\(f_n(x|\theta)\epsilon(\theta)\)</span>. Sería la pdf de encontrar en simultáneo determinados valores para x y <span class="arithmatex">\(\theta\)</span>. La probabilidad conjunta marginal de <span class="arithmatex">\(X_1...X_n\)</span> se encuentra integrando la pdf conjunta con <span class="arithmatex">\(\theta\)</span> para todos los valores de <span class="arithmatex">\(\theta\)</span>. Sería la probabilidad marginal de encontrar determinados valores de x (sabiendo la distribución de <span class="arithmatex">\(\theta\)</span> pero sin saber el valor puntual que toma).</p>
<p><span class="arithmatex">\(g_n(x) = \int_\Omega f_n(x|\theta)\epsilon(\theta) d\theta\)</span></p>
<p>Por teorema de Bayes tenemos que la distribución posterior de <span class="arithmatex">\(\theta\)</span>, es decir, dados los x es:
<span class="arithmatex">\(<span class="arithmatex">\(\epsilon(\theta|x) = \frac{f_n(x|\theta)\epsilon(\theta)}{g_n(x)} \text{ para } \theta \in \Omega\)</span>\)</span> 
 Se dice que la distribución prior <span class="arithmatex">\(\epsilon(\theta)\)</span> representa la verosimilitud, antes de ver los valores de <span class="arithmatex">\(X_1...X_n\)</span>, de que el verdadero valor de <span class="arithmatex">\(\theta\)</span> se encuentre en cada una de las regiones de <span class="arithmatex">\(\Omega\)</span> y que la pdf de la distribución posterior <span class="arithmatex">\(\epsilon(\theta|x)\)</span> representa la verosimilitud después que los valores <span class="arithmatex">\(X_1 = x_1,...,X_n = x_n\)</span> hayan sido observados.</p>
<p>## La funcion de Versoimilitud</p>
<p>El denominador de la distribución posterior es básicamente la integral del numerador para todos los posibles valores de <span class="arithmatex">\(\theta\)</span>. Depende de los valores observados <span class="arithmatex">\(X_1...X_n\)</span> pero no de <span class="arithmatex">\(\theta\)</span>, por lo que puede considerarse constante en este contexto.<br />
 Dado que es una constante podemos quitarla de la distribución posterior que vimos y decir que 
 <span class="arithmatex">\(<span class="arithmatex">\(\epsilon(\theta|x) \propto f_n(x|\theta)\epsilon(\theta)\)</span>\)</span></p>
<p>Cuando se ve <span class="arithmatex">\(f_n(x|\theta)\)</span> para una muestra aleatoria como función de <span class="arithmatex">\(\theta\)</span>, se la suele llamar función de verosimilitud. En inglés: Likelihood function.</p>
<p>Juntando estos términos podemos decir que la pdf posterior de <span class="arithmatex">\(\theta\)</span> es proporcional al producto de la función de verosimilitud y la pdf prior de <span class="arithmatex">\(\theta\)</span>.  </p>
<p>La idea de ver esta relación de proporcionalidad es para poder calcular la pdf posterior evitando calcular la integral del denomiador <span class="arithmatex">\(g_n(x)\)</span>. Si el numerador tiene la forma de alguna de las distribuciones conocidad (normal, beta, gamma, uniforme, etc) es posible calcular fácilmente el factor constante por el cual multiplicar esa pdf para llegar a la posterior.</p>
<h3 id="distribuciones-prior-conjugadas"><a class="toclink" href="../../2019/10/31/maxima-verosimilitud-y-estimacion-bayesiana/#distribuciones-prior-conjugadas">Distribuciones prior Conjugadas</a></h3>
<p>Este concepto refiere a que ciertas distribuciones son particularmente útiles para los cálculos cuando las variables aleatorias observadas provienen de alguna distribución específica.<br />
Es decir que según la distribución de la que provienen las X puede que haya alguna distribución conjugada tal que al asumirla para la pdf prior <span class="arithmatex">\(\epsilon(\theta)\)</span> ya sabemos que la distribución posterior también será de esa familia.</p>
<p>Un ejemplo ilustrador:<br />
  Supongamos que tomamos observaciones <span class="arithmatex">\(X_1...X_n\)</span> de una distribución Bernoulli de la cual no sabemos el parámetro <span class="arithmatex">\(\theta\)</span> (que debe estar entre 0 y 1). Supongamos además que la pdf prior de <span class="arithmatex">\(\theta\)</span> es una distribución beta con algúnos parámetros dados <span class="arithmatex">\(\alpha \text{ y } \beta\)</span>. En este caso sabemos que por ser un caso de distribución conjugada, la pdf posterior de <span class="arithmatex">\(\theta\)</span> dado <span class="arithmatex">\(X = x_i (i = 1,...,n)\)</span> es a su vez una distribución beta con parámetros <span class="arithmatex">\(\alpha + \sum_{i=1}^n x_i \text{ y } \beta + n - \sum_{i=1}^n x_i\)</span>.</p>
<p>Según la distribución de la que provengan las observaciones hay distintas distribuciones conjugadas que son las más convenientes para ese caso.</p>
<h2 id="estimacion-de-parametros"><a class="toclink" href="../../2019/10/31/maxima-verosimilitud-y-estimacion-bayesiana/#estimacion-de-parametros">Estimación de parámetros</a></h2>
<p>La idea es estimar algún parámetro de la distribución de la cual se obtienen los datos observados. El valor estimado del parámetro va a depender de dos cosas:  </p>
<ul>
<li>Del <em>estimador</em> que hayamos elegido (es decir, la función de los datos elegida)</li>
<li>De la muestra. El valor estimado va a depender de los datos aleatorios que tengamos de la distribución.</li>
</ul>
<p>Como el estimador depende de la muestra podemos verlo a su vez como una variable aleatoria.</p>
<h3 id="funcion-de-perdida"><a class="toclink" href="../../2019/10/31/maxima-verosimilitud-y-estimacion-bayesiana/#funcion-de-perdida">Función de pérdida</a></h3>
<p>Lo que queremos de un estimador es que devuelva un valor estimado "a" para el parámetro lo más cercano posible al verdadero valor de <span class="arithmatex">\(\theta\)</span>. La función de pérdida es una función que cuantifica esto.
$$ L(\theta,a)$$
Hay algunas funciones habituales pero pueden adecuarse según el problema.<br />
Podemos decir que en general lo que se busca es encontrar una estimación para la cual la esperanza de la pérdida sea un mínimo.</p>
<h3 id="estimador-bayesiano"><a class="toclink" href="../../2019/10/31/maxima-verosimilitud-y-estimacion-bayesiana/#estimador-bayesiano">Estimador bayesiano</a></h3>
<p>Si tenemos una muestra aleatoria y una pdf posterior para <span class="arithmatex">\(\theta\)</span> entonces el valor esperado de la pérdida para cualquier valor estimado "a" es:
<span class="arithmatex">\(<span class="arithmatex">\(E[L(\theta,a)|x] = \int_\Omega L(\theta,a)\epsilon(\theta,x)d\theta\)</span>\)</span></p>
<p>Lo que buscamos es encontrar un valor de a cuya pérdida esperada sea mínima. La función que genera un valor de a mínimo para cada posible valor de X será un estimador de <span class="arithmatex">\(\theta\)</span> y en particular se llamará <em>Estimador Bayesiano</em>.<br />
El estimador bayesiano, que minimiza la pérdida esperada para cualquier set de datos X, va a depender de la función de pérdida que elijamos y de la pdf prior que se elija para <span class="arithmatex">\(\theta\)</span>.</p>
<p>Por ejemplo,para la función de pérdida más utilizada, que es la de error cuadrático
<span class="arithmatex">\(<span class="arithmatex">\(L(\theta,a) = (\theta -a)^2\)</span>\)</span>
está demostrado que la pérdida es mínima cuando <span class="arithmatex">\(a\)</span> es la media de la distribución posterior <span class="arithmatex">\(E(\theta|x)\)</span>.</p>
<p>Dijimos que el valor del estimador bayesiano va a depender de la distribución prior elegida. Esto es cierto, pero hay que tener en cuenta que para muestras grandes las diferencias empiezan a achicarse y los estimadores bayesianos provenientes de distintos priors empiezan a converger en la mayoría de los casos.</p>
<h3 id="estimadores-de-maxima-verosimilitud"><a class="toclink" href="../../2019/10/31/maxima-verosimilitud-y-estimacion-bayesiana/#estimadores-de-maxima-verosimilitud">Estimadores de Máxima Verosimilitud</a></h3>
<p>Los estimadores de máxima verosimilitud (MLE) son muy comunmente usados para estimar parámetros desconocidos ya que más allá de la discusión casi filosófica de "bayesianos vs frecuentistas", sirven para estimar sin tener que definir una función de pérdida ni una distribución prior para los parámetros. Esto último es importante ya que para casos donde se necesita estimar un vector de parámetros, la distribución prior debe ser una multivariada que englobe a todos y eleva la complejidad del proceso bayesiano ampliamente.<br />
Para muestras chicas MLE suele hacer un trabajo decente y para muestras grandes suele ser excelente por lo que se llega a resultados muy similares a través de un proceso más directo y más sencillo.  </p>
<p>Para estimar mediante MLE lo único que necesitamos es la función de verosimilitud ya definida.
<span class="arithmatex">\(<span class="arithmatex">\(f_n(x_1...X_n|\theta)\)</span>\)</span>
Luego lo único que se hace es buscar el parámetro <span class="arithmatex">\(\hat \theta\)</span> (estimado) que maximice esa función. Básicamente es buscar qué parámetro hace que la probabilidad conjunta de obtener esos valores de X sea máxima? Ese es nuestro MLE.</p>
<p>Para la gran mayoría de los casos esta metodología funciona pero hay que tener en cuenta que es posible que para algunos problemas no haya un máximo para la función de verosimilitud o que haya más de un punto, en cuyo caso hay que elegir alguno de ellos.</p>
<h4 id="mle-en-bernoulli"><a class="toclink" href="../../2019/10/31/maxima-verosimilitud-y-estimacion-bayesiana/#mle-en-bernoulli">MLE en Bernoulli</a></h4>
<p>Supongamos que tomamos observaciones <span class="arithmatex">\(X_1...X_n\)</span> de una distribución Bernoulli de la cual no sabemos el parámetro <span class="arithmatex">\(\theta\)</span> (que debe estar entre 0 y 1).</p>
<p>Para cualquier vector de observaciones <span class="arithmatex">\(X_1...X_n\)</span> la función de verosimilitud es:
$$ f_n(x|\theta) = \prod_{i = 1}^n \theta<sup 1-x_i="1-x_i">{x_i}(1-\theta)</sup>$$
El valor de <span class="arithmatex">\(\theta\)</span> que maximice la función de verosimilitud es el mismo valor que maximiza <span class="arithmatex">\(log f_n(x|\theta)\)</span>, por lo que es conveniente encontrar tal valor buscando que maximice:
<span class="arithmatex">\(<span class="arithmatex">\(L(\theta) = log f_n(x|\theta) = \sum_{i=1}^n[x_i log \theta + (1 - x_i) log(1-\theta)] = (\sum_{i=1}^nx_i)log \theta + (n-\sum_{i=1}^n x_i) log (1-\theta)\)</span>\)</span></p>
<p>Si derivamos <span class="arithmatex">\(dL(\theta) / d\theta\)</span> e igualamos a 0, resolviendo esa ecuando para <span class="arithmatex">\(\theta\)</span> encontramos que <span class="arithmatex">\(\theta = \bar x_n\)</span>.<br />
Este valor maximiza el logaritmo de la función de verosimilitud y por ende también de la función de verosimilitud en sí misma. Por lo tanto el MLE de <span class="arithmatex">\(\theta\)</span> es <span class="arithmatex">\(\hat \theta = \bar X_n\)</span></p>
<div class="language-r highlight"><pre><span></span><code><span id="__span-8-1"><a id="__codelineno-8-1" name="__codelineno-8-1" href="#__codelineno-8-1"></a><span class="c1"># Generamos 100 observaciones de una Bernoulli</span>
</span><span id="__span-8-2"><a id="__codelineno-8-2" name="__codelineno-8-2" href="#__codelineno-8-2"></a><span class="nf">set.seed</span><span class="p">(</span><span class="m">150</span><span class="p">)</span>
</span><span id="__span-8-3"><a id="__codelineno-8-3" name="__codelineno-8-3" href="#__codelineno-8-3"></a><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">rbinom</span><span class="p">(</span><span class="m">100</span><span class="p">,</span><span class="w"> </span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="n">prob</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.723</span><span class="p">)</span>
</span><span id="__span-8-4"><a id="__codelineno-8-4" name="__codelineno-8-4" href="#__codelineno-8-4"></a>
</span><span id="__span-8-5"><a id="__codelineno-8-5" name="__codelineno-8-5" href="#__codelineno-8-5"></a><span class="c1"># Calculamos su promedio, que ya sabemos es la mejor estimación para p dados los datos</span>
</span><span id="__span-8-6"><a id="__codelineno-8-6" name="__codelineno-8-6" href="#__codelineno-8-6"></a><span class="nf">mean</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</span></code></pre></div>
<div class="language-text highlight"><pre><span></span><code><span id="__span-9-1"><a id="__codelineno-9-1" name="__codelineno-9-1" href="#__codelineno-9-1"></a>## [1] 0.68
</span></code></pre></div>
<div class="language-r highlight"><pre><span></span><code><span id="__span-10-1"><a id="__codelineno-10-1" name="__codelineno-10-1" href="#__codelineno-10-1"></a><span class="c1"># Definimos función de verosimilitud</span>
</span><span id="__span-10-2"><a id="__codelineno-10-2" name="__codelineno-10-2" href="#__codelineno-10-2"></a><span class="c1"># Es la pdf de una Bernoulli para cada observación y sumamos sus logaritmos (en negativo porque </span>
</span><span id="__span-10-3"><a id="__codelineno-10-3" name="__codelineno-10-3" href="#__codelineno-10-3"></a><span class="c1"># el optimizador minimiza en vez de maximizar)</span>
</span><span id="__span-10-4"><a id="__codelineno-10-4" name="__codelineno-10-4" href="#__codelineno-10-4"></a><span class="n">LL</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">function</span><span class="p">(</span><span class="w"> </span><span class="n">p</span><span class="p">){</span>
</span><span id="__span-10-5"><a id="__codelineno-10-5" name="__codelineno-10-5" href="#__codelineno-10-5"></a><span class="w">   </span><span class="n">R</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">dbinom</span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">data</span><span class="p">,</span><span class="w"> </span><span class="n">size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="n">prob</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">p</span><span class="p">)</span>
</span><span id="__span-10-6"><a id="__codelineno-10-6" name="__codelineno-10-6" href="#__codelineno-10-6"></a>
</span><span id="__span-10-7"><a id="__codelineno-10-7" name="__codelineno-10-7" href="#__codelineno-10-7"></a><span class="w">   </span><span class="o">-</span><span class="nf">sum</span><span class="p">(</span><span class="nf">log</span><span class="p">(</span><span class="n">R</span><span class="p">))</span><span class="w">  </span><span class="c1"># Negativo porque log de probabilidades es &lt;0.</span>
</span><span id="__span-10-8"><a id="__codelineno-10-8" name="__codelineno-10-8" href="#__codelineno-10-8"></a><span class="w"> </span><span class="p">}</span>
</span><span id="__span-10-9"><a id="__codelineno-10-9" name="__codelineno-10-9" href="#__codelineno-10-9"></a>
</span><span id="__span-10-10"><a id="__codelineno-10-10" name="__codelineno-10-10" href="#__codelineno-10-10"></a><span class="c1"># Función que busca los parámetros que minimzan el negativo de la log verosimilitud</span>
</span><span id="__span-10-11"><a id="__codelineno-10-11" name="__codelineno-10-11" href="#__codelineno-10-11"></a><span class="c1"># Elegimos un valor inicial de p en el medio.</span>
</span><span id="__span-10-12"><a id="__codelineno-10-12" name="__codelineno-10-12" href="#__codelineno-10-12"></a><span class="n">stats4</span><span class="o">::</span><span class="nf">mle</span><span class="p">(</span><span class="n">LL</span><span class="p">,</span><span class="w"> </span><span class="n">start</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">list</span><span class="p">(</span><span class="n">p</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.5</span><span class="p">)</span><span class="w"> </span><span class="p">)</span>
</span></code></pre></div>
<p><div class="language-text highlight"><pre><span></span><code><span id="__span-11-1"><a id="__codelineno-11-1" name="__codelineno-11-1" href="#__codelineno-11-1"></a>## 
</span><span id="__span-11-2"><a id="__codelineno-11-2" name="__codelineno-11-2" href="#__codelineno-11-2"></a>## Call:
</span><span id="__span-11-3"><a id="__codelineno-11-3" name="__codelineno-11-3" href="#__codelineno-11-3"></a>## stats4::mle(minuslogl = LL, start = list(p = 0.5))
</span><span id="__span-11-4"><a id="__codelineno-11-4" name="__codelineno-11-4" href="#__codelineno-11-4"></a>## 
</span><span id="__span-11-5"><a id="__codelineno-11-5" name="__codelineno-11-5" href="#__codelineno-11-5"></a>## Coefficients:
</span><span id="__span-11-6"><a id="__codelineno-11-6" name="__codelineno-11-6" href="#__codelineno-11-6"></a>##         p 
</span><span id="__span-11-7"><a id="__codelineno-11-7" name="__codelineno-11-7" href="#__codelineno-11-7"></a>## 0.6799996
</span></code></pre></div>
Vemos que la estimación por MLE es <em>idéntica</em> a la media. No corresponde con el verdadero valor del parámetro poblacional p debido a la muestra particular que fue seleccionada.</p>
<p>Algunos comentarios finales:</p>
<ul>
<li>En algunos casos no es posible encontrar la solución óptima si no es por métodos numéricos.</li>
<li>Cuando <span class="arithmatex">\(n \to \infty\)</span> MLE converge en probabilidad al verdadero <span class="arithmatex">\(\theta\)</span>. Por ende cuando <span class="arithmatex">\(n \to \infty\)</span> el estimador bayesiano (que cumple la misma propiedad) y MLE serán muy parecidos entre sí y al verdadero <span class="arithmatex">\(\theta\)</span>.</li>
<li>MLE solo depende de las observaciones y no de cómo y en qué orden fueron recolectadas.</li>
</ul>
    
  </div>
</article>
      
        <article class="md-post md-post--excerpt">
  <header class="md-post__header">
    
      <nav class="md-post__authors md-typeset">
        
          <span class="md-author">
            <img src="https://media.licdn.com/dms/image/v2/D4D03AQGGiT9NDiLy7Q/profile-displayphoto-shrink_200_200/profile-displayphoto-shrink_200_200/0/1681511830071?e=1738195200&v=beta&t=Nd1WNLQTxHfCe7dT9BBaQYgaYtEHFCOPpntpImC4Lz8" alt="Franco Betteo">
          </span>
        
      </nav>
    
    <div class="md-post__meta md-meta">
      <ul class="md-meta__list">
        <li class="md-meta__item">
          <time datetime="2019-10-13 00:00:00+00:00">2019-10-13</time></li>
        
          <li class="md-meta__item">
            in
            
              <a href="../../category/estadistica/" class="md-meta__link">estadistica</a>, 
              <a href="../../category/r/" class="md-meta__link">R</a></li>
        
        
          
          <li class="md-meta__item">
            
              3 min read
            
          </li>
        
      </ul>
      
    </div>
  </header>
  <div class="md-post__content md-typeset">
    <h2 id="teorema-central-del-limite"><a class="toclink" href="../../2019/10/13/teorema-central-del-limite/">Teorema Central del Limite</a></h2>
<p>El <a href="https://es.wikipedia.org/wiki/Teorema_del_l%C3%ADmite_central">teorema central del límite (TCL)</a> 
es fundamental en el desarrollo de la estadística y ha obtenido
distintas variantes a lo largo de la historia. Veremos dos de las versiones más conocidas.</p>
<h4 id="teorema-central-del-limite-para-media-muestral-lindeberg-levy"><a class="toclink" href="../../2019/10/13/teorema-central-del-limite/#teorema-central-del-limite-para-media-muestral-lindeberg-levy">Teorema Central del Límite para Media Muestral (Lindeberg - Lévy)</a></h4>
<blockquote>
<p>Si las varaibles <span class="arithmatex">\(X_1 ... X_n\)</span> forman una muestra aleatoria de tamaño n proveniente de una 
distribución con media <span class="arithmatex">\(\mu\)</span> y varianza <span class="arithmatex">\(\sigma^2\)</span> (0 &lt; <span class="arithmatex">\(\sigma^2\)</span> &lt; <span class="arithmatex">\(\infty\)</span>), entonces  para 
cualquier número fijo x.
$$  \lim_{n\to \infty} Pr\Big[\frac{n^{&frac12;}(\bar X_n - \mu)}{\sigma} &lt;= x\Big] = \Phi (x)$$</p>
</blockquote>
<p>Donde <span class="arithmatex">\(\Phi (x)\)</span> es la función de distribución de una Normal Estándar.</p>
<p>El por qué de la convergencia del teorema no será probado acá pero no es díficil de encontrar.
Por ejemplo <a href="https://www.uv.es/ceaces/tex1t/2%20conver/levi.htm">ACÁ</a></p>
<p>Básicamente lo que dice el teorema, es que tomando una muestra grande de una población con media <span class="arithmatex">\(\mu\)</span> y 
varianza <span class="arithmatex">\(\sigma^2\)</span> definidas, entonces <span class="arithmatex">\(\frac{n^{1/2}(\bar X_n - \mu)}{\sigma}\)</span> va a tender a una normal estándar. Como consecuencia de eso podemos decir que <span class="arithmatex">\(\bar X_n\)</span> va a distribuirse 
aproximandamete como <span class="arithmatex">\(N(\mu, \sigma^2/n)\)</span>.</p>
<p>El TCL nos dice cómo se distribuye la media muestral si tenemos una muestra grande.</p>
<p>Análogamente, también podemos decir que <span class="arithmatex">\(\sum_{i=1}^n X_i\)</span> va a ser aproximadamente una normal
<span class="arithmatex">\(N(n\mu, n\sigma^2)\)</span></p>
<h5 id="ejemplo-lanzar-una-moneda"><a class="toclink" href="../../2019/10/13/teorema-central-del-limite/#ejemplo-lanzar-una-moneda">Ejemplo. Lanzar una moneda</a></h5>
<p>Si lanzamos una moneda 900 veces. Cuál es la probabilidad  de obtener más de 495 caras?</p>
<p><span class="arithmatex">\(X_i\)</span> = 1 si sale cara en el lanzamiento i, y 0 si sale cruz.<br />
E(<span class="arithmatex">\(X_i\)</span>) = &frac12; y Var(<span class="arithmatex">\(X_i\)</span>) = &frac14;. Esto se deduce de ser un experimento con distribución Bernouilli.</p>
<p>Para llevarlo a los términos del TCL, tenemos una muestra de tamaño n = 900, con <span class="arithmatex">\(\mu\)</span> = &frac12; y
<span class="arithmatex">\(\sigma^2\)</span> = &frac14;.</p>
<p>Por TCL tenemos que la distribución de la suma del número total de caras <span class="arithmatex">\(\sum_{i=1}^{900} X_i\)</span> se
distribuye aproximádamente como una normal con media = 900 * (&frac12;) = 450,
varianza = 900 * (&frac14;) = 225 y desvío estándar 225^(&frac12;) = 15.</p>
<p>Por lo tanto la variable <span class="arithmatex">\(Z = \frac{H - 450}{15}\)</span> se dsitribuye aproximadamente como una normal 
estándar.
<span class="arithmatex">\(<span class="arithmatex">\(Pr( H &gt; 495) = Pr(\frac{H - 450}{15} &gt; \frac{495 - 450}{15}) = Pr(Z&gt;3) = 1 - \Phi(3) = 0.0013\)</span>\)</span></p>
<p>Podemos comparar contra el resultado que obtenemos al hacer el mismo ejercicio pero mirando 
directamente la distribución binomial (que es la que realmente genera el proceso de datos)</p>
<div class="language-r highlight"><pre><span></span><code><span id="__span-4-1"><a id="__codelineno-4-1" name="__codelineno-4-1" href="#__codelineno-4-1"></a><span class="nf">pbinom</span><span class="p">(</span><span class="m">495</span><span class="p">,</span><span class="m">900</span><span class="p">,</span><span class="w"> </span><span class="m">0.5</span><span class="p">,</span><span class="w"> </span><span class="n">lower.tail</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">FALSE</span><span class="p">)</span>
</span></code></pre></div>
<div class="language-text highlight"><pre><span></span><code><span id="__span-5-1"><a id="__codelineno-5-1" name="__codelineno-5-1" href="#__codelineno-5-1"></a>## [1] 0.001200108
</span></code></pre></div>
<p>Vemos que los resultados son muy similares.</p>
<h4 id="teorema-central-del-limite-para-suma-de-variables-aleatorias-independientes-liapunov"><a class="toclink" href="../../2019/10/13/teorema-central-del-limite/#teorema-central-del-limite-para-suma-de-variables-aleatorias-independientes-liapunov">Teorema Central del Límite para Suma de Variables Aleatorias Independientes (Liapunov)</a></h4>
<p>Este TCL aplica a una secuencia de variables aleatorias independientes pero que no necesariamente
tienen que provenir de una misma distribución. Todas deben tener una media y varianza definidas.</p>
<p>La variable <span class="arithmatex">\(<span class="arithmatex">\(Y_n = \frac{\sum_{i=1}^n X_i - \sum_{i=1}^2 \mu_i}{(\sum_{i=1}^n\sigma_i^2)^{1/2}}\)</span>\)</span></p>
<p>Entonces <span class="arithmatex">\(E(Y_n) = 0\)</span> y <span class="arithmatex">\(Var(Y_n)\)</span> = 1</p>
<p>Siendo un poco más precisos veamos el teorema:</p>
<blockquote>
<p>Suponiendo que las variables aleatorias <span class="arithmatex">\(X_1. X_2, ...\)</span>  son independientes y que
<span class="arithmatex">\(E(|X_i - \mu_i|^3) &lt; \infty\)</span> para 1,2,...
Y suponidendo que <span class="arithmatex">\(<span class="arithmatex">\(\lim_{n\to \infty} \frac{\sum_{i=1}^n E(|X_i - \mu_i|^3)}{(\sum_{i=1}^n \sigma^2_i)^{3/2}} = 0\)</span>\)</span>
Entonces, utilizando la variable Y definida previamente tenemos que <span class="arithmatex">\(<span class="arithmatex">\(\lim_{n \to \infty} Pr(Y_n &lt;= x) = \Phi(x)\)</span>\)</span></p>
</blockquote>
<p>La interpretacaión del teorema es que si se cumple la condición de los 3eros momentos, entonces para valores grandes de n la distribución de <span class="arithmatex">\(\sum_{i=1}^n X_i\)</span> será aproximadamente normal con media <span class="arithmatex">\(\sum_{i=1}^n \mu_i\)</span> y varianza <span class="arithmatex">\(\sum_{i=1}^n \sigma^2_i\)</span>.</p>
<h4 id="diferencias-entre-lindeberg-levy-y-liapunov"><a class="toclink" href="../../2019/10/13/teorema-central-del-limite/#diferencias-entre-lindeberg-levy-y-liapunov">Diferencias entre Lindeberg-Lévy y Liapunov</a></h4>
<p>El teorema de Lindeberg-Lévy aplica para secuencias de variables aleatorias iid y solo requiere que la varianza de estas variables sea finita. En cambio el teorema de Liapunov aplica a secuencias de variables aleatorias independientes pero que no necesariamente provienen de una misma distribución. Requiere que el tercer momento de cada variable existe y cumple con la ecuación del teorema.</p>
<h4 id="efecto-de-tcl"><a class="toclink" href="../../2019/10/13/teorema-central-del-limite/#efecto-de-tcl">Efecto de TCL</a></h4>
<p>Más allá de la utilidad para aproximar distribuciones y medias mediante una normal, el TCL aporta una posible explicación a por qué tantas variables se distribuyen aproximadamante como normales. Si muchas de las variables a medir pueden pensarse como sumas de otras variables es lógico que tiendan a verse como normales aunque las variables que se suman para darle origen provengan de distintas distribuciones.</p>
    
  </div>
</article>
      
        <article class="md-post md-post--excerpt">
  <header class="md-post__header">
    
      <nav class="md-post__authors md-typeset">
        
          <span class="md-author">
            <img src="https://media.licdn.com/dms/image/v2/D4D03AQGGiT9NDiLy7Q/profile-displayphoto-shrink_200_200/profile-displayphoto-shrink_200_200/0/1681511830071?e=1738195200&v=beta&t=Nd1WNLQTxHfCe7dT9BBaQYgaYtEHFCOPpntpImC4Lz8" alt="Franco Betteo">
          </span>
        
      </nav>
    
    <div class="md-post__meta md-meta">
      <ul class="md-meta__list">
        <li class="md-meta__item">
          <time datetime="2019-07-01 00:00:00+00:00">2019-07-01</time></li>
        
          <li class="md-meta__item">
            in
            
              <a href="../../category/estadistica/" class="md-meta__link">estadistica</a>, 
              <a href="../../category/r/" class="md-meta__link">R</a></li>
        
        
          
          <li class="md-meta__item">
            
              11 min read
            
          </li>
        
      </ul>
      
    </div>
  </header>
  <div class="md-post__content md-typeset">
    <h2 id="metodos-de-resampleo-islr-capitulo-5"><a class="toclink" href="../../2019/07/01/metodos-de-resampleo/">Metodos de Resampleo - ISLR Capitulo 5</a></h2>
<p>Los métodos de resampleo son indispensables en la estadística moderna ya que permiten ajustar modelos a diferentes muestras de un mismo set de entrenamiento con el fin de obtener mayor información del modelo. Por ejemplo puede ser de utilidad para ver la variabilidad del modelo en distintas muestras. Los dos métodos que se presentan en el capítulo son <em>cross-validation</em> y <em>bootstrap</em>. A grandes rasgos CV puede servir para estimar el test error de un modelo o para ajustar hiperparámetros del modelo como el nivel de flexbilidad. Por su parte bootstrap puede usarse para medir la precisión de un parámetro estimado mediante un modelo estadístico.</p>
<h3 id="cross-validation"><a class="toclink" href="../../2019/07/01/metodos-de-resampleo/#cross-validation">Cross-Validation</a></h3>
<p>De los modelos que uno entrena es de sumo interés obtener el "test error" que sería el error promedio al predecir una nueva observación aplicando el modelo estadístico entrenado. Esto puede calcularse si tenemos un set de testeo puntualmente para ello pero no suele ser el caso lamentablemente.
En general no se tienen tantos datos como para separar en sets como uno desearía y surgen distintas técnicas para estimar el test error basado solamente en los datos de entrenamiento. Algunas de estas técnicas estiman el test error ajustando el training error por algún factor mientras que otras separan el training set en subsets donde uno hace las veces de test set.</p>
<h5 id="validation-set"><a class="toclink" href="../../2019/07/01/metodos-de-resampleo/#validation-set">Validation Set</a></h5>
<p>Un método muy utilizado es el del set de validación. Básicamente consiste en separar nuestro training set en dos sets, un "nuevo" training set y uno set de validación. Una práctica habitual es separar 70-30, pero va a depender de la cantidad de observaciones que tengan y no hay una regla estricta. Básicamente de los datos que tienen para entrenar el modelo separan una parte que va a ser el set de validación y entrenan el modelo con los datos restantes (70% por ejemplo). Luego se mide la precisión del modelo en el 30% restante (set de validación) que  son datos que no fueron utilizados a la hora de ajustar el modelo. Si utilizamos el MSE (mean squared error) cómo medida del error, este va a ser nuestro test error estimado. Recordemos que es el MSE calculado con las predicciones en el set de validación.
Por otra parte el set de validación también puede servir para ajustar algún hiperparámetro. Se pueden correr muchos modelos con distintos hiperparámetros y ver cuál tiene menor MSE en el set de validación.  </p>
<p>Es un método muy sencillo y suele ser eficaz pero tiene dos potenciales problemas:
* El MSE puede variar mucho según cómo dividieron las observaciones en training y validación. Otra segmentación puede dar resultados muy distintos.
* No utilizás todos tus datos para ajustar el modelo y puede que eso lleve a sobreestimar el test error, que quizás sería menor si usaras todas las observaciones para entrenar el modelo.</p>
<h5 id="leave-one-out-cross-validation"><a class="toclink" href="../../2019/07/01/metodos-de-resampleo/#leave-one-out-cross-validation">Leave-One-Out Cross-Validation</a></h5>
<p>LOOCV es un intento de solucionar los problemas del enfoque del set de validación [<strong>SPOILER: No es recomendado pero vale la pena conocerlo</strong>].<br />
Este enfoque es llevar el set de validación al extremo. Lo que se hace es de nuevo separar nuestro training set en dos pero esta vez guardando una sola observación como validación y usando las n-1 restantes para entrenar el modelo. La idea es hacer esto n veces, dejando cada vez una observación distinta como validación.
El test error estimado es el promedio de los MSE de cada predicción que se hizo de la observación de validación. 
Pensando en los problemas del set de validación, con LOOCV logramos usar casi todos los datos disponibles para entrenar el modelo (n-1 observaciones) por lo tanto deberíamos tener modelos con menos sesgo y no sobreestimar tanto el test error como con el enfoque de set de validación.
Por otra parte con el set de validación podemos obtener resultados muy distintos según el azar de cómo dividamos nuestros datos. En LOOCV esto no pasa ya que todos nuestros modelos de entrenamiento van a ser practicamente iguales salvo por una observación cada vez. No hay azar en la división de training y validación. 
Enseguida vemos el mayor problema de este enfoque, que es computacional. Debemos ajustar n modelos y no solo uno. Dependiendo de nuestros datos y la complejidad de nuestro modelo esto puede demandar muchísimo tiempo/recursos.</p>
<h5 id="k-fold-cross-validation"><a class="toclink" href="../../2019/07/01/metodos-de-resampleo/#k-fold-cross-validation">K-Fold Cross-Validation</a></h5>
<p>K-Fold CV es un punto intermedio entre ambos enfoques y es de lo más utilizado al día de hoy. Consiste en separar nuestros datos en K subsets de mismo tamaño. Se selecciona uno de esos K subsets y se lo deja como validación. Se entrena el modelo con los K-1 subsets y se predice en el de validación que separamos. Así K veces, dejando como validación cada vez uno subset distinto. El Test error estimado es el promedio de los MSE en cada caso. Se puede ver fácilmente que si K = n, entonces estaríamos en LOOCV. Los valores típicos de K suelen ser 5 o 10, y por ende es muchísimo menos costoso que LOOCV.
Al separar en "solo" 10 subsets cada set de validación puede tener cierta variabilidad en el MSE respecto a otros pero esta va a ser menor que en el enfoque de set de validación. En el libro se muestran unos gráficos para data simulada donde se ve que LOOCV y K-Fold tienen comportamiento muy similar y según el caso pueden sobreestimar o subestimar el verdadero test error (depende el problema y la flexibilidad elegida).
Como mencionamos para el set de validación, K-fold también puede ser utilizado para ajustar algún hiperparámetro del modelo como el nivel de fleixibilidad. En este caso lo que nos interesa es encontrar el valor mínimo del MSE entre los distintos posibles valores del hiperparámetro para decidir cual es el mejor posible pero el valor puntual del MSE o su precisión no nos interesa tanto.</p>
<h5 id="trade-off-entre-sesgo-y-varianza-en-k-fold-cross-validation"><a class="toclink" href="../../2019/07/01/metodos-de-resampleo/#trade-off-entre-sesgo-y-varianza-en-k-fold-cross-validation">Trade-Off entre sesgo y varianza en K-Fold Cross-Validation</a></h5>
<p>Otro punto muy importante de K-Fold, además de que requiere menos intensidad computacional que LOOCV, es que suele dar estimaciones más precisas del test error que LOOCV, y esto tiene que ver por el tradeoff entre sesgo y varianza.</p>
<p>Vimos antes que LOOCV debería ser el estimar más insesgado del test error ya que utiliza casi todas las observaciones de entrenamiento cada vez sin embargo hay que ver que sucede con la varianza ya que es otro componente del MSE. (Más detalles en <a href="https://fbetteo.netlify.com/2019/05/aprendizaje-estad%C3%ADstico-islr-capitulo-2/">ISLR Cap 2</a>).<br />
Resulta que LOOCV tiene mayor varianza que K-Fold CV siempre que K sea menor que n. Esto sucede porque en LOOCV lo que hacemos es promediar el resultado de n modelos cuyos datos de entrenamiento son casi idénticos (salvo por una observación) y por ende los resultados están en gran medida correlacionados positivamente.<br />
Por otro lado al hacer K-Fold CV se promedian <em>solo</em> K resultados que están menos correlacionados entre sí ya que los datos de entrenamiento se solapan menos entre ellos. 
La clave acá es que el promedio de muchos valores altamente correlacionados tiene mayor varianza que el promedio de muchos valores que no están tan correlacionados. Dado este escenario se hicieron pruebas que llegaron a la conclusión empírica de que K=5 y k = 10 son valores que no suelen tener excesivo sesgo ni varianza.<br />
Al parecer en los últimos años se empezó a dudar de la universalidad de este enunciado y se han hecho pruebas donde LOOCV no tiene mayor varianza. Sin embargo sigue siendo computacionalmente más demandante y el beneficio del menor sesgo no era suficiente para darle demasiada importancia.</p>
<h5 id="cross-validation-en-problemas-de-clasificacion"><a class="toclink" href="../../2019/07/01/metodos-de-resampleo/#cross-validation-en-problemas-de-clasificacion">Cross-Validation en problemas de clasificación.</a></h5>
<p>Los procedimientos vistos hasta ahora son útiles tanto para variables continuas como para problemas de clasificación. Vinimos usando ejemplos donde la medida del error era el MSE (variable dependiente continua) pero podemos aplicar todo de la misma manera utilizando alguna medida de clasificación como la cantidad de observaciones mal clasificadas. Todo el resto se mantiene y es válido, tanto sete de validación, como LOOCV o K-Fold.</p>
<h3 id="bootstrap"><a class="toclink" href="../../2019/07/01/metodos-de-resampleo/#bootstrap">Bootstrap</a></h3>
<p>El <em>bootstrap</em> es una herramienta estadística muy extendida que se utiliza para cuantificar la incertidumbre asociada a algún estimador o método de aprendizaje estadístico. Un ejemplo sencilla sería que se puede usar para estimar los errores estándar de los coeficientes de una regresión lineal. Sin embargo lo poderoso de esta herramienta es que es utilizable en muchísimos métodos de aprendizaje, incluso en algunos donde es difícil estimar la varianza o esta no es calculado por los paquetes estadísticos.<br />
Idealmente para estimar la variabilidad de un estimador lo que uno haría es ajustar un modelo n veces y ver cómo varía el estimador a lo largo de esos n modelos utilizando n muestras. Sin embargo no es habitual tener tantos datos ni muestras disponibles. Mismo uno querría utilizar todos los datos en simultáneo posiblemente para reducir el sesgo. Acá es donde bootstrap se luce ya que permite emular el proceso de obtener nuevas muestras de datos a partir de nuestros datos de entrenamiento. <strong>En vez de muestrear de manera independiente sobre la población lo que se hace es muestrear n veces con reposición de nuestro set de entrenamiento, generado n muestras a partir de nuestros datos originales</strong>.
Ya con nuestras nuevas muestras (provenientes todas del dataset original) podemos calcular n modelos y por ende n veces el mismo estimador, pudiendo estimar el desvío estándar de este.<br />
En el fondo lo que se hace es suponer que nuestra muestra es <em>representativa</em> de la población y es nuestra mejor aproximación. Luego obtenemos muestras de estos datos que son nuestra versión reducida de la población. Posiblemente haya algún sesgo pero es una herramienta bastante útil para estimar la variabilidad de nuestros estimadores.</p>
<p>Generamos un ejemplo para ver cómo funciona.</p>
<p>Empezamos generado una población de y que depende x con intercepto 5 y b1 = 5.</p>
<div class="language-r highlight"><pre><span></span><code><span id="__span-28-1"><a id="__codelineno-28-1" name="__codelineno-28-1" href="#__codelineno-28-1"></a><span class="nf">library</span><span class="p">(</span><span class="n">ggplot2</span><span class="p">)</span>
</span><span id="__span-28-2"><a id="__codelineno-28-2" name="__codelineno-28-2" href="#__codelineno-28-2"></a><span class="nf">set.seed</span><span class="p">(</span><span class="m">1</span><span class="p">)</span>
</span><span id="__span-28-3"><a id="__codelineno-28-3" name="__codelineno-28-3" href="#__codelineno-28-3"></a><span class="n">x</span><span class="w"> </span><span class="o">&lt;-</span><span class="nf">rnorm</span><span class="p">(</span><span class="m">10000</span><span class="p">,</span><span class="w"> </span><span class="n">mean</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">2</span><span class="p">,</span><span class="w"> </span><span class="n">sd</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">3</span><span class="p">)</span>
</span><span id="__span-28-4"><a id="__codelineno-28-4" name="__codelineno-28-4" href="#__codelineno-28-4"></a><span class="n">y</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">4</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="m">5</span><span class="o">*</span><span class="n">x</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="nf">rnorm</span><span class="p">(</span><span class="m">10000</span><span class="p">,</span><span class="m">0</span><span class="p">,</span><span class="m">4</span><span class="p">)</span>
</span><span id="__span-28-5"><a id="__codelineno-28-5" name="__codelineno-28-5" href="#__codelineno-28-5"></a><span class="n">df</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">cbind.data.frame</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="n">x</span><span class="p">)</span>
</span><span id="__span-28-6"><a id="__codelineno-28-6" name="__codelineno-28-6" href="#__codelineno-28-6"></a>
</span><span id="__span-28-7"><a id="__codelineno-28-7" name="__codelineno-28-7" href="#__codelineno-28-7"></a><span class="nf">ggplot</span><span class="p">(</span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">df</span><span class="p">,</span><span class="w"> </span><span class="nf">aes</span><span class="p">(</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="n">y</span><span class="w"> </span><span class="p">))</span><span class="w"> </span><span class="o">+</span><span class="w"> </span>
</span><span id="__span-28-8"><a id="__codelineno-28-8" name="__codelineno-28-8" href="#__codelineno-28-8"></a><span class="w">  </span><span class="nf">geom_point</span><span class="p">()</span>
</span></code></pre></div>
<p><img alt="Image" src="../../img/2019-07-01-metodos-de-resampleo-unnamed-chunk-1-1.png" /></p>
<p>Primero vemos el caso ideal que sería poder obtener muchas muestras de la población y ajustar modelos a estas. Luego veremos como varían nuestros coeficientes.</p>
<div class="language-r highlight"><pre><span></span><code><span id="__span-29-1"><a id="__codelineno-29-1" name="__codelineno-29-1" href="#__codelineno-29-1"></a><span class="c1"># Muestras de la población</span>
</span><span id="__span-29-2"><a id="__codelineno-29-2" name="__codelineno-29-2" href="#__codelineno-29-2"></a><span class="n">results_pop</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">data.frame</span><span class="p">(</span><span class="n">b0</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">double</span><span class="p">(),</span><span class="w"> </span><span class="n">b1</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">double</span><span class="p">())</span>
</span><span id="__span-29-3"><a id="__codelineno-29-3" name="__codelineno-29-3" href="#__codelineno-29-3"></a><span class="nf">set.seed</span><span class="p">(</span><span class="m">123</span><span class="p">)</span>
</span><span id="__span-29-4"><a id="__codelineno-29-4" name="__codelineno-29-4" href="#__codelineno-29-4"></a><span class="nf">for </span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="n">in</span><span class="w"> </span><span class="m">1</span><span class="o">:</span><span class="m">1000</span><span class="p">){</span>
</span><span id="__span-29-5"><a id="__codelineno-29-5" name="__codelineno-29-5" href="#__codelineno-29-5"></a><span class="w">  </span><span class="n">df_train</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">df</span><span class="p">[</span><span class="nf">sample</span><span class="p">(</span><span class="nf">nrow</span><span class="p">(</span><span class="n">df</span><span class="p">),</span><span class="n">size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">500</span><span class="p">,</span><span class="n">replace</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">FALSE</span><span class="p">),]</span>
</span><span id="__span-29-6"><a id="__codelineno-29-6" name="__codelineno-29-6" href="#__codelineno-29-6"></a><span class="w">  </span><span class="n">ml_train</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">lm</span><span class="p">(</span><span class="n">formula</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">df_train</span><span class="p">)</span>
</span><span id="__span-29-7"><a id="__codelineno-29-7" name="__codelineno-29-7" href="#__codelineno-29-7"></a><span class="w">  </span><span class="n">results_pop</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="m">1</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ml_train</span><span class="o">$</span><span class="n">coefficients</span><span class="p">[[</span><span class="m">1</span><span class="p">]]</span>
</span><span id="__span-29-8"><a id="__codelineno-29-8" name="__codelineno-29-8" href="#__codelineno-29-8"></a><span class="w">  </span><span class="n">results_pop</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="m">2</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ml_train</span><span class="o">$</span><span class="n">coefficients</span><span class="p">[[</span><span class="m">2</span><span class="p">]]</span>
</span><span id="__span-29-9"><a id="__codelineno-29-9" name="__codelineno-29-9" href="#__codelineno-29-9"></a>
</span><span id="__span-29-10"><a id="__codelineno-29-10" name="__codelineno-29-10" href="#__codelineno-29-10"></a><span class="p">}</span>
</span><span id="__span-29-11"><a id="__codelineno-29-11" name="__codelineno-29-11" href="#__codelineno-29-11"></a>
</span><span id="__span-29-12"><a id="__codelineno-29-12" name="__codelineno-29-12" href="#__codelineno-29-12"></a><span class="nf">summary</span><span class="p">(</span><span class="n">results_pop</span><span class="p">)</span>
</span></code></pre></div>
<div class="language-text highlight"><pre><span></span><code><span id="__span-30-1"><a id="__codelineno-30-1" name="__codelineno-30-1" href="#__codelineno-30-1"></a>##        b0              b1       
</span><span id="__span-30-2"><a id="__codelineno-30-2" name="__codelineno-30-2" href="#__codelineno-30-2"></a>##  Min.   :3.198   Min.   :4.804  
</span><span id="__span-30-3"><a id="__codelineno-30-3" name="__codelineno-30-3" href="#__codelineno-30-3"></a>##  1st Qu.:3.834   1st Qu.:4.969  
</span><span id="__span-30-4"><a id="__codelineno-30-4" name="__codelineno-30-4" href="#__codelineno-30-4"></a>##  Median :3.974   Median :5.005  
</span><span id="__span-30-5"><a id="__codelineno-30-5" name="__codelineno-30-5" href="#__codelineno-30-5"></a>##  Mean   :3.975   Mean   :5.004  
</span><span id="__span-30-6"><a id="__codelineno-30-6" name="__codelineno-30-6" href="#__codelineno-30-6"></a>##  3rd Qu.:4.115   3rd Qu.:5.043  
</span><span id="__span-30-7"><a id="__codelineno-30-7" name="__codelineno-30-7" href="#__codelineno-30-7"></a>##  Max.   :4.615   Max.   :5.169
</span></code></pre></div>
<div class="language-r highlight"><pre><span></span><code><span id="__span-31-1"><a id="__codelineno-31-1" name="__codelineno-31-1" href="#__codelineno-31-1"></a><span class="nf">print</span><span class="p">(</span><span class="nf">paste0</span><span class="p">(</span><span class="s">&quot;El desvío estándar de b0 a partir de 1000 modelos es &quot;</span><span class="p">,</span><span class="w"> </span><span class="nf">sd</span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">results_pop</span><span class="o">$</span><span class="n">b0</span><span class="p">)))</span>
</span></code></pre></div>
<div class="language-text highlight"><pre><span></span><code><span id="__span-32-1"><a id="__codelineno-32-1" name="__codelineno-32-1" href="#__codelineno-32-1"></a>## [1] &quot;El desvío estándar de b0 a partir de 1000 modelos es 0.207882713489026&quot;
</span></code></pre></div>
<div class="language-r highlight"><pre><span></span><code><span id="__span-33-1"><a id="__codelineno-33-1" name="__codelineno-33-1" href="#__codelineno-33-1"></a><span class="nf">ggplot</span><span class="p">(</span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">results_pop</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span>
</span><span id="__span-33-2"><a id="__codelineno-33-2" name="__codelineno-33-2" href="#__codelineno-33-2"></a><span class="w">  </span><span class="nf">geom_histogram</span><span class="p">(</span><span class="w"> </span><span class="nf">aes</span><span class="p">(</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">b0</span><span class="p">),</span><span class="w"> </span><span class="n">fill</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;white&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">colour</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;black&quot;</span><span class="p">)</span><span class="w">  </span><span class="o">+</span><span class="w"> </span>
</span><span id="__span-33-3"><a id="__codelineno-33-3" name="__codelineno-33-3" href="#__codelineno-33-3"></a><span class="w">  </span><span class="nf">geom_vline</span><span class="p">(</span><span class="w"> </span><span class="nf">aes</span><span class="p">(</span><span class="n">xintercept</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">mean</span><span class="p">(</span><span class="n">b0</span><span class="p">)),</span><span class="w"> </span><span class="n">colour</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;red&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1</span><span class="p">)</span>
</span></code></pre></div>
<p><img alt="Image" src="../../img/2019-07-01-metodos-de-resampleo-unnamed-chunk-2-1.png" /></p>
<p>Vemos que estimando 1000 modelos a partir de 500 observaciones independientes de la población original obtenemos para b0 estimaciones centradas aproximadamente en el valor real (3.975) pero con un mínimo encontrado en 3.198 y un máximo en 4.615. El desvío estándar de la estimación es de 0.2078.
A su vez mostramos un histograma de cómo se distribuye la estimación de b0.</p>
<p>Ahora simulemos un caso real donde solo tenemos una muestra de 500 observaciones y es todo con lo que podemos trabajar.
Como primera medida estimamos una regresión lineal y vemos qué parámetros ajustan mejor nuestros datos.</p>
<div class="language-r highlight"><pre><span></span><code><span id="__span-34-1"><a id="__codelineno-34-1" name="__codelineno-34-1" href="#__codelineno-34-1"></a><span class="c1"># Muestras de la población</span>
</span><span id="__span-34-2"><a id="__codelineno-34-2" name="__codelineno-34-2" href="#__codelineno-34-2"></a><span class="n">results_sample</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">data.frame</span><span class="p">(</span><span class="n">b0</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">double</span><span class="p">(),</span><span class="w"> </span><span class="n">b1</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">double</span><span class="p">())</span>
</span><span id="__span-34-3"><a id="__codelineno-34-3" name="__codelineno-34-3" href="#__codelineno-34-3"></a><span class="nf">set.seed</span><span class="p">(</span><span class="m">456</span><span class="p">)</span>
</span><span id="__span-34-4"><a id="__codelineno-34-4" name="__codelineno-34-4" href="#__codelineno-34-4"></a><span class="n">df_train_sample</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">df</span><span class="p">[</span><span class="nf">sample</span><span class="p">(</span><span class="nf">nrow</span><span class="p">(</span><span class="n">df</span><span class="p">),</span><span class="n">size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">500</span><span class="p">,</span><span class="n">replace</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">FALSE</span><span class="p">),]</span>
</span><span id="__span-34-5"><a id="__codelineno-34-5" name="__codelineno-34-5" href="#__codelineno-34-5"></a><span class="n">ml_train_sample</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">lm</span><span class="p">(</span><span class="n">formula</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">df_train_sample</span><span class="p">)</span>
</span><span id="__span-34-6"><a id="__codelineno-34-6" name="__codelineno-34-6" href="#__codelineno-34-6"></a>
</span><span id="__span-34-7"><a id="__codelineno-34-7" name="__codelineno-34-7" href="#__codelineno-34-7"></a><span class="n">results_sample</span><span class="p">[</span><span class="m">1</span><span class="p">,</span><span class="m">1</span><span class="p">]</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">ml_train_sample</span><span class="o">$</span><span class="n">coefficients</span><span class="p">[[</span><span class="m">1</span><span class="p">]]</span>
</span><span id="__span-34-8"><a id="__codelineno-34-8" name="__codelineno-34-8" href="#__codelineno-34-8"></a><span class="n">results_sample</span><span class="p">[</span><span class="m">1</span><span class="p">,</span><span class="m">2</span><span class="p">]</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">ml_train_sample</span><span class="o">$</span><span class="n">coefficients</span><span class="p">[[</span><span class="m">2</span><span class="p">]]</span>
</span><span id="__span-34-9"><a id="__codelineno-34-9" name="__codelineno-34-9" href="#__codelineno-34-9"></a>
</span><span id="__span-34-10"><a id="__codelineno-34-10" name="__codelineno-34-10" href="#__codelineno-34-10"></a><span class="n">knitr</span><span class="o">::</span><span class="nf">kable</span><span class="p">(</span><span class="n">results_sample</span><span class="p">,</span><span class="w"> </span><span class="n">caption</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;Coefficients&quot;</span><span class="p">)</span>
</span></code></pre></div>
<p>Table: Coefficients</p>
<table>
<thead>
<tr>
<th style="text-align: right;">b0</th>
<th style="text-align: right;">b1</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: right;">3.89621</td>
<td style="text-align: right;">5.025914</td>
</tr>
</tbody>
</table>
<p>Vemos que a partir de entrenar el modelo con las 500 observaciones obtenemos un intercepto de 3.896 y un b1 estimado de 5.026.
Nosotros, como conocemos la población, sabemos que el intercepto no es del todo preciso ya que el real es 4 sin embargo en un caso real eso no lo sabríamos. Nos interesaría saber qué variabilidad tiene ese coeficiente para tener una medida de qué tan variable es nuestro resultado.<br />
Para una regresión lineal eso se puede saber ya que no es difícil calcular la varianza de los estimadores, pero con modelos más complicados no siempre se puede y ahí es donde bootstrap ayuda realmente. Acá lo hacemos con la regresión lineal porque es lo más sencillo de mostrar.<br />
Suponiendo que queremos obtener una estimaación de la variabilidad del coeficiente estimado b0 procedemos con bootstrap.</p>
<p>Fijense que lo que hacemos es distinto al primer caso. Acá tomamos 10000 muestras no de la población sino de nuestro set de 500 observaciones. Estas muestras son también de 500 observaciones, la diferencia es que es con reposición por lo tanto una misma observación puede figurar más de una vez.</p>
<div class="language-r highlight"><pre><span></span><code><span id="__span-35-1"><a id="__codelineno-35-1" name="__codelineno-35-1" href="#__codelineno-35-1"></a><span class="c1"># Muestras de la población</span>
</span><span id="__span-35-2"><a id="__codelineno-35-2" name="__codelineno-35-2" href="#__codelineno-35-2"></a><span class="n">results_bootstrap</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">data.frame</span><span class="p">(</span><span class="n">b0</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">double</span><span class="p">(),</span><span class="w"> </span><span class="n">b1</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">double</span><span class="p">())</span>
</span><span id="__span-35-3"><a id="__codelineno-35-3" name="__codelineno-35-3" href="#__codelineno-35-3"></a><span class="nf">set.seed</span><span class="p">(</span><span class="m">789</span><span class="p">)</span>
</span><span id="__span-35-4"><a id="__codelineno-35-4" name="__codelineno-35-4" href="#__codelineno-35-4"></a><span class="nf">for </span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="n">in</span><span class="w"> </span><span class="m">1</span><span class="o">:</span><span class="m">10000</span><span class="p">){</span>
</span><span id="__span-35-5"><a id="__codelineno-35-5" name="__codelineno-35-5" href="#__codelineno-35-5"></a><span class="w">  </span><span class="n">df_train_bs</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">df</span><span class="p">[</span><span class="nf">sample</span><span class="p">(</span><span class="nf">nrow</span><span class="p">(</span><span class="n">df_train_sample</span><span class="p">),</span><span class="n">size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">500</span><span class="p">,</span><span class="n">replace</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">),]</span>
</span><span id="__span-35-6"><a id="__codelineno-35-6" name="__codelineno-35-6" href="#__codelineno-35-6"></a><span class="w">  </span><span class="n">ml_train_bs</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">lm</span><span class="p">(</span><span class="n">formula</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">df_train_bs</span><span class="p">)</span>
</span><span id="__span-35-7"><a id="__codelineno-35-7" name="__codelineno-35-7" href="#__codelineno-35-7"></a><span class="w">  </span><span class="n">results_bootstrap</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="m">1</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ml_train_bs</span><span class="o">$</span><span class="n">coefficients</span><span class="p">[[</span><span class="m">1</span><span class="p">]]</span>
</span><span id="__span-35-8"><a id="__codelineno-35-8" name="__codelineno-35-8" href="#__codelineno-35-8"></a><span class="w">  </span><span class="n">results_bootstrap</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="m">2</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ml_train_bs</span><span class="o">$</span><span class="n">coefficients</span><span class="p">[[</span><span class="m">2</span><span class="p">]]</span>
</span><span id="__span-35-9"><a id="__codelineno-35-9" name="__codelineno-35-9" href="#__codelineno-35-9"></a>
</span><span id="__span-35-10"><a id="__codelineno-35-10" name="__codelineno-35-10" href="#__codelineno-35-10"></a><span class="p">}</span>
</span><span id="__span-35-11"><a id="__codelineno-35-11" name="__codelineno-35-11" href="#__codelineno-35-11"></a>
</span><span id="__span-35-12"><a id="__codelineno-35-12" name="__codelineno-35-12" href="#__codelineno-35-12"></a><span class="nf">summary</span><span class="p">(</span><span class="n">results_bootstrap</span><span class="p">)</span>
</span></code></pre></div>
<div class="language-text highlight"><pre><span></span><code><span id="__span-36-1"><a id="__codelineno-36-1" name="__codelineno-36-1" href="#__codelineno-36-1"></a>##        b0              b1       
</span><span id="__span-36-2"><a id="__codelineno-36-2" name="__codelineno-36-2" href="#__codelineno-36-2"></a>##  Min.   :3.245   Min.   :4.791  
</span><span id="__span-36-3"><a id="__codelineno-36-3" name="__codelineno-36-3" href="#__codelineno-36-3"></a>##  1st Qu.:3.822   1st Qu.:4.982  
</span><span id="__span-36-4"><a id="__codelineno-36-4" name="__codelineno-36-4" href="#__codelineno-36-4"></a>##  Median :3.962   Median :5.020  
</span><span id="__span-36-5"><a id="__codelineno-36-5" name="__codelineno-36-5" href="#__codelineno-36-5"></a>##  Mean   :3.962   Mean   :5.019  
</span><span id="__span-36-6"><a id="__codelineno-36-6" name="__codelineno-36-6" href="#__codelineno-36-6"></a>##  3rd Qu.:4.100   3rd Qu.:5.057  
</span><span id="__span-36-7"><a id="__codelineno-36-7" name="__codelineno-36-7" href="#__codelineno-36-7"></a>##  Max.   :4.709   Max.   :5.205
</span></code></pre></div>
<div class="language-r highlight"><pre><span></span><code><span id="__span-37-1"><a id="__codelineno-37-1" name="__codelineno-37-1" href="#__codelineno-37-1"></a><span class="nf">print</span><span class="p">(</span><span class="nf">paste0</span><span class="p">(</span><span class="s">&quot;El desvío estándar de b0 a partir de 10000 modelos es &quot;</span><span class="p">,</span><span class="w"> </span><span class="nf">sd</span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">results_bootstrap</span><span class="o">$</span><span class="n">b0</span><span class="p">)))</span>
</span></code></pre></div>
<div class="language-text highlight"><pre><span></span><code><span id="__span-38-1"><a id="__codelineno-38-1" name="__codelineno-38-1" href="#__codelineno-38-1"></a>## [1] &quot;El desvío estándar de b0 a partir de 10000 modelos es 0.207126704818891&quot;
</span></code></pre></div>
<div class="language-r highlight"><pre><span></span><code><span id="__span-39-1"><a id="__codelineno-39-1" name="__codelineno-39-1" href="#__codelineno-39-1"></a><span class="nf">ggplot</span><span class="p">(</span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">results_bootstrap</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span>
</span><span id="__span-39-2"><a id="__codelineno-39-2" name="__codelineno-39-2" href="#__codelineno-39-2"></a><span class="w">  </span><span class="nf">geom_histogram</span><span class="p">(</span><span class="w"> </span><span class="nf">aes</span><span class="p">(</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">b0</span><span class="p">),</span><span class="n">fill</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;white&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">colour</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;black&quot;</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span>
</span><span id="__span-39-3"><a id="__codelineno-39-3" name="__codelineno-39-3" href="#__codelineno-39-3"></a><span class="w">  </span><span class="nf">geom_vline</span><span class="p">(</span><span class="w"> </span><span class="nf">aes</span><span class="p">(</span><span class="n">xintercept</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">mean</span><span class="p">(</span><span class="n">b0</span><span class="p">)),</span><span class="w"> </span><span class="n">colour</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;blue&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1</span><span class="p">)</span>
</span></code></pre></div>
<p><img alt="Image" src="../../img/2019-07-01-metodos-de-resampleo-unnamed-chunk-4-1.png" /></p>
<p>Voilà. Corrimos 10000 iteraciones de nuestro modelo a partir de 10000 muestras de nuestra data original. El desvío estándar de b0 para bootstrap quedó de 0.2071. Que si comparamos con el de 1000 muestras independientes que era 0.2078 es prácticamente igual.
A su vez, podemos calcular el desvío teórico de b0 a partir del modelo (la solución fácil).</p>
<div class="language-r highlight"><pre><span></span><code><span id="__span-40-1"><a id="__codelineno-40-1" name="__codelineno-40-1" href="#__codelineno-40-1"></a><span class="nf">summary</span><span class="p">(</span><span class="n">ml_train_sample</span><span class="p">)</span>
</span></code></pre></div>
<div class="language-text highlight"><pre><span></span><code><span id="__span-41-1"><a id="__codelineno-41-1" name="__codelineno-41-1" href="#__codelineno-41-1"></a>## 
</span><span id="__span-41-2"><a id="__codelineno-41-2" name="__codelineno-41-2" href="#__codelineno-41-2"></a>## Call:
</span><span id="__span-41-3"><a id="__codelineno-41-3" name="__codelineno-41-3" href="#__codelineno-41-3"></a>## lm(formula = y ~ x, data = df_train_sample)
</span><span id="__span-41-4"><a id="__codelineno-41-4" name="__codelineno-41-4" href="#__codelineno-41-4"></a>## 
</span><span id="__span-41-5"><a id="__codelineno-41-5" name="__codelineno-41-5" href="#__codelineno-41-5"></a>## Residuals:
</span><span id="__span-41-6"><a id="__codelineno-41-6" name="__codelineno-41-6" href="#__codelineno-41-6"></a>##      Min       1Q   Median       3Q      Max 
</span><span id="__span-41-7"><a id="__codelineno-41-7" name="__codelineno-41-7" href="#__codelineno-41-7"></a>## -13.2193  -2.8265   0.0281   2.7421  10.7577 
</span><span id="__span-41-8"><a id="__codelineno-41-8" name="__codelineno-41-8" href="#__codelineno-41-8"></a>## 
</span><span id="__span-41-9"><a id="__codelineno-41-9" name="__codelineno-41-9" href="#__codelineno-41-9"></a>## Coefficients:
</span><span id="__span-41-10"><a id="__codelineno-41-10" name="__codelineno-41-10" href="#__codelineno-41-10"></a>##             Estimate Std. Error t value Pr(&gt;|t|)    
</span><span id="__span-41-11"><a id="__codelineno-41-11" name="__codelineno-41-11" href="#__codelineno-41-11"></a>## (Intercept)  3.89621    0.21607   18.03   &lt;2e-16 ***
</span><span id="__span-41-12"><a id="__codelineno-41-12" name="__codelineno-41-12" href="#__codelineno-41-12"></a>## x            5.02591    0.05902   85.16   &lt;2e-16 ***
</span><span id="__span-41-13"><a id="__codelineno-41-13" name="__codelineno-41-13" href="#__codelineno-41-13"></a>## ---
</span><span id="__span-41-14"><a id="__codelineno-41-14" name="__codelineno-41-14" href="#__codelineno-41-14"></a>## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
</span><span id="__span-41-15"><a id="__codelineno-41-15" name="__codelineno-41-15" href="#__codelineno-41-15"></a>## 
</span><span id="__span-41-16"><a id="__codelineno-41-16" name="__codelineno-41-16" href="#__codelineno-41-16"></a>## Residual standard error: 3.98 on 498 degrees of freedom
</span><span id="__span-41-17"><a id="__codelineno-41-17" name="__codelineno-41-17" href="#__codelineno-41-17"></a>## Multiple R-squared:  0.9357, Adjusted R-squared:  0.9356 
</span><span id="__span-41-18"><a id="__codelineno-41-18" name="__codelineno-41-18" href="#__codelineno-41-18"></a>## F-statistic:  7252 on 1 and 498 DF,  p-value: &lt; 2.2e-16
</span></code></pre></div>
<p>Vemos que desde R el modelo nos devuelve que b0 tiene un desvío de 0.21607. Prácticamente igual al desvío de las muestras independientes como al de bootstrap.
Por otra parte vemos que el promedio de b0 estimado en bootstrap es mucho más cercano a 4 que el estimado con una sola iteración y quedó mucho más cerca que el promedio de los estimados mediante muestras independientes.
Nada mal no?</p>
    
  </div>
</article>
      
      
        
          



<nav class="md-pagination">
  <a class="md-pagination__link" href="../../">1</a> <span class="md-pagination__current">2</span> <a class="md-pagination__link" href="../3/">3</a> <a class="md-pagination__link" href="../4/">4</a>
</nav>
        
      
    </div>
  </div>

          
  <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var labels=set.querySelector(".tabbed-labels");for(var tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script>

<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
    
      
      <nav class="md-footer__inner md-grid" aria-label="Footer" >
        
          
          <a href="../../../interests/" class="md-footer__link md-footer__link--prev" aria-label="Previous: Interests">
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
            </div>
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Previous
              </span>
              <div class="md-ellipsis">
                Interests
              </div>
            </div>
          </a>
        
        
          
          <a href="../../category/personal/" class="md-footer__link md-footer__link--next" aria-label="Next: Personal">
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Next
              </span>
              <div class="md-ellipsis">
                Personal
              </div>
            </div>
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11z"/></svg>
            </div>
          </a>
        
      </nav>
    
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
      <div class="md-progress" data-md-component="progress" role="progressbar"></div>
    
    
    <script id="__config" type="application/json">{"base": "../../..", "features": ["announce.dismiss", "content.action.edit", "content.action.view", "content.code.annotate", "content.code.copy", "content.code.select", "content.tabs.link", "content.tooltips", "header.autohide", "navigation.expand", "navigation.footer", "navigation.indexes", "navigation.instant", "navigation.instant.prefetch", "navigation.instant.progress", "navigation.prune", "navigation.sections", "navigation.tabs", "navigation.tabs.sticky", "navigation.top", "navigation.tracking", "search.highlight", "search.share", "search.suggest", "toc.follow"], "search": "../../../assets/javascripts/workers/search.6ce7567c.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../../../assets/javascripts/bundle.83f73b43.min.js"></script>
      
        <script src="../../../javascripts/mathjax.js"></script>
      
        <script src="https://unpkg.com/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>